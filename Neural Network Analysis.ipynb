{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis\n",
    "\n",
    "**Reference**: Maleakhi Agung Wijaya  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from os.path import join\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, mean_absolute_error as mae\n",
    "import os\n",
    "from pathlib2 import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras import layers, models, backend as K, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocessing\n",
    "\n",
    "In this step, we will load all dataframes,fill missing values, and scale so that each column all features are on the same scale. Afterwards, we will generate sequential datasets using **full features, PCA features**, and only **technical indicator features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_orders, n_markets, aggregated_datasets = load_aggregated_datasets([ \n",
    "                                                                         \n",
    "                                                                          DATASET_AAPL,\n",
    "                                                                          DATASET_MSFT,\n",
    "                                                                          DATASET_AMZN])\n",
    "\n",
    "## AAPL\n",
    "aapl_df = aggregated_datasets[\"AAPL\"]\n",
    "\n",
    "## AMZN\n",
    "amzn_df = aggregated_datasets[\"AMZN\"]\n",
    "\n",
    "## MSFT\n",
    "msft_df = aggregated_datasets[\"MSFT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN BELOW FOR 3D CNN PRED\n",
    "# Fill missing values, do some scaling (run prev cell first)\n",
    "list_df = []\n",
    "\n",
    "for df in [aapl_df, msft_df, amzn_df]:\n",
    "    columns = df.columns\n",
    "    for i in columns:\n",
    "        df[i] = df[i].fillna(method=\"bfill\")\n",
    "    y = df[\"MOVEMENT\"].copy()\n",
    "    X = df.drop(columns=[\"MOVEMENT\"]).copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X))\n",
    "    X[\"MOVEMENT\"] = np.array(y)\n",
    "    X.columns = columns\n",
    "    list_df.append(X)\n",
    "    \n",
    "aapl_df_full = list_df[0]\n",
    "msft_df_full = list_df[1]\n",
    "amzn_df_full = list_df[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(df, min):\n",
    "    rfecv = RFECV(estimator=LogisticRegression(), step =1, min_features_to_select=min, cv=5, scoring='accuracy')\n",
    "    y = df[\"MOVEMENT\"].copy()\n",
    "    X = df.drop(columns=[\"MOVEMENT\"]).copy()\n",
    "    selector = rfecv.fit(df.drop(columns=[\"MOVEMENT\"]), df[\"MOVEMENT\"])\n",
    "    print(\"Optimal number of features: \", rfecv.n_features_)\n",
    "    selected_rfe_features = pd.DataFrame({'Feature':list(X.columns), 'Ranking': selector.ranking_})\n",
    "    selected_rfe_features.sort_values(by='Ranking',inplace=True)\n",
    "    print(selected_rfe_features.head(rfecv.n_features_))\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "    plt.plot(range(min, len(rfecv.grid_scores_) + min), rfecv.grid_scores_)\n",
    "    plt.show()\n",
    "    reduced_X = pd.DataFrame(selector.transform(X))\n",
    "    reduced_X[\"MOVEMENT\"] = y\n",
    "    return reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features:  8\n",
      "     Feature  Ranking\n",
      "27  Feeder-F        1\n",
      "23     Sugar        1\n",
      "21       Oil        1\n",
      "37     Mom15        1\n",
      "38     Mom20        1\n",
      "46       Pro        1\n",
      "29       Tnx        1\n",
      "43      Trix        1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features:  6\n",
      "      Feature  Ranking\n",
      "29        Tnx        1\n",
      "41     Fast_k        1\n",
      "2      Volume        1\n",
      "53        Cci        1\n",
      "44  William_R        1\n",
      "10       QCOM        1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features:  12\n",
      "     Feature  Ranking\n",
      "56    Ultosc        1\n",
      "17   Aud_usd        1\n",
      "16   Gpb_usd        1\n",
      "30       Bzf        1\n",
      "13    Silver        1\n",
      "12  MGC_Gold        1\n",
      "22   BTC-USD        1\n",
      "9       AVGO        1\n",
      "10      QCOM        1\n",
      "45      Rocr        1\n",
      "2     Volume        1\n",
      "35      Mom5        1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_df_pca = []\n",
    "\n",
    "for df in [aapl_df_full, msft_df_full, amzn_df_full]:\n",
    "    columns = df.columns\n",
    "    cur_df = df.copy()\n",
    "    cur_df = feature_select(cur_df , 5)\n",
    "    pca = PCA(n_components= 5)\n",
    "    y = cur_df[\"MOVEMENT\"].copy()\n",
    "    X = cur_df.drop(columns=[\"MOVEMENT\"]).copy()\n",
    "    reduced_X = pd.DataFrame(pca.fit_transform(X))\n",
    "    reduced_X[\"MOVEMENT\"] = y\n",
    "    list_df_pca.append(reduced_X)\n",
    "\n",
    "aapl_df_pca = list_df_pca[0]\n",
    "msft_df_pca = list_df_pca[1]\n",
    "amzn_df_pca = list_df_pca[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical indicator dataframe\n",
    "\n",
    "list_df_ti = []\n",
    "\n",
    "for df in [aapl_df_full, msft_df_full, amzn_df_full]:\n",
    "    \n",
    "    y = df[\"MOVEMENT\"].copy()\n",
    "    X = df[list(df.columns)[33:58]].copy()\n",
    "    X[\"MOVEMENT\"] = np.array(y)\n",
    "    list_df_ti.append(X)\n",
    "\n",
    "### Clean dataframe (ti features)\n",
    "aapl_df_ti = list_df_ti[0]\n",
    "msft_df_ti = list_df_ti[1]\n",
    "amzn_df_ti = list_df_ti[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential dataset\n",
    "sequence_length = 60\n",
    "\n",
    "### Sequential dataset (full features)\n",
    "aapl_X_seq, aapl_y_seq = generate_sequential_data(aapl_df_full, sequence_length)\n",
    "msft_X_seq, msft_y_seq = generate_sequential_data(msft_df_full, sequence_length)\n",
    "amzn_X_seq, amzn_y_seq = generate_sequential_data(amzn_df_full, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential dataset (PCA features)\n",
    "aapl_X_pca_seq, aapl_y_pca_seq = generate_sequential_data(aapl_df_pca, sequence_length)\n",
    "msft_X_pca_seq, msft_y_pca_seq = generate_sequential_data(msft_df_pca, sequence_length)\n",
    "amzn_X_pca_seq, amzn_y_pca_seq = generate_sequential_data(amzn_df_pca, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential dataset (TI features)\n",
    "aapl_X_ti_seq, aapl_y_ti_seq = generate_sequential_data(aapl_df_ti, sequence_length)\n",
    "msft_X_ti_seq, msft_y_ti_seq = generate_sequential_data(msft_df_ti, sequence_length)\n",
    "amzn_X_ti_seq, amzn_y_ti_seq = generate_sequential_data(amzn_df_ti, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNNpred\n",
    "\n",
    "In this section, we will implement a 2D CNNpred from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (full features)\n",
    "aapl_X_seq_flatten = sequential_reshape(aapl_X_seq, (len(aapl_X_seq), sequence_length, -1, 1))\n",
    "msft_X_seq_flatten = sequential_reshape(msft_X_seq, (len(msft_X_seq), sequence_length, -1, 1))\n",
    "amzn_X_seq_flatten = sequential_reshape(amzn_X_seq, (len(amzn_X_seq), sequence_length, -1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (pca)\n",
    "aapl_X_pca_seq_flatten = sequential_reshape(aapl_X_pca_seq, (len(aapl_X_seq), sequence_length, -1, 1))\n",
    "msft_X_pca_seq_flatten = sequential_reshape(msft_X_pca_seq, (len(msft_X_seq), sequence_length, -1, 1))\n",
    "amzn_X_pca_seq_flatten = sequential_reshape(amzn_X_pca_seq, (len(amzn_X_seq), sequence_length, -1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (technical indicator)\n",
    "aapl_X_ti_seq_flatten = sequential_reshape(aapl_X_ti_seq, (len(aapl_X_seq), sequence_length, -1, 1))\n",
    "msft_X_ti_seq_flatten = sequential_reshape(msft_X_ti_seq, (len(msft_X_seq), sequence_length, -1, 1))\n",
    "amzn_X_ti_seq_flatten = sequential_reshape(amzn_X_ti_seq, (len(amzn_X_seq), sequence_length, -1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training, validation, and testing (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full features\n",
    "aapl_X_train_full, aapl_X_test_full, aapl_y_train_full, aapl_y_test_full = train_test_split(aapl_X_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=False)\n",
    "aapl_X_train_full, aapl_X_valid_full, aapl_y_train_full, aapl_y_valid_full = train_test_split(aapl_X_train_full,\n",
    "                                                                                        aapl_y_train_full,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=False)\n",
    "msft_X_train_full, msft_X_test_full, msft_y_train_full, msft_y_test_full = train_test_split(msft_X_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=False)\n",
    "msft_X_train_full, msft_X_valid_full, msft_y_train_full, msft_y_valid_full = train_test_split(msft_X_train_full,\n",
    "                                                                                        msft_y_train_full,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=False)\n",
    "amzn_X_train_full, amzn_X_test_full, amzn_y_train_full, amzn_y_test_full = train_test_split(amzn_X_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "amzn_X_train_full, amzn_X_valid_full, amzn_y_train_full, amzn_y_valid_full = train_test_split(amzn_X_train_full,\n",
    "                                                                                        amzn_y_train_full,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(809, 60, 57, 1)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 60, 57, 1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_X_valid_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 60, 57, 1)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_X_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pca features\n",
    "aapl_X_train_pca, aapl_X_test_pca, aapl_y_train_pca, aapl_y_test_pca = train_test_split(aapl_X_pca_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "aapl_X_train_pca, aapl_X_valid_pca, aapl_y_train_pca, aapl_y_valid_pca = train_test_split(aapl_X_train_pca,\n",
    "                                                                                        aapl_y_train_pca,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "msft_X_train_pca, msft_X_test_pca, msft_y_train_pca, msft_y_test_pca = train_test_split(msft_X_pca_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "msft_X_train_pca, msft_X_valid_pca, msft_y_train_pca, msft_y_valid_pca = train_test_split(msft_X_train_pca,\n",
    "                                                                                        msft_y_train_pca,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "amzn_X_train_pca, amzn_X_test_pca, amzn_y_train_pca, amzn_y_test_pca = train_test_split(amzn_X_pca_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "amzn_X_train_pca, amzn_X_valid_pca, amzn_y_train_pca, amzn_y_valid_pca = train_test_split(amzn_X_train_pca,\n",
    "                                                                                        amzn_y_train_pca,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ti features\n",
    "aapl_X_train_ti, aapl_X_test_ti, aapl_y_train_ti, aapl_y_test_ti = train_test_split(aapl_X_ti_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "aapl_X_train_ti, aapl_X_valid_ti, aapl_y_train_ti, aapl_y_valid_ti = train_test_split(aapl_X_train_ti,\n",
    "                                                                                        aapl_y_train_ti,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "msft_X_train_ti, msft_X_test_ti, msft_y_train_ti, msft_y_test_ti = train_test_split(msft_X_ti_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "msft_X_train_ti, msft_X_valid_ti, msft_y_train_ti, msft_y_valid_ti = train_test_split(msft_X_train_ti,\n",
    "                                                                                        msft_y_train_ti,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "amzn_X_train_ti, amzn_X_test_ti, amzn_y_train_ti, amzn_y_test_ti = train_test_split(amzn_X_ti_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n",
    "amzn_X_train_ti, amzn_X_valid_ti, amzn_y_train_ti, amzn_y_valid_ti = train_test_split(amzn_X_train_ti,\n",
    "                                                                                        amzn_y_train_ti,\n",
    "                                                                                        stratify=None,\n",
    "                                                                                        test_size=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "# Train\n",
    "X_train_full = np.concatenate(\n",
    "    (aapl_X_train_full,\n",
    "     msft_X_train_full,\n",
    "     amzn_X_train_full,\n",
    "    )\n",
    ")\n",
    "y_train_full = np.concatenate(\n",
    "    (np.array(aapl_y_train_full),\n",
    "     np.array(msft_y_train_full),\n",
    "     np.array(amzn_y_train_full),\n",
    "     \n",
    "    )\n",
    ")\n",
    "\n",
    "# Valid\n",
    "X_valid_full = np.concatenate(\n",
    "    (aapl_X_valid_full,\n",
    "     msft_X_valid_full,\n",
    "     amzn_X_valid_full,\n",
    "     )\n",
    ")\n",
    "y_valid_full = np.concatenate(\n",
    "    (np.array(aapl_y_valid_full),\n",
    "     np.array(msft_y_valid_full),\n",
    "     np.array(amzn_y_valid_full),\n",
    "     \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca\n",
    "# Train\n",
    "X_train_pca = np.concatenate(\n",
    "    (aapl_X_train_pca,\n",
    "     msft_X_train_pca,\n",
    "     amzn_X_train_pca,\n",
    "    )\n",
    ")\n",
    "y_train_pca = np.concatenate(\n",
    "    (np.array(aapl_y_train_pca),\n",
    "     np.array(msft_y_train_pca),\n",
    "     np.array(amzn_y_train_pca),\n",
    "     \n",
    "    )\n",
    ")\n",
    "\n",
    "# Valid\n",
    "X_valid_pca = np.concatenate(\n",
    "    (aapl_X_valid_pca,\n",
    "     msft_X_valid_pca,\n",
    "     amzn_X_valid_pca,\n",
    "    )\n",
    ")\n",
    "y_valid_pca = np.concatenate(\n",
    "    (np.array(aapl_y_valid_pca),\n",
    "     np.array(msft_y_valid_pca),\n",
    "     np.array(amzn_y_valid_pca),\n",
    "     \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti\n",
    "# Train\n",
    "X_train_ti = np.concatenate(\n",
    "    (aapl_X_train_ti,\n",
    "     msft_X_train_ti,\n",
    "     amzn_X_train_ti,\n",
    "     )\n",
    ")\n",
    "y_train_ti = np.concatenate(\n",
    "    (np.array(aapl_y_train_ti),\n",
    "     np.array(msft_y_train_ti),\n",
    "     np.array(amzn_y_train_ti),\n",
    "     \n",
    "    )\n",
    ")\n",
    "\n",
    "# Valid\n",
    "X_valid_ti = np.concatenate(\n",
    "    (aapl_X_valid_ti,\n",
    "     msft_X_valid_ti,\n",
    "     amzn_X_valid_ti,\n",
    "     )\n",
    ")\n",
    "y_valid_ti = np.concatenate(\n",
    "    (np.array(aapl_y_valid_ti),\n",
    "     np.array(msft_y_valid_ti),\n",
    "     np.array(amzn_y_valid_ti),\n",
    "     \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"result_5_nam.txt\", \"a\")\n",
    "f.write(\"dsdsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 21ms/step - loss: 0.6909 - acc: 0.5521 - f1: 0.3604 - val_loss: 0.6910 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6878 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6933 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6878 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6880 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.6917 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6917 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6866 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6914 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5529 - f1: 0.3571 - val_loss: 0.6912 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6862 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6913 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6847 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6914 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6856 - acc: 0.5529 - f1: 0.3556 - val_loss: 0.6916 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6841 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.5534 - f1: 0.3570 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6839 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6833 - acc: 0.5546 - f1: 0.3625 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6837 - acc: 0.5558 - f1: 0.3722 - val_loss: 0.6913 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6819 - acc: 0.5558 - f1: 0.3716 - val_loss: 0.6913 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6843 - acc: 0.5591 - f1: 0.4306 - val_loss: 0.6907 - val_acc: 0.5444 - val_f1: 0.4670\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6815 - acc: 0.5558 - f1: 0.3707 - val_loss: 0.6903 - val_acc: 0.5333 - val_f1: 0.3896\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6796 - acc: 0.5595 - f1: 0.4012 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3473\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6785 - acc: 0.5616 - f1: 0.4295 - val_loss: 0.6916 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6787 - acc: 0.5591 - f1: 0.4536 - val_loss: 0.6900 - val_acc: 0.5630 - val_f1: 0.5343\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6795 - acc: 0.5562 - f1: 0.4540 - val_loss: 0.6889 - val_acc: 0.5667 - val_f1: 0.5454\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6777 - acc: 0.5661 - f1: 0.4523 - val_loss: 0.6886 - val_acc: 0.5481 - val_f1: 0.4714\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6767 - acc: 0.5653 - f1: 0.4855 - val_loss: 0.6882 - val_acc: 0.5519 - val_f1: 0.5328\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6742 - acc: 0.5665 - f1: 0.5028 - val_loss: 0.6892 - val_acc: 0.5481 - val_f1: 0.5704\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6737 - acc: 0.5793 - f1: 0.4951 - val_loss: 0.6877 - val_acc: 0.5111 - val_f1: 0.5223\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6738 - acc: 0.5752 - f1: 0.5125 - val_loss: 0.6865 - val_acc: 0.5556 - val_f1: 0.4935\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6723 - acc: 0.5822 - f1: 0.5259 - val_loss: 0.6862 - val_acc: 0.5444 - val_f1: 0.5206\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6703 - acc: 0.5830 - f1: 0.5185 - val_loss: 0.6900 - val_acc: 0.5407 - val_f1: 0.4696\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.5760 - f1: 0.5220 - val_loss: 0.6860 - val_acc: 0.5481 - val_f1: 0.5503\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6684 - acc: 0.5962 - f1: 0.5641 - val_loss: 0.6910 - val_acc: 0.5444 - val_f1: 0.5297\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6662 - acc: 0.5880 - f1: 0.5498 - val_loss: 0.6908 - val_acc: 0.5185 - val_f1: 0.5187\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.5946 - f1: 0.5566 - val_loss: 0.6893 - val_acc: 0.5333 - val_f1: 0.5039\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.5929 - f1: 0.5550 - val_loss: 0.6890 - val_acc: 0.5444 - val_f1: 0.5434\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6602 - acc: 0.5970 - f1: 0.5585 - val_loss: 0.6872 - val_acc: 0.5593 - val_f1: 0.5495\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6606 - acc: 0.6090 - f1: 0.5768 - val_loss: 0.6933 - val_acc: 0.5185 - val_f1: 0.5308\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6590 - acc: 0.6065 - f1: 0.5813 - val_loss: 0.6887 - val_acc: 0.5259 - val_f1: 0.5394\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6593 - acc: 0.5979 - f1: 0.5603 - val_loss: 0.6951 - val_acc: 0.5259 - val_f1: 0.5245\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6556 - acc: 0.6135 - f1: 0.5754 - val_loss: 0.6893 - val_acc: 0.5148 - val_f1: 0.5440\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6538 - acc: 0.6028 - f1: 0.5750 - val_loss: 0.6888 - val_acc: 0.5259 - val_f1: 0.5555\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6554 - acc: 0.6024 - f1: 0.5849 - val_loss: 0.6852 - val_acc: 0.5481 - val_f1: 0.5630\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6543 - acc: 0.6106 - f1: 0.5820 - val_loss: 0.6840 - val_acc: 0.5481 - val_f1: 0.5573\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6462 - acc: 0.6251 - f1: 0.5993 - val_loss: 0.6872 - val_acc: 0.5444 - val_f1: 0.5627\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6465 - acc: 0.6160 - f1: 0.5885 - val_loss: 0.6861 - val_acc: 0.5370 - val_f1: 0.5456\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6477 - acc: 0.6168 - f1: 0.5953 - val_loss: 0.6892 - val_acc: 0.5630 - val_f1: 0.5534\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6489 - acc: 0.6185 - f1: 0.6014 - val_loss: 0.6899 - val_acc: 0.5481 - val_f1: 0.5359\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6444 - acc: 0.6119 - f1: 0.5819 - val_loss: 0.6860 - val_acc: 0.5630 - val_f1: 0.5703\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6437 - acc: 0.6259 - f1: 0.6030 - val_loss: 0.6857 - val_acc: 0.5556 - val_f1: 0.5702\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6393 - acc: 0.6230 - f1: 0.6008 - val_loss: 0.6862 - val_acc: 0.5593 - val_f1: 0.5563\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6392 - acc: 0.6341 - f1: 0.6184 - val_loss: 0.6835 - val_acc: 0.5370 - val_f1: 0.5519\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6369 - acc: 0.6337 - f1: 0.6175 - val_loss: 0.6841 - val_acc: 0.5481 - val_f1: 0.5684\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6379 - acc: 0.6349 - f1: 0.6129 - val_loss: 0.6884 - val_acc: 0.5667 - val_f1: 0.5605\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6316 - acc: 0.6465 - f1: 0.6252 - val_loss: 0.6864 - val_acc: 0.5519 - val_f1: 0.5470\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6301 - acc: 0.6403 - f1: 0.6230 - val_loss: 0.6858 - val_acc: 0.5407 - val_f1: 0.5683\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6289 - acc: 0.6457 - f1: 0.6318 - val_loss: 0.6876 - val_acc: 0.5185 - val_f1: 0.5359\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6229 - acc: 0.6502 - f1: 0.6302 - val_loss: 0.6870 - val_acc: 0.5222 - val_f1: 0.5569\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6247 - acc: 0.6535 - f1: 0.6402 - val_loss: 0.6885 - val_acc: 0.5704 - val_f1: 0.5671\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6221 - acc: 0.6613 - f1: 0.6405 - val_loss: 0.6867 - val_acc: 0.5222 - val_f1: 0.5535\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6210 - acc: 0.6461 - f1: 0.6343 - val_loss: 0.6879 - val_acc: 0.5296 - val_f1: 0.5597\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6194 - acc: 0.6547 - f1: 0.6371 - val_loss: 0.6839 - val_acc: 0.5370 - val_f1: 0.5669\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6198 - acc: 0.6452 - f1: 0.6359 - val_loss: 0.6832 - val_acc: 0.5593 - val_f1: 0.5563\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6197 - acc: 0.6580 - f1: 0.6391 - val_loss: 0.6911 - val_acc: 0.5296 - val_f1: 0.5617\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6181 - acc: 0.6465 - f1: 0.6301 - val_loss: 0.6843 - val_acc: 0.5667 - val_f1: 0.5798\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6106 - acc: 0.6675 - f1: 0.6567 - val_loss: 0.6861 - val_acc: 0.5630 - val_f1: 0.5735\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6118 - acc: 0.6601 - f1: 0.6408 - val_loss: 0.6879 - val_acc: 0.5259 - val_f1: 0.5561\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6080 - acc: 0.6683 - f1: 0.6587 - val_loss: 0.6836 - val_acc: 0.5444 - val_f1: 0.5643\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6055 - acc: 0.6683 - f1: 0.6578 - val_loss: 0.6886 - val_acc: 0.5704 - val_f1: 0.5833\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6057 - acc: 0.6803 - f1: 0.6646 - val_loss: 0.6853 - val_acc: 0.5333 - val_f1: 0.5614\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6069 - acc: 0.6724 - f1: 0.6600 - val_loss: 0.6882 - val_acc: 0.5444 - val_f1: 0.5574\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5998 - acc: 0.6770 - f1: 0.6675 - val_loss: 0.6884 - val_acc: 0.5370 - val_f1: 0.5460\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5975 - acc: 0.6728 - f1: 0.6547 - val_loss: 0.6860 - val_acc: 0.5481 - val_f1: 0.5679\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6008 - acc: 0.6741 - f1: 0.6629 - val_loss: 0.6885 - val_acc: 0.5593 - val_f1: 0.5755\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5884 - acc: 0.6873 - f1: 0.6787 - val_loss: 0.6937 - val_acc: 0.5519 - val_f1: 0.5696\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5864 - acc: 0.6885 - f1: 0.6754 - val_loss: 0.6924 - val_acc: 0.5667 - val_f1: 0.5818\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5905 - acc: 0.6790 - f1: 0.6674 - val_loss: 0.6862 - val_acc: 0.5185 - val_f1: 0.5481\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5899 - acc: 0.6794 - f1: 0.6669 - val_loss: 0.6898 - val_acc: 0.5481 - val_f1: 0.5675\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5846 - acc: 0.6873 - f1: 0.6760 - val_loss: 0.6917 - val_acc: 0.5519 - val_f1: 0.5549\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5852 - acc: 0.6906 - f1: 0.6781 - val_loss: 0.6920 - val_acc: 0.5370 - val_f1: 0.5570\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5775 - acc: 0.6893 - f1: 0.6779 - val_loss: 0.6880 - val_acc: 0.5667 - val_f1: 0.5796\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5733 - acc: 0.6914 - f1: 0.6801 - val_loss: 0.6993 - val_acc: 0.5630 - val_f1: 0.5669\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5715 - acc: 0.7017 - f1: 0.6944 - val_loss: 0.7009 - val_acc: 0.5444 - val_f1: 0.5668\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5768 - acc: 0.6972 - f1: 0.6838 - val_loss: 0.6948 - val_acc: 0.5704 - val_f1: 0.5812\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5706 - acc: 0.6988 - f1: 0.6906 - val_loss: 0.6935 - val_acc: 0.5519 - val_f1: 0.5756\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5708 - acc: 0.6996 - f1: 0.6874 - val_loss: 0.7058 - val_acc: 0.5519 - val_f1: 0.5755\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5688 - acc: 0.7025 - f1: 0.6923 - val_loss: 0.7145 - val_acc: 0.5778 - val_f1: 0.6008\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5642 - acc: 0.7050 - f1: 0.6941 - val_loss: 0.7014 - val_acc: 0.5444 - val_f1: 0.5889\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5624 - acc: 0.6976 - f1: 0.6890 - val_loss: 0.6950 - val_acc: 0.5481 - val_f1: 0.5666\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5574 - acc: 0.7141 - f1: 0.7038 - val_loss: 0.7096 - val_acc: 0.5556 - val_f1: 0.5696\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5584 - acc: 0.7087 - f1: 0.7008 - val_loss: 0.7019 - val_acc: 0.5556 - val_f1: 0.5995\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5537 - acc: 0.7169 - f1: 0.7076 - val_loss: 0.7064 - val_acc: 0.5481 - val_f1: 0.5717\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5570 - acc: 0.7198 - f1: 0.7128 - val_loss: 0.7093 - val_acc: 0.5259 - val_f1: 0.5498\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5472 - acc: 0.7099 - f1: 0.7022 - val_loss: 0.7155 - val_acc: 0.5259 - val_f1: 0.5507\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5477 - acc: 0.7182 - f1: 0.7100 - val_loss: 0.7146 - val_acc: 0.5407 - val_f1: 0.5809\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5461 - acc: 0.7173 - f1: 0.7084 - val_loss: 0.7163 - val_acc: 0.5370 - val_f1: 0.5856\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5542 - acc: 0.7091 - f1: 0.7000 - val_loss: 0.7094 - val_acc: 0.5296 - val_f1: 0.5511\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5403 - acc: 0.7305 - f1: 0.7240 - val_loss: 0.7133 - val_acc: 0.5333 - val_f1: 0.5577\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5364 - acc: 0.7215 - f1: 0.7104 - val_loss: 0.7189 - val_acc: 0.5148 - val_f1: 0.5463\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5350 - acc: 0.7371 - f1: 0.7306 - val_loss: 0.7113 - val_acc: 0.5444 - val_f1: 0.5637\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5419 - acc: 0.7256 - f1: 0.7160 - val_loss: 0.7228 - val_acc: 0.5593 - val_f1: 0.5908\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5358 - acc: 0.7363 - f1: 0.7296 - val_loss: 0.7130 - val_acc: 0.5185 - val_f1: 0.5727\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5288 - acc: 0.7281 - f1: 0.7201 - val_loss: 0.7177 - val_acc: 0.5148 - val_f1: 0.5653\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5319 - acc: 0.7256 - f1: 0.7186 - val_loss: 0.7198 - val_acc: 0.5333 - val_f1: 0.5599\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5328 - acc: 0.7359 - f1: 0.7287 - val_loss: 0.7279 - val_acc: 0.5333 - val_f1: 0.5744\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5310 - acc: 0.7227 - f1: 0.7142 - val_loss: 0.7284 - val_acc: 0.5333 - val_f1: 0.6030\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5392 - acc: 0.7206 - f1: 0.7123 - val_loss: 0.7249 - val_acc: 0.5259 - val_f1: 0.5972\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5241 - acc: 0.7359 - f1: 0.7286 - val_loss: 0.7266 - val_acc: 0.5037 - val_f1: 0.5568\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5177 - acc: 0.7499 - f1: 0.7423 - val_loss: 0.7292 - val_acc: 0.5222 - val_f1: 0.5900\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5141 - acc: 0.7400 - f1: 0.7334 - val_loss: 0.7223 - val_acc: 0.5222 - val_f1: 0.5976\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5044 - acc: 0.7507 - f1: 0.7456 - val_loss: 0.7417 - val_acc: 0.5444 - val_f1: 0.5786\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5156 - acc: 0.7412 - f1: 0.7340 - val_loss: 0.7336 - val_acc: 0.5370 - val_f1: 0.6054\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5177 - acc: 0.7412 - f1: 0.7333 - val_loss: 0.7261 - val_acc: 0.5185 - val_f1: 0.5952\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4969 - acc: 0.7660 - f1: 0.7598 - val_loss: 0.7308 - val_acc: 0.5185 - val_f1: 0.5676\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5117 - acc: 0.7507 - f1: 0.7446 - val_loss: 0.7465 - val_acc: 0.5185 - val_f1: 0.5657\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5035 - acc: 0.7507 - f1: 0.7446 - val_loss: 0.7362 - val_acc: 0.5148 - val_f1: 0.5671\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5042 - acc: 0.7482 - f1: 0.7426 - val_loss: 0.7465 - val_acc: 0.5148 - val_f1: 0.5896\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5073 - acc: 0.7557 - f1: 0.7486 - val_loss: 0.7285 - val_acc: 0.5296 - val_f1: 0.6007\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4875 - acc: 0.7651 - f1: 0.7583 - val_loss: 0.7456 - val_acc: 0.5259 - val_f1: 0.5941\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5049 - acc: 0.7573 - f1: 0.7497 - val_loss: 0.7471 - val_acc: 0.5222 - val_f1: 0.5953\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4935 - acc: 0.7573 - f1: 0.7491 - val_loss: 0.7635 - val_acc: 0.5222 - val_f1: 0.6087\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5030 - acc: 0.7511 - f1: 0.7448 - val_loss: 0.7455 - val_acc: 0.5259 - val_f1: 0.5955\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4954 - acc: 0.7627 - f1: 0.7550 - val_loss: 0.7467 - val_acc: 0.5148 - val_f1: 0.5902\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4913 - acc: 0.7631 - f1: 0.7570 - val_loss: 0.7427 - val_acc: 0.5259 - val_f1: 0.5957\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4940 - acc: 0.7631 - f1: 0.7571 - val_loss: 0.7415 - val_acc: 0.5296 - val_f1: 0.6000\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4886 - acc: 0.7705 - f1: 0.7650 - val_loss: 0.7669 - val_acc: 0.5074 - val_f1: 0.5604\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4864 - acc: 0.7656 - f1: 0.7600 - val_loss: 0.7517 - val_acc: 0.5296 - val_f1: 0.5987\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4863 - acc: 0.7585 - f1: 0.7516 - val_loss: 0.7653 - val_acc: 0.5111 - val_f1: 0.5815\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4813 - acc: 0.7548 - f1: 0.7503 - val_loss: 0.7564 - val_acc: 0.5148 - val_f1: 0.5896\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4753 - acc: 0.7660 - f1: 0.7597 - val_loss: 0.7643 - val_acc: 0.5259 - val_f1: 0.5786\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4907 - acc: 0.7557 - f1: 0.7476 - val_loss: 0.7455 - val_acc: 0.5222 - val_f1: 0.5919\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4831 - acc: 0.7631 - f1: 0.7590 - val_loss: 0.7539 - val_acc: 0.5185 - val_f1: 0.5932\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4806 - acc: 0.7680 - f1: 0.7619 - val_loss: 0.7591 - val_acc: 0.5111 - val_f1: 0.5388\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4800 - acc: 0.7647 - f1: 0.7606 - val_loss: 0.7649 - val_acc: 0.5037 - val_f1: 0.5581\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4745 - acc: 0.7647 - f1: 0.7576 - val_loss: 0.7655 - val_acc: 0.4963 - val_f1: 0.5542\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4699 - acc: 0.7750 - f1: 0.7708 - val_loss: 0.7663 - val_acc: 0.5296 - val_f1: 0.5764\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4813 - acc: 0.7660 - f1: 0.7609 - val_loss: 0.7498 - val_acc: 0.5074 - val_f1: 0.5793\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4737 - acc: 0.7771 - f1: 0.7726 - val_loss: 0.7568 - val_acc: 0.5037 - val_f1: 0.5581\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4684 - acc: 0.7754 - f1: 0.7705 - val_loss: 0.7718 - val_acc: 0.5185 - val_f1: 0.5675\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4716 - acc: 0.7763 - f1: 0.7716 - val_loss: 0.7586 - val_acc: 0.5185 - val_f1: 0.5454\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4706 - acc: 0.7684 - f1: 0.7640 - val_loss: 0.7618 - val_acc: 0.5148 - val_f1: 0.5895\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4530 - acc: 0.7923 - f1: 0.7868 - val_loss: 0.7650 - val_acc: 0.5333 - val_f1: 0.6037\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4618 - acc: 0.7812 - f1: 0.7773 - val_loss: 0.7645 - val_acc: 0.5370 - val_f1: 0.6033\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4576 - acc: 0.7853 - f1: 0.7804 - val_loss: 0.7741 - val_acc: 0.5074 - val_f1: 0.5394\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4597 - acc: 0.7903 - f1: 0.7855 - val_loss: 0.7681 - val_acc: 0.5111 - val_f1: 0.5618\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4501 - acc: 0.7878 - f1: 0.7822 - val_loss: 0.7681 - val_acc: 0.5148 - val_f1: 0.5677\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4521 - acc: 0.7816 - f1: 0.7767 - val_loss: 0.7666 - val_acc: 0.5148 - val_f1: 0.5640\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4525 - acc: 0.7878 - f1: 0.7837 - val_loss: 0.7704 - val_acc: 0.5148 - val_f1: 0.5692\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4567 - acc: 0.7812 - f1: 0.7769 - val_loss: 0.7608 - val_acc: 0.5296 - val_f1: 0.5794\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4531 - acc: 0.7907 - f1: 0.7867 - val_loss: 0.7762 - val_acc: 0.5222 - val_f1: 0.5976\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4430 - acc: 0.7973 - f1: 0.7920 - val_loss: 0.7679 - val_acc: 0.5259 - val_f1: 0.5977\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4474 - acc: 0.7870 - f1: 0.7827 - val_loss: 0.7715 - val_acc: 0.5333 - val_f1: 0.6030\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4443 - acc: 0.7936 - f1: 0.7889 - val_loss: 0.7800 - val_acc: 0.5185 - val_f1: 0.5904\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4512 - acc: 0.7800 - f1: 0.7753 - val_loss: 0.7728 - val_acc: 0.5259 - val_f1: 0.5760\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4446 - acc: 0.7911 - f1: 0.7863 - val_loss: 0.7782 - val_acc: 0.5370 - val_f1: 0.6033\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4388 - acc: 0.7952 - f1: 0.7896 - val_loss: 0.7775 - val_acc: 0.5407 - val_f1: 0.6101\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4471 - acc: 0.7956 - f1: 0.7909 - val_loss: 0.7813 - val_acc: 0.5519 - val_f1: 0.5941\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4437 - acc: 0.8002 - f1: 0.7944 - val_loss: 0.7846 - val_acc: 0.5370 - val_f1: 0.6048\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4450 - acc: 0.7849 - f1: 0.7798 - val_loss: 0.7890 - val_acc: 0.5074 - val_f1: 0.5856\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4379 - acc: 0.7911 - f1: 0.7855 - val_loss: 0.7981 - val_acc: 0.5370 - val_f1: 0.5756\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4363 - acc: 0.7907 - f1: 0.7847 - val_loss: 0.7823 - val_acc: 0.5370 - val_f1: 0.6072\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4413 - acc: 0.7944 - f1: 0.7887 - val_loss: 0.7878 - val_acc: 0.5222 - val_f1: 0.5934\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4345 - acc: 0.7981 - f1: 0.7932 - val_loss: 0.7972 - val_acc: 0.5222 - val_f1: 0.5955\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.6902 - acc: 0.5447 - f1: 0.3612 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5534 - f1: 0.3568 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6886 - acc: 0.5534 - f1: 0.3575 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6882 - acc: 0.5558 - f1: 0.3868 - val_loss: 0.6953 - val_acc: 0.4704 - val_f1: 0.3239\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6876 - acc: 0.5529 - f1: 0.3705 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6868 - acc: 0.5538 - f1: 0.3627 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6861 - acc: 0.5534 - f1: 0.3744 - val_loss: 0.6952 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5534 - f1: 0.3749 - val_loss: 0.6933 - val_acc: 0.5259 - val_f1: 0.3413\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5558 - f1: 0.3829 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6861 - acc: 0.5525 - f1: 0.3809 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5534 - f1: 0.4337 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6866 - acc: 0.5472 - f1: 0.4137 - val_loss: 0.6952 - val_acc: 0.4815 - val_f1: 0.4079\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5546 - f1: 0.4047 - val_loss: 0.6944 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6844 - acc: 0.5546 - f1: 0.4092 - val_loss: 0.6954 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6833 - acc: 0.5575 - f1: 0.4168 - val_loss: 0.6960 - val_acc: 0.5185 - val_f1: 0.3732\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6831 - acc: 0.5645 - f1: 0.4319 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5637 - f1: 0.4459 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6825 - acc: 0.5641 - f1: 0.4450 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6814 - acc: 0.5632 - f1: 0.4636 - val_loss: 0.6935 - val_acc: 0.5222 - val_f1: 0.3448\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6798 - acc: 0.5694 - f1: 0.4828 - val_loss: 0.6957 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5620 - f1: 0.4517 - val_loss: 0.6936 - val_acc: 0.5333 - val_f1: 0.4230\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6803 - acc: 0.5731 - f1: 0.4992 - val_loss: 0.6914 - val_acc: 0.5296 - val_f1: 0.3730\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6794 - acc: 0.5690 - f1: 0.4717 - val_loss: 0.6950 - val_acc: 0.5037 - val_f1: 0.3985\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6787 - acc: 0.5661 - f1: 0.4879 - val_loss: 0.6934 - val_acc: 0.5519 - val_f1: 0.3941\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.5682 - f1: 0.4972 - val_loss: 0.6873 - val_acc: 0.5185 - val_f1: 0.3436\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6744 - acc: 0.5740 - f1: 0.4956 - val_loss: 0.6955 - val_acc: 0.5259 - val_f1: 0.3413\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6773 - acc: 0.5645 - f1: 0.4992 - val_loss: 0.6948 - val_acc: 0.5148 - val_f1: 0.4866\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6779 - acc: 0.5731 - f1: 0.5170 - val_loss: 0.6934 - val_acc: 0.5074 - val_f1: 0.3968\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6754 - acc: 0.5764 - f1: 0.5055 - val_loss: 0.6881 - val_acc: 0.5222 - val_f1: 0.4505\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6770 - acc: 0.5822 - f1: 0.5484 - val_loss: 0.6907 - val_acc: 0.5333 - val_f1: 0.3787\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6748 - acc: 0.5735 - f1: 0.4805 - val_loss: 0.6896 - val_acc: 0.5481 - val_f1: 0.4784\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6742 - acc: 0.5843 - f1: 0.5459 - val_loss: 0.6948 - val_acc: 0.5074 - val_f1: 0.3606\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6738 - acc: 0.5756 - f1: 0.5050 - val_loss: 0.6915 - val_acc: 0.5148 - val_f1: 0.4583\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6727 - acc: 0.5768 - f1: 0.5267 - val_loss: 0.6914 - val_acc: 0.5333 - val_f1: 0.4218\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6675 - acc: 0.5830 - f1: 0.5321 - val_loss: 0.6938 - val_acc: 0.5333 - val_f1: 0.3778\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.5876 - f1: 0.5528 - val_loss: 0.6937 - val_acc: 0.5185 - val_f1: 0.4503\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6669 - acc: 0.5855 - f1: 0.5333 - val_loss: 0.6908 - val_acc: 0.5259 - val_f1: 0.4528\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6646 - acc: 0.6036 - f1: 0.5694 - val_loss: 0.6964 - val_acc: 0.5370 - val_f1: 0.4318\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6721 - acc: 0.5744 - f1: 0.5138 - val_loss: 0.6925 - val_acc: 0.5259 - val_f1: 0.4459\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6695 - acc: 0.5814 - f1: 0.5393 - val_loss: 0.6880 - val_acc: 0.5370 - val_f1: 0.4251\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6657 - acc: 0.5946 - f1: 0.5571 - val_loss: 0.6914 - val_acc: 0.5407 - val_f1: 0.4184\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6669 - acc: 0.5904 - f1: 0.5539 - val_loss: 0.6928 - val_acc: 0.5370 - val_f1: 0.4667\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6693 - acc: 0.5843 - f1: 0.5522 - val_loss: 0.7016 - val_acc: 0.5444 - val_f1: 0.4177\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6693 - acc: 0.5789 - f1: 0.5427 - val_loss: 0.6897 - val_acc: 0.5444 - val_f1: 0.4746\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6636 - acc: 0.5909 - f1: 0.5556 - val_loss: 0.6929 - val_acc: 0.5185 - val_f1: 0.4576\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6589 - acc: 0.6073 - f1: 0.5743 - val_loss: 0.6962 - val_acc: 0.5296 - val_f1: 0.4304\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6628 - acc: 0.5933 - f1: 0.5453 - val_loss: 0.6897 - val_acc: 0.5259 - val_f1: 0.4670\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6643 - acc: 0.5954 - f1: 0.5776 - val_loss: 0.6970 - val_acc: 0.5444 - val_f1: 0.4524\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6623 - acc: 0.5970 - f1: 0.5567 - val_loss: 0.6937 - val_acc: 0.5333 - val_f1: 0.4534\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6597 - acc: 0.6032 - f1: 0.5744 - val_loss: 0.6955 - val_acc: 0.5333 - val_f1: 0.4836\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6556 - acc: 0.5991 - f1: 0.5672 - val_loss: 0.6909 - val_acc: 0.5407 - val_f1: 0.5128\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6570 - acc: 0.5987 - f1: 0.5707 - val_loss: 0.6987 - val_acc: 0.5296 - val_f1: 0.4855\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6578 - acc: 0.6028 - f1: 0.5676 - val_loss: 0.6950 - val_acc: 0.5185 - val_f1: 0.4294\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6510 - acc: 0.6115 - f1: 0.5878 - val_loss: 0.6945 - val_acc: 0.5185 - val_f1: 0.4441\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6495 - acc: 0.6131 - f1: 0.5849 - val_loss: 0.6959 - val_acc: 0.5259 - val_f1: 0.5257\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6473 - acc: 0.6156 - f1: 0.5952 - val_loss: 0.6969 - val_acc: 0.5185 - val_f1: 0.4492\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6492 - acc: 0.6259 - f1: 0.5986 - val_loss: 0.7055 - val_acc: 0.5111 - val_f1: 0.4264\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6479 - acc: 0.6110 - f1: 0.5887 - val_loss: 0.6955 - val_acc: 0.5222 - val_f1: 0.4681\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6470 - acc: 0.6180 - f1: 0.5887 - val_loss: 0.6947 - val_acc: 0.5333 - val_f1: 0.4727\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6431 - acc: 0.6209 - f1: 0.6016 - val_loss: 0.7039 - val_acc: 0.5148 - val_f1: 0.4124\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6384 - acc: 0.6288 - f1: 0.6059 - val_loss: 0.7040 - val_acc: 0.5296 - val_f1: 0.4851\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6404 - acc: 0.6271 - f1: 0.6033 - val_loss: 0.7063 - val_acc: 0.5037 - val_f1: 0.4592\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6377 - acc: 0.6308 - f1: 0.6136 - val_loss: 0.7049 - val_acc: 0.5407 - val_f1: 0.5074\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6367 - acc: 0.6333 - f1: 0.6126 - val_loss: 0.7045 - val_acc: 0.5185 - val_f1: 0.4864\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6362 - acc: 0.6366 - f1: 0.6150 - val_loss: 0.7080 - val_acc: 0.5296 - val_f1: 0.4563\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6414 - acc: 0.6267 - f1: 0.6087 - val_loss: 0.7048 - val_acc: 0.5296 - val_f1: 0.4708\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6347 - acc: 0.6321 - f1: 0.6158 - val_loss: 0.7047 - val_acc: 0.5185 - val_f1: 0.4395\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6327 - acc: 0.6308 - f1: 0.6150 - val_loss: 0.7059 - val_acc: 0.5074 - val_f1: 0.4925\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6330 - acc: 0.6242 - f1: 0.6004 - val_loss: 0.7110 - val_acc: 0.5074 - val_f1: 0.4757\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6327 - acc: 0.6403 - f1: 0.6241 - val_loss: 0.7059 - val_acc: 0.5259 - val_f1: 0.5038\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6222 - acc: 0.6498 - f1: 0.6317 - val_loss: 0.7087 - val_acc: 0.5259 - val_f1: 0.4913\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6238 - acc: 0.6485 - f1: 0.6323 - val_loss: 0.7195 - val_acc: 0.5111 - val_f1: 0.4773\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6304 - acc: 0.6382 - f1: 0.6217 - val_loss: 0.7012 - val_acc: 0.5370 - val_f1: 0.5287\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6272 - acc: 0.6477 - f1: 0.6306 - val_loss: 0.7143 - val_acc: 0.5370 - val_f1: 0.5158\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6165 - acc: 0.6510 - f1: 0.6367 - val_loss: 0.7138 - val_acc: 0.5148 - val_f1: 0.4249\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6169 - acc: 0.6547 - f1: 0.6380 - val_loss: 0.7112 - val_acc: 0.5259 - val_f1: 0.4986\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6159 - acc: 0.6593 - f1: 0.6443 - val_loss: 0.7243 - val_acc: 0.5296 - val_f1: 0.4857\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6084 - acc: 0.6687 - f1: 0.6557 - val_loss: 0.7210 - val_acc: 0.5259 - val_f1: 0.5013\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6169 - acc: 0.6527 - f1: 0.6400 - val_loss: 0.7228 - val_acc: 0.5148 - val_f1: 0.4219\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6103 - acc: 0.6687 - f1: 0.6528 - val_loss: 0.7228 - val_acc: 0.5185 - val_f1: 0.4978\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6127 - acc: 0.6646 - f1: 0.6525 - val_loss: 0.7263 - val_acc: 0.5259 - val_f1: 0.4984\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6033 - acc: 0.6679 - f1: 0.6533 - val_loss: 0.7237 - val_acc: 0.5185 - val_f1: 0.4880\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6070 - acc: 0.6654 - f1: 0.6551 - val_loss: 0.7309 - val_acc: 0.5074 - val_f1: 0.4247\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6053 - acc: 0.6691 - f1: 0.6578 - val_loss: 0.7251 - val_acc: 0.5259 - val_f1: 0.5109\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6043 - acc: 0.6576 - f1: 0.6435 - val_loss: 0.7177 - val_acc: 0.5111 - val_f1: 0.5076\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5971 - acc: 0.6799 - f1: 0.6692 - val_loss: 0.7394 - val_acc: 0.5148 - val_f1: 0.4960\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5993 - acc: 0.6811 - f1: 0.6704 - val_loss: 0.7471 - val_acc: 0.5111 - val_f1: 0.4941\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6039 - acc: 0.6601 - f1: 0.6444 - val_loss: 0.7324 - val_acc: 0.5037 - val_f1: 0.5114\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5908 - acc: 0.6836 - f1: 0.6735 - val_loss: 0.7357 - val_acc: 0.5185 - val_f1: 0.5155\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5944 - acc: 0.6848 - f1: 0.6751 - val_loss: 0.7350 - val_acc: 0.5148 - val_f1: 0.5095\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5919 - acc: 0.6893 - f1: 0.6771 - val_loss: 0.7401 - val_acc: 0.5000 - val_f1: 0.5041\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5959 - acc: 0.6753 - f1: 0.6656 - val_loss: 0.7373 - val_acc: 0.5222 - val_f1: 0.5156\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5870 - acc: 0.6906 - f1: 0.6806 - val_loss: 0.7349 - val_acc: 0.5037 - val_f1: 0.4790\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5805 - acc: 0.6893 - f1: 0.6758 - val_loss: 0.7448 - val_acc: 0.5037 - val_f1: 0.4999\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5822 - acc: 0.6864 - f1: 0.6773 - val_loss: 0.7380 - val_acc: 0.5333 - val_f1: 0.4877\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5855 - acc: 0.6873 - f1: 0.6745 - val_loss: 0.7503 - val_acc: 0.5037 - val_f1: 0.4415\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5866 - acc: 0.6877 - f1: 0.6789 - val_loss: 0.7433 - val_acc: 0.5037 - val_f1: 0.5113\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5757 - acc: 0.6967 - f1: 0.6864 - val_loss: 0.7591 - val_acc: 0.5111 - val_f1: 0.4962\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5754 - acc: 0.7058 - f1: 0.6974 - val_loss: 0.7699 - val_acc: 0.5111 - val_f1: 0.4722\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5752 - acc: 0.7013 - f1: 0.6919 - val_loss: 0.7484 - val_acc: 0.5111 - val_f1: 0.4864\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5732 - acc: 0.6996 - f1: 0.6905 - val_loss: 0.7688 - val_acc: 0.4963 - val_f1: 0.4499\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5715 - acc: 0.7120 - f1: 0.7030 - val_loss: 0.7690 - val_acc: 0.5148 - val_f1: 0.4935\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5642 - acc: 0.7103 - f1: 0.7003 - val_loss: 0.7599 - val_acc: 0.5148 - val_f1: 0.5238\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5720 - acc: 0.6955 - f1: 0.6873 - val_loss: 0.7693 - val_acc: 0.5148 - val_f1: 0.5493\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5639 - acc: 0.7083 - f1: 0.6987 - val_loss: 0.7713 - val_acc: 0.5037 - val_f1: 0.5385\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5704 - acc: 0.6963 - f1: 0.6889 - val_loss: 0.7627 - val_acc: 0.5222 - val_f1: 0.5191\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5611 - acc: 0.7124 - f1: 0.7028 - val_loss: 0.7677 - val_acc: 0.5111 - val_f1: 0.5441\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5599 - acc: 0.7103 - f1: 0.7022 - val_loss: 0.7832 - val_acc: 0.5074 - val_f1: 0.4272\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5538 - acc: 0.7157 - f1: 0.7068 - val_loss: 0.7939 - val_acc: 0.5148 - val_f1: 0.4915\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5577 - acc: 0.7050 - f1: 0.6970 - val_loss: 0.7809 - val_acc: 0.5037 - val_f1: 0.4904\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5490 - acc: 0.7190 - f1: 0.7096 - val_loss: 0.7891 - val_acc: 0.5222 - val_f1: 0.5062\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5477 - acc: 0.7264 - f1: 0.7195 - val_loss: 0.8095 - val_acc: 0.5148 - val_f1: 0.4512\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5571 - acc: 0.7079 - f1: 0.6996 - val_loss: 0.8028 - val_acc: 0.5111 - val_f1: 0.4564\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5528 - acc: 0.7099 - f1: 0.7021 - val_loss: 0.7783 - val_acc: 0.5222 - val_f1: 0.5603\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5527 - acc: 0.7149 - f1: 0.7081 - val_loss: 0.7718 - val_acc: 0.5111 - val_f1: 0.4742\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5409 - acc: 0.7239 - f1: 0.7149 - val_loss: 0.7743 - val_acc: 0.5111 - val_f1: 0.5296\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5465 - acc: 0.7244 - f1: 0.7167 - val_loss: 0.8077 - val_acc: 0.5222 - val_f1: 0.5291\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5405 - acc: 0.7338 - f1: 0.7265 - val_loss: 0.7845 - val_acc: 0.5222 - val_f1: 0.5211\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5436 - acc: 0.7252 - f1: 0.7184 - val_loss: 0.7942 - val_acc: 0.5333 - val_f1: 0.4777\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5477 - acc: 0.7128 - f1: 0.7052 - val_loss: 0.7857 - val_acc: 0.5407 - val_f1: 0.5260\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5316 - acc: 0.7338 - f1: 0.7246 - val_loss: 0.8009 - val_acc: 0.5037 - val_f1: 0.5211\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5326 - acc: 0.7293 - f1: 0.7229 - val_loss: 0.8034 - val_acc: 0.5296 - val_f1: 0.5644\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5371 - acc: 0.7235 - f1: 0.7157 - val_loss: 0.7841 - val_acc: 0.5074 - val_f1: 0.5514\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5362 - acc: 0.7305 - f1: 0.7239 - val_loss: 0.7911 - val_acc: 0.5185 - val_f1: 0.5576\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5345 - acc: 0.7301 - f1: 0.7232 - val_loss: 0.8023 - val_acc: 0.5185 - val_f1: 0.5288\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.6888 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.6903 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6884 - acc: 0.5529 - f1: 0.3555 - val_loss: 0.6920 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6876 - acc: 0.5554 - f1: 0.3678 - val_loss: 0.6938 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5538 - f1: 0.3567 - val_loss: 0.6908 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6874 - acc: 0.5550 - f1: 0.3606 - val_loss: 0.6916 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5534 - f1: 0.3622 - val_loss: 0.6944 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6845 - acc: 0.5534 - f1: 0.3574 - val_loss: 0.6907 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6850 - acc: 0.5529 - f1: 0.3689 - val_loss: 0.6957 - val_acc: 0.4704 - val_f1: 0.3870\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6850 - acc: 0.5476 - f1: 0.3923 - val_loss: 0.6949 - val_acc: 0.4704 - val_f1: 0.3239\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6849 - acc: 0.5538 - f1: 0.4166 - val_loss: 0.6914 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6835 - acc: 0.5538 - f1: 0.3659 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6831 - acc: 0.5521 - f1: 0.3561 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5534 - f1: 0.3782 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6830 - acc: 0.5579 - f1: 0.4161 - val_loss: 0.6924 - val_acc: 0.5296 - val_f1: 0.3473\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6809 - acc: 0.5492 - f1: 0.4067 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6797 - acc: 0.5534 - f1: 0.4018 - val_loss: 0.6933 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6791 - acc: 0.5628 - f1: 0.4574 - val_loss: 0.6933 - val_acc: 0.5185 - val_f1: 0.3803\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6785 - acc: 0.5649 - f1: 0.4449 - val_loss: 0.6945 - val_acc: 0.5259 - val_f1: 0.3552\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6760 - acc: 0.5674 - f1: 0.4834 - val_loss: 0.6904 - val_acc: 0.5333 - val_f1: 0.3624\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6755 - acc: 0.5591 - f1: 0.4717 - val_loss: 0.6944 - val_acc: 0.4963 - val_f1: 0.4230\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6764 - acc: 0.5583 - f1: 0.4812 - val_loss: 0.6929 - val_acc: 0.5148 - val_f1: 0.4441\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6751 - acc: 0.5645 - f1: 0.4992 - val_loss: 0.6911 - val_acc: 0.5370 - val_f1: 0.4146\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.5727 - f1: 0.4891 - val_loss: 0.6951 - val_acc: 0.4556 - val_f1: 0.4132\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6721 - acc: 0.5797 - f1: 0.5351 - val_loss: 0.6936 - val_acc: 0.5222 - val_f1: 0.4495\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6729 - acc: 0.5789 - f1: 0.5167 - val_loss: 0.6932 - val_acc: 0.4926 - val_f1: 0.4206\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6729 - acc: 0.5830 - f1: 0.5358 - val_loss: 0.6930 - val_acc: 0.5481 - val_f1: 0.4305\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6691 - acc: 0.5814 - f1: 0.5402 - val_loss: 0.6952 - val_acc: 0.4852 - val_f1: 0.4226\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6654 - acc: 0.5933 - f1: 0.5531 - val_loss: 0.6904 - val_acc: 0.5370 - val_f1: 0.5249\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6657 - acc: 0.5913 - f1: 0.5509 - val_loss: 0.6934 - val_acc: 0.5222 - val_f1: 0.4234\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6658 - acc: 0.5974 - f1: 0.5607 - val_loss: 0.6969 - val_acc: 0.4741 - val_f1: 0.4169\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6634 - acc: 0.5913 - f1: 0.5674 - val_loss: 0.6927 - val_acc: 0.5259 - val_f1: 0.4813\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6646 - acc: 0.5851 - f1: 0.5426 - val_loss: 0.6926 - val_acc: 0.4926 - val_f1: 0.5388\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6611 - acc: 0.6028 - f1: 0.5812 - val_loss: 0.6946 - val_acc: 0.5519 - val_f1: 0.5250\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6673 - acc: 0.5925 - f1: 0.5596 - val_loss: 0.6869 - val_acc: 0.5667 - val_f1: 0.5419\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6576 - acc: 0.6040 - f1: 0.5569 - val_loss: 0.6976 - val_acc: 0.4926 - val_f1: 0.5305\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6580 - acc: 0.6044 - f1: 0.5793 - val_loss: 0.6954 - val_acc: 0.5037 - val_f1: 0.5332\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6554 - acc: 0.6094 - f1: 0.5864 - val_loss: 0.6916 - val_acc: 0.5074 - val_f1: 0.4868\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6522 - acc: 0.6160 - f1: 0.5819 - val_loss: 0.6933 - val_acc: 0.5481 - val_f1: 0.5945\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6544 - acc: 0.6094 - f1: 0.5934 - val_loss: 0.6881 - val_acc: 0.5667 - val_f1: 0.5693\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6527 - acc: 0.6110 - f1: 0.5849 - val_loss: 0.6956 - val_acc: 0.4926 - val_f1: 0.5260\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6523 - acc: 0.6106 - f1: 0.5904 - val_loss: 0.6875 - val_acc: 0.5519 - val_f1: 0.5309\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6511 - acc: 0.6205 - f1: 0.6001 - val_loss: 0.6876 - val_acc: 0.5296 - val_f1: 0.5175\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6528 - acc: 0.6139 - f1: 0.5862 - val_loss: 0.6878 - val_acc: 0.5296 - val_f1: 0.5595\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6509 - acc: 0.6222 - f1: 0.6069 - val_loss: 0.7003 - val_acc: 0.5111 - val_f1: 0.4918\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6479 - acc: 0.6242 - f1: 0.6106 - val_loss: 0.6887 - val_acc: 0.5370 - val_f1: 0.4938\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6467 - acc: 0.6185 - f1: 0.5923 - val_loss: 0.6887 - val_acc: 0.5370 - val_f1: 0.4838\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6436 - acc: 0.6201 - f1: 0.5991 - val_loss: 0.6883 - val_acc: 0.5074 - val_f1: 0.4880\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6445 - acc: 0.6255 - f1: 0.6031 - val_loss: 0.6884 - val_acc: 0.5148 - val_f1: 0.4976\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6388 - acc: 0.6304 - f1: 0.6153 - val_loss: 0.6957 - val_acc: 0.4926 - val_f1: 0.4891\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6364 - acc: 0.6362 - f1: 0.6190 - val_loss: 0.6904 - val_acc: 0.5000 - val_f1: 0.5235\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6355 - acc: 0.6370 - f1: 0.6184 - val_loss: 0.6873 - val_acc: 0.5333 - val_f1: 0.5560\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6383 - acc: 0.6378 - f1: 0.6192 - val_loss: 0.6914 - val_acc: 0.5111 - val_f1: 0.5217\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6334 - acc: 0.6440 - f1: 0.6295 - val_loss: 0.6885 - val_acc: 0.5185 - val_f1: 0.5323\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6314 - acc: 0.6457 - f1: 0.6272 - val_loss: 0.6945 - val_acc: 0.4963 - val_f1: 0.4896\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6273 - acc: 0.6506 - f1: 0.6360 - val_loss: 0.6828 - val_acc: 0.5556 - val_f1: 0.5819\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6292 - acc: 0.6568 - f1: 0.6383 - val_loss: 0.6798 - val_acc: 0.5741 - val_f1: 0.5918\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6271 - acc: 0.6518 - f1: 0.6397 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.5121\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6240 - acc: 0.6625 - f1: 0.6468 - val_loss: 0.6866 - val_acc: 0.5333 - val_f1: 0.5663\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6238 - acc: 0.6555 - f1: 0.6408 - val_loss: 0.6900 - val_acc: 0.5370 - val_f1: 0.5729\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6185 - acc: 0.6691 - f1: 0.6563 - val_loss: 0.6949 - val_acc: 0.5185 - val_f1: 0.5002\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6190 - acc: 0.6621 - f1: 0.6471 - val_loss: 0.6981 - val_acc: 0.5000 - val_f1: 0.4750\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6212 - acc: 0.6469 - f1: 0.6310 - val_loss: 0.6897 - val_acc: 0.5481 - val_f1: 0.5721\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6172 - acc: 0.6551 - f1: 0.6416 - val_loss: 0.6953 - val_acc: 0.5407 - val_f1: 0.5618\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6156 - acc: 0.6597 - f1: 0.6437 - val_loss: 0.6892 - val_acc: 0.5259 - val_f1: 0.5382\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6114 - acc: 0.6720 - f1: 0.6606 - val_loss: 0.6851 - val_acc: 0.5407 - val_f1: 0.5496\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6117 - acc: 0.6634 - f1: 0.6496 - val_loss: 0.6858 - val_acc: 0.5185 - val_f1: 0.5525\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6071 - acc: 0.6700 - f1: 0.6591 - val_loss: 0.6899 - val_acc: 0.5519 - val_f1: 0.5533\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6039 - acc: 0.6774 - f1: 0.6648 - val_loss: 0.6904 - val_acc: 0.5148 - val_f1: 0.5159\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6083 - acc: 0.6646 - f1: 0.6531 - val_loss: 0.6833 - val_acc: 0.5630 - val_f1: 0.5963\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6052 - acc: 0.6790 - f1: 0.6644 - val_loss: 0.6885 - val_acc: 0.5333 - val_f1: 0.5621\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5948 - acc: 0.6860 - f1: 0.6752 - val_loss: 0.6885 - val_acc: 0.5296 - val_f1: 0.5679\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5960 - acc: 0.6823 - f1: 0.6726 - val_loss: 0.6871 - val_acc: 0.5148 - val_f1: 0.5446\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5988 - acc: 0.6852 - f1: 0.6749 - val_loss: 0.6856 - val_acc: 0.5370 - val_f1: 0.5464\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5913 - acc: 0.6881 - f1: 0.6733 - val_loss: 0.6881 - val_acc: 0.5444 - val_f1: 0.5554\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5978 - acc: 0.6819 - f1: 0.6709 - val_loss: 0.6891 - val_acc: 0.5407 - val_f1: 0.5441\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5943 - acc: 0.6819 - f1: 0.6703 - val_loss: 0.6940 - val_acc: 0.5556 - val_f1: 0.5775\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5887 - acc: 0.6955 - f1: 0.6880 - val_loss: 0.6842 - val_acc: 0.5407 - val_f1: 0.5744\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5869 - acc: 0.6889 - f1: 0.6766 - val_loss: 0.6945 - val_acc: 0.5259 - val_f1: 0.5575\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5872 - acc: 0.6972 - f1: 0.6873 - val_loss: 0.7067 - val_acc: 0.5370 - val_f1: 0.5612\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5796 - acc: 0.6980 - f1: 0.6894 - val_loss: 0.7001 - val_acc: 0.5333 - val_f1: 0.5669\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5808 - acc: 0.6984 - f1: 0.6909 - val_loss: 0.6952 - val_acc: 0.5963 - val_f1: 0.6191\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5816 - acc: 0.6869 - f1: 0.6753 - val_loss: 0.6900 - val_acc: 0.5556 - val_f1: 0.5986\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5713 - acc: 0.7070 - f1: 0.6991 - val_loss: 0.6972 - val_acc: 0.5556 - val_f1: 0.5610\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5833 - acc: 0.6897 - f1: 0.6795 - val_loss: 0.7008 - val_acc: 0.5556 - val_f1: 0.5919\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5742 - acc: 0.7009 - f1: 0.6898 - val_loss: 0.6919 - val_acc: 0.5704 - val_f1: 0.6019\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5660 - acc: 0.7120 - f1: 0.7023 - val_loss: 0.6987 - val_acc: 0.5556 - val_f1: 0.5784\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5636 - acc: 0.7149 - f1: 0.7068 - val_loss: 0.6991 - val_acc: 0.5815 - val_f1: 0.6082\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5589 - acc: 0.7190 - f1: 0.7095 - val_loss: 0.7053 - val_acc: 0.5481 - val_f1: 0.5772\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5602 - acc: 0.7112 - f1: 0.7032 - val_loss: 0.7029 - val_acc: 0.5370 - val_f1: 0.5582\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5551 - acc: 0.7260 - f1: 0.7167 - val_loss: 0.7041 - val_acc: 0.5519 - val_f1: 0.5609\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5586 - acc: 0.7285 - f1: 0.7210 - val_loss: 0.6929 - val_acc: 0.5815 - val_f1: 0.5931\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5584 - acc: 0.7136 - f1: 0.7050 - val_loss: 0.7004 - val_acc: 0.5593 - val_f1: 0.5751\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5511 - acc: 0.7281 - f1: 0.7199 - val_loss: 0.7047 - val_acc: 0.5333 - val_f1: 0.5589\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5580 - acc: 0.7206 - f1: 0.7113 - val_loss: 0.7055 - val_acc: 0.5444 - val_f1: 0.5656\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5551 - acc: 0.7215 - f1: 0.7147 - val_loss: 0.7133 - val_acc: 0.5370 - val_f1: 0.5606\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5422 - acc: 0.7388 - f1: 0.7324 - val_loss: 0.7110 - val_acc: 0.5556 - val_f1: 0.5767\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5518 - acc: 0.7305 - f1: 0.7221 - val_loss: 0.7011 - val_acc: 0.5556 - val_f1: 0.5739\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5473 - acc: 0.7219 - f1: 0.7142 - val_loss: 0.7093 - val_acc: 0.5704 - val_f1: 0.5849\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5449 - acc: 0.7301 - f1: 0.7199 - val_loss: 0.7167 - val_acc: 0.5407 - val_f1: 0.5667\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5452 - acc: 0.7293 - f1: 0.7223 - val_loss: 0.7108 - val_acc: 0.5519 - val_f1: 0.5724\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5358 - acc: 0.7404 - f1: 0.7345 - val_loss: 0.7181 - val_acc: 0.5630 - val_f1: 0.5998\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5275 - acc: 0.7363 - f1: 0.7289 - val_loss: 0.7253 - val_acc: 0.5407 - val_f1: 0.5660\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5316 - acc: 0.7404 - f1: 0.7327 - val_loss: 0.7168 - val_acc: 0.5481 - val_f1: 0.5709\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5392 - acc: 0.7351 - f1: 0.7289 - val_loss: 0.7199 - val_acc: 0.5444 - val_f1: 0.5661\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5292 - acc: 0.7326 - f1: 0.7242 - val_loss: 0.7273 - val_acc: 0.5259 - val_f1: 0.5556\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5245 - acc: 0.7421 - f1: 0.7349 - val_loss: 0.7223 - val_acc: 0.5630 - val_f1: 0.6053\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5307 - acc: 0.7326 - f1: 0.7269 - val_loss: 0.7221 - val_acc: 0.5481 - val_f1: 0.5713\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5216 - acc: 0.7528 - f1: 0.7464 - val_loss: 0.7318 - val_acc: 0.5444 - val_f1: 0.5714\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5261 - acc: 0.7458 - f1: 0.7386 - val_loss: 0.7316 - val_acc: 0.5370 - val_f1: 0.5869\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5148 - acc: 0.7482 - f1: 0.7419 - val_loss: 0.7356 - val_acc: 0.5259 - val_f1: 0.5572\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5181 - acc: 0.7400 - f1: 0.7320 - val_loss: 0.7286 - val_acc: 0.5444 - val_f1: 0.5677\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5258 - acc: 0.7371 - f1: 0.7311 - val_loss: 0.7386 - val_acc: 0.5222 - val_f1: 0.5320\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5169 - acc: 0.7524 - f1: 0.7467 - val_loss: 0.7408 - val_acc: 0.5333 - val_f1: 0.5586\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5167 - acc: 0.7474 - f1: 0.7400 - val_loss: 0.7444 - val_acc: 0.5370 - val_f1: 0.5639\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5159 - acc: 0.7342 - f1: 0.7267 - val_loss: 0.7413 - val_acc: 0.5259 - val_f1: 0.5571\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5232 - acc: 0.7503 - f1: 0.7450 - val_loss: 0.7416 - val_acc: 0.5704 - val_f1: 0.6070\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5158 - acc: 0.7470 - f1: 0.7400 - val_loss: 0.7361 - val_acc: 0.5481 - val_f1: 0.5491\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5071 - acc: 0.7520 - f1: 0.7459 - val_loss: 0.7448 - val_acc: 0.5593 - val_f1: 0.5975\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5016 - acc: 0.7590 - f1: 0.7536 - val_loss: 0.7438 - val_acc: 0.5444 - val_f1: 0.5682\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5166 - acc: 0.7511 - f1: 0.7453 - val_loss: 0.7475 - val_acc: 0.5556 - val_f1: 0.5746\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4975 - acc: 0.7540 - f1: 0.7483 - val_loss: 0.7580 - val_acc: 0.5370 - val_f1: 0.5603\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5048 - acc: 0.7573 - f1: 0.7516 - val_loss: 0.7446 - val_acc: 0.5481 - val_f1: 0.5702\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5042 - acc: 0.7532 - f1: 0.7478 - val_loss: 0.7493 - val_acc: 0.5407 - val_f1: 0.5427\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4898 - acc: 0.7676 - f1: 0.7610 - val_loss: 0.7475 - val_acc: 0.5444 - val_f1: 0.5919\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4919 - acc: 0.7631 - f1: 0.7562 - val_loss: 0.7521 - val_acc: 0.5370 - val_f1: 0.5656\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4898 - acc: 0.7684 - f1: 0.7632 - val_loss: 0.7630 - val_acc: 0.5259 - val_f1: 0.5585\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4930 - acc: 0.7606 - f1: 0.7550 - val_loss: 0.7661 - val_acc: 0.5296 - val_f1: 0.5818\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4862 - acc: 0.7754 - f1: 0.7702 - val_loss: 0.7604 - val_acc: 0.5370 - val_f1: 0.5605\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4997 - acc: 0.7651 - f1: 0.7596 - val_loss: 0.7653 - val_acc: 0.5630 - val_f1: 0.5805\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4876 - acc: 0.7598 - f1: 0.7524 - val_loss: 0.7698 - val_acc: 0.5259 - val_f1: 0.5521\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4869 - acc: 0.7717 - f1: 0.7664 - val_loss: 0.7788 - val_acc: 0.5222 - val_f1: 0.5519\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4762 - acc: 0.7796 - f1: 0.7739 - val_loss: 0.7801 - val_acc: 0.5370 - val_f1: 0.5648\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4825 - acc: 0.7705 - f1: 0.7642 - val_loss: 0.7706 - val_acc: 0.5259 - val_f1: 0.5538\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4741 - acc: 0.7746 - f1: 0.7695 - val_loss: 0.7712 - val_acc: 0.5444 - val_f1: 0.5695\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4850 - acc: 0.7726 - f1: 0.7665 - val_loss: 0.7706 - val_acc: 0.4926 - val_f1: 0.5564\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4774 - acc: 0.7709 - f1: 0.7661 - val_loss: 0.7795 - val_acc: 0.5222 - val_f1: 0.5497\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4699 - acc: 0.7870 - f1: 0.7810 - val_loss: 0.7691 - val_acc: 0.5444 - val_f1: 0.5694\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4725 - acc: 0.7857 - f1: 0.7810 - val_loss: 0.7889 - val_acc: 0.5185 - val_f1: 0.5470\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4768 - acc: 0.7585 - f1: 0.7536 - val_loss: 0.7868 - val_acc: 0.5222 - val_f1: 0.5528\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4772 - acc: 0.7820 - f1: 0.7760 - val_loss: 0.7878 - val_acc: 0.5037 - val_f1: 0.5374\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4718 - acc: 0.7829 - f1: 0.7775 - val_loss: 0.7729 - val_acc: 0.5148 - val_f1: 0.5496\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4701 - acc: 0.7829 - f1: 0.7767 - val_loss: 0.7976 - val_acc: 0.5370 - val_f1: 0.5650\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4719 - acc: 0.7812 - f1: 0.7778 - val_loss: 0.7723 - val_acc: 0.5296 - val_f1: 0.5562\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4732 - acc: 0.7779 - f1: 0.7716 - val_loss: 0.7722 - val_acc: 0.5148 - val_f1: 0.5484\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4555 - acc: 0.7890 - f1: 0.7847 - val_loss: 0.7992 - val_acc: 0.5148 - val_f1: 0.5478\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4643 - acc: 0.7812 - f1: 0.7752 - val_loss: 0.7798 - val_acc: 0.5296 - val_f1: 0.5561\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4587 - acc: 0.7808 - f1: 0.7748 - val_loss: 0.7965 - val_acc: 0.5148 - val_f1: 0.5492\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4645 - acc: 0.7779 - f1: 0.7733 - val_loss: 0.7765 - val_acc: 0.5259 - val_f1: 0.5556\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4707 - acc: 0.7874 - f1: 0.7830 - val_loss: 0.7859 - val_acc: 0.5296 - val_f1: 0.5539\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4576 - acc: 0.7866 - f1: 0.7822 - val_loss: 0.7915 - val_acc: 0.5259 - val_f1: 0.5566\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4547 - acc: 0.7923 - f1: 0.7869 - val_loss: 0.7908 - val_acc: 0.5222 - val_f1: 0.5498\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4540 - acc: 0.7792 - f1: 0.7751 - val_loss: 0.7897 - val_acc: 0.5185 - val_f1: 0.5498\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4531 - acc: 0.7993 - f1: 0.7949 - val_loss: 0.7860 - val_acc: 0.5185 - val_f1: 0.5520\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4501 - acc: 0.7841 - f1: 0.7785 - val_loss: 0.7965 - val_acc: 0.5259 - val_f1: 0.5577\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4538 - acc: 0.7940 - f1: 0.7900 - val_loss: 0.7907 - val_acc: 0.5370 - val_f1: 0.5621\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4540 - acc: 0.7870 - f1: 0.7822 - val_loss: 0.7898 - val_acc: 0.5296 - val_f1: 0.5566\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 24ms/step - loss: 0.6896 - acc: 0.5480 - f1: 0.3766 - val_loss: 0.6942 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6883 - acc: 0.5550 - f1: 0.3621 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6879 - acc: 0.5529 - f1: 0.3619 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6869 - acc: 0.5542 - f1: 0.3578 - val_loss: 0.6913 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5529 - f1: 0.3573 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5542 - f1: 0.3633 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5517 - f1: 0.3640 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6863 - acc: 0.5542 - f1: 0.3706 - val_loss: 0.6898 - val_acc: 0.5370 - val_f1: 0.3679\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5608 - f1: 0.3992 - val_loss: 0.6910 - val_acc: 0.5370 - val_f1: 0.5508\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5538 - f1: 0.3960 - val_loss: 0.6893 - val_acc: 0.5296 - val_f1: 0.3521\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6860 - acc: 0.5534 - f1: 0.3932 - val_loss: 0.6902 - val_acc: 0.5296 - val_f1: 0.3608\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6874 - acc: 0.5608 - f1: 0.4001 - val_loss: 0.6902 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.5521 - f1: 0.3612 - val_loss: 0.6899 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6848 - acc: 0.5649 - f1: 0.4458 - val_loss: 0.6906 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6830 - acc: 0.5550 - f1: 0.3711 - val_loss: 0.6898 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6825 - acc: 0.5529 - f1: 0.3622 - val_loss: 0.6908 - val_acc: 0.5333 - val_f1: 0.3666\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5604 - f1: 0.4378 - val_loss: 0.6907 - val_acc: 0.5333 - val_f1: 0.3578\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6792 - acc: 0.5513 - f1: 0.3711 - val_loss: 0.6911 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6799 - acc: 0.5558 - f1: 0.4254 - val_loss: 0.6924 - val_acc: 0.5222 - val_f1: 0.3705\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6818 - acc: 0.5542 - f1: 0.4224 - val_loss: 0.6909 - val_acc: 0.5333 - val_f1: 0.3613\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6793 - acc: 0.5534 - f1: 0.4238 - val_loss: 0.6917 - val_acc: 0.5296 - val_f1: 0.3519\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6789 - acc: 0.5608 - f1: 0.4402 - val_loss: 0.6895 - val_acc: 0.5593 - val_f1: 0.4075\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6771 - acc: 0.5686 - f1: 0.4485 - val_loss: 0.6910 - val_acc: 0.5222 - val_f1: 0.3573\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6752 - acc: 0.5682 - f1: 0.4768 - val_loss: 0.6945 - val_acc: 0.4852 - val_f1: 0.4617\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6764 - acc: 0.5740 - f1: 0.5048 - val_loss: 0.6931 - val_acc: 0.5111 - val_f1: 0.3495\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6747 - acc: 0.5715 - f1: 0.5122 - val_loss: 0.6959 - val_acc: 0.5222 - val_f1: 0.3743\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6758 - acc: 0.5686 - f1: 0.4667 - val_loss: 0.6915 - val_acc: 0.5481 - val_f1: 0.3984\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6761 - acc: 0.5777 - f1: 0.5092 - val_loss: 0.7062 - val_acc: 0.4889 - val_f1: 0.3849\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6735 - acc: 0.5748 - f1: 0.5031 - val_loss: 0.6959 - val_acc: 0.5111 - val_f1: 0.3856\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6696 - acc: 0.5847 - f1: 0.5202 - val_loss: 0.6976 - val_acc: 0.4926 - val_f1: 0.3931\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6677 - acc: 0.5797 - f1: 0.5125 - val_loss: 0.7013 - val_acc: 0.4704 - val_f1: 0.4107\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6677 - acc: 0.5925 - f1: 0.5470 - val_loss: 0.7001 - val_acc: 0.4704 - val_f1: 0.4224\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6670 - acc: 0.6053 - f1: 0.5478 - val_loss: 0.7085 - val_acc: 0.4926 - val_f1: 0.4139\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6682 - acc: 0.5847 - f1: 0.5340 - val_loss: 0.6991 - val_acc: 0.4852 - val_f1: 0.5156\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6662 - acc: 0.5789 - f1: 0.5310 - val_loss: 0.7008 - val_acc: 0.4741 - val_f1: 0.4069\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6643 - acc: 0.6176 - f1: 0.5744 - val_loss: 0.7156 - val_acc: 0.4778 - val_f1: 0.4112\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6621 - acc: 0.5946 - f1: 0.5554 - val_loss: 0.7053 - val_acc: 0.4741 - val_f1: 0.4073\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6628 - acc: 0.5987 - f1: 0.5643 - val_loss: 0.7024 - val_acc: 0.4815 - val_f1: 0.3995\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6611 - acc: 0.5933 - f1: 0.5528 - val_loss: 0.7170 - val_acc: 0.4815 - val_f1: 0.4148\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6613 - acc: 0.5983 - f1: 0.5591 - val_loss: 0.6893 - val_acc: 0.5444 - val_f1: 0.5098\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6601 - acc: 0.6065 - f1: 0.5669 - val_loss: 0.7006 - val_acc: 0.5148 - val_f1: 0.5305\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6606 - acc: 0.6077 - f1: 0.5665 - val_loss: 0.6967 - val_acc: 0.4889 - val_f1: 0.5157\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6552 - acc: 0.6073 - f1: 0.5792 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1: 0.5085\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6562 - acc: 0.6143 - f1: 0.5915 - val_loss: 0.7037 - val_acc: 0.5074 - val_f1: 0.5327\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6553 - acc: 0.6028 - f1: 0.5666 - val_loss: 0.7008 - val_acc: 0.4963 - val_f1: 0.4880\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6498 - acc: 0.6156 - f1: 0.5867 - val_loss: 0.7045 - val_acc: 0.4963 - val_f1: 0.5504\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6479 - acc: 0.6164 - f1: 0.5887 - val_loss: 0.6976 - val_acc: 0.5074 - val_f1: 0.5275\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6484 - acc: 0.6176 - f1: 0.5898 - val_loss: 0.7066 - val_acc: 0.4926 - val_f1: 0.4842\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6451 - acc: 0.6135 - f1: 0.5843 - val_loss: 0.7054 - val_acc: 0.4889 - val_f1: 0.5187\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.6259 - f1: 0.6036 - val_loss: 0.7168 - val_acc: 0.5074 - val_f1: 0.5234\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6451 - acc: 0.6205 - f1: 0.5989 - val_loss: 0.7005 - val_acc: 0.5222 - val_f1: 0.5706\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6404 - acc: 0.6238 - f1: 0.6053 - val_loss: 0.7160 - val_acc: 0.4815 - val_f1: 0.4896\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6398 - acc: 0.6263 - f1: 0.6029 - val_loss: 0.7101 - val_acc: 0.5037 - val_f1: 0.5600\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6353 - acc: 0.6362 - f1: 0.6180 - val_loss: 0.6998 - val_acc: 0.4926 - val_f1: 0.5486\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.6333 - f1: 0.6130 - val_loss: 0.7100 - val_acc: 0.5000 - val_f1: 0.5312\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6325 - acc: 0.6316 - f1: 0.6094 - val_loss: 0.7129 - val_acc: 0.4926 - val_f1: 0.5488\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6342 - acc: 0.6432 - f1: 0.6290 - val_loss: 0.7222 - val_acc: 0.5185 - val_f1: 0.5720\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6297 - acc: 0.6345 - f1: 0.6122 - val_loss: 0.7012 - val_acc: 0.5222 - val_f1: 0.5381\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6273 - acc: 0.6494 - f1: 0.6299 - val_loss: 0.6914 - val_acc: 0.4852 - val_f1: 0.5379\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6275 - acc: 0.6539 - f1: 0.6432 - val_loss: 0.7199 - val_acc: 0.5000 - val_f1: 0.5346\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6233 - acc: 0.6630 - f1: 0.6442 - val_loss: 0.6978 - val_acc: 0.5148 - val_f1: 0.5663\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6229 - acc: 0.6547 - f1: 0.6465 - val_loss: 0.6940 - val_acc: 0.5185 - val_f1: 0.5616\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6203 - acc: 0.6539 - f1: 0.6363 - val_loss: 0.7090 - val_acc: 0.5037 - val_f1: 0.5545\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6170 - acc: 0.6576 - f1: 0.6407 - val_loss: 0.6942 - val_acc: 0.5296 - val_f1: 0.5764\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6140 - acc: 0.6584 - f1: 0.6415 - val_loss: 0.7083 - val_acc: 0.4889 - val_f1: 0.5481\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6108 - acc: 0.6617 - f1: 0.6501 - val_loss: 0.7202 - val_acc: 0.5037 - val_f1: 0.5619\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6056 - acc: 0.6708 - f1: 0.6568 - val_loss: 0.7115 - val_acc: 0.5037 - val_f1: 0.5603\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6070 - acc: 0.6724 - f1: 0.6613 - val_loss: 0.7128 - val_acc: 0.5000 - val_f1: 0.5586\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6044 - acc: 0.6658 - f1: 0.6507 - val_loss: 0.7017 - val_acc: 0.5222 - val_f1: 0.5745\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6016 - acc: 0.6687 - f1: 0.6583 - val_loss: 0.7120 - val_acc: 0.4889 - val_f1: 0.5516\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5973 - acc: 0.6897 - f1: 0.6803 - val_loss: 0.7127 - val_acc: 0.4889 - val_f1: 0.5494\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6047 - acc: 0.6794 - f1: 0.6684 - val_loss: 0.7020 - val_acc: 0.5259 - val_f1: 0.5700\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6010 - acc: 0.6840 - f1: 0.6721 - val_loss: 0.7116 - val_acc: 0.5222 - val_f1: 0.5711\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5920 - acc: 0.6926 - f1: 0.6822 - val_loss: 0.7190 - val_acc: 0.5148 - val_f1: 0.5703\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5847 - acc: 0.6910 - f1: 0.6784 - val_loss: 0.7085 - val_acc: 0.5222 - val_f1: 0.5741\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5908 - acc: 0.6770 - f1: 0.6681 - val_loss: 0.7022 - val_acc: 0.5259 - val_f1: 0.5759\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5912 - acc: 0.6782 - f1: 0.6679 - val_loss: 0.7114 - val_acc: 0.5333 - val_f1: 0.5805\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5881 - acc: 0.6827 - f1: 0.6718 - val_loss: 0.7121 - val_acc: 0.5296 - val_f1: 0.5793\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5872 - acc: 0.6864 - f1: 0.6761 - val_loss: 0.7222 - val_acc: 0.5185 - val_f1: 0.5737\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5851 - acc: 0.6976 - f1: 0.6888 - val_loss: 0.7098 - val_acc: 0.5259 - val_f1: 0.5758\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5781 - acc: 0.6885 - f1: 0.6800 - val_loss: 0.7111 - val_acc: 0.5037 - val_f1: 0.5582\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5782 - acc: 0.6873 - f1: 0.6790 - val_loss: 0.7141 - val_acc: 0.5148 - val_f1: 0.5689\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5762 - acc: 0.6992 - f1: 0.6911 - val_loss: 0.7114 - val_acc: 0.5259 - val_f1: 0.5754\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5670 - acc: 0.7058 - f1: 0.6953 - val_loss: 0.7127 - val_acc: 0.5222 - val_f1: 0.5541\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5685 - acc: 0.7033 - f1: 0.6939 - val_loss: 0.7051 - val_acc: 0.5148 - val_f1: 0.5440\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.5658 - acc: 0.7017 - f1: 0.6922 - val_loss: 0.7173 - val_acc: 0.4852 - val_f1: 0.5098\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5747 - acc: 0.6988 - f1: 0.6922 - val_loss: 0.7110 - val_acc: 0.5037 - val_f1: 0.5393\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5647 - acc: 0.6996 - f1: 0.6895 - val_loss: 0.7179 - val_acc: 0.5000 - val_f1: 0.5378\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5616 - acc: 0.7087 - f1: 0.7009 - val_loss: 0.7099 - val_acc: 0.5333 - val_f1: 0.5605\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5669 - acc: 0.7099 - f1: 0.7014 - val_loss: 0.7230 - val_acc: 0.5259 - val_f1: 0.5718\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5603 - acc: 0.7161 - f1: 0.7083 - val_loss: 0.7106 - val_acc: 0.5111 - val_f1: 0.5452\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5562 - acc: 0.7136 - f1: 0.7063 - val_loss: 0.7128 - val_acc: 0.5407 - val_f1: 0.5623\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5550 - acc: 0.7124 - f1: 0.7040 - val_loss: 0.7205 - val_acc: 0.5370 - val_f1: 0.5641\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5490 - acc: 0.7248 - f1: 0.7166 - val_loss: 0.7193 - val_acc: 0.4815 - val_f1: 0.4857\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5600 - acc: 0.7103 - f1: 0.7043 - val_loss: 0.7169 - val_acc: 0.5333 - val_f1: 0.5761\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5507 - acc: 0.7235 - f1: 0.7157 - val_loss: 0.7185 - val_acc: 0.5407 - val_f1: 0.5586\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5531 - acc: 0.7136 - f1: 0.7050 - val_loss: 0.7238 - val_acc: 0.5407 - val_f1: 0.5657\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5485 - acc: 0.7075 - f1: 0.7005 - val_loss: 0.7301 - val_acc: 0.5333 - val_f1: 0.5542\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5438 - acc: 0.7182 - f1: 0.7094 - val_loss: 0.7171 - val_acc: 0.5148 - val_f1: 0.5464\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5372 - acc: 0.7314 - f1: 0.7242 - val_loss: 0.7409 - val_acc: 0.5111 - val_f1: 0.5275\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5437 - acc: 0.7239 - f1: 0.7146 - val_loss: 0.7232 - val_acc: 0.5259 - val_f1: 0.5538\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5328 - acc: 0.7408 - f1: 0.7344 - val_loss: 0.7294 - val_acc: 0.5333 - val_f1: 0.5611\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5347 - acc: 0.7318 - f1: 0.7244 - val_loss: 0.7355 - val_acc: 0.5185 - val_f1: 0.5678\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5386 - acc: 0.7289 - f1: 0.7220 - val_loss: 0.7349 - val_acc: 0.5148 - val_f1: 0.5463\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5283 - acc: 0.7429 - f1: 0.7365 - val_loss: 0.7231 - val_acc: 0.5111 - val_f1: 0.5438\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5268 - acc: 0.7363 - f1: 0.7292 - val_loss: 0.7522 - val_acc: 0.5185 - val_f1: 0.5703\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5349 - acc: 0.7276 - f1: 0.7222 - val_loss: 0.7268 - val_acc: 0.5333 - val_f1: 0.5566\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5221 - acc: 0.7371 - f1: 0.7299 - val_loss: 0.7382 - val_acc: 0.5296 - val_f1: 0.5770\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5318 - acc: 0.7264 - f1: 0.7198 - val_loss: 0.7195 - val_acc: 0.5444 - val_f1: 0.5687\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5244 - acc: 0.7347 - f1: 0.7275 - val_loss: 0.7204 - val_acc: 0.5370 - val_f1: 0.5620\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5256 - acc: 0.7359 - f1: 0.7280 - val_loss: 0.7257 - val_acc: 0.5222 - val_f1: 0.5550\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5102 - acc: 0.7495 - f1: 0.7434 - val_loss: 0.7286 - val_acc: 0.5259 - val_f1: 0.5559\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5148 - acc: 0.7441 - f1: 0.7377 - val_loss: 0.7350 - val_acc: 0.5111 - val_f1: 0.5491\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5195 - acc: 0.7379 - f1: 0.7314 - val_loss: 0.7365 - val_acc: 0.5222 - val_f1: 0.5529\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5122 - acc: 0.7524 - f1: 0.7455 - val_loss: 0.7502 - val_acc: 0.5111 - val_f1: 0.5231\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5119 - acc: 0.7400 - f1: 0.7340 - val_loss: 0.7372 - val_acc: 0.5037 - val_f1: 0.5396\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5134 - acc: 0.7441 - f1: 0.7382 - val_loss: 0.7325 - val_acc: 0.5185 - val_f1: 0.5252\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5080 - acc: 0.7474 - f1: 0.7421 - val_loss: 0.7244 - val_acc: 0.5259 - val_f1: 0.5333\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5153 - acc: 0.7388 - f1: 0.7321 - val_loss: 0.7338 - val_acc: 0.5444 - val_f1: 0.5646\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5097 - acc: 0.7392 - f1: 0.7343 - val_loss: 0.7416 - val_acc: 0.5333 - val_f1: 0.5597\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5058 - acc: 0.7495 - f1: 0.7435 - val_loss: 0.7279 - val_acc: 0.5519 - val_f1: 0.5722\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5062 - acc: 0.7445 - f1: 0.7378 - val_loss: 0.7397 - val_acc: 0.5519 - val_f1: 0.5760\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5049 - acc: 0.7577 - f1: 0.7512 - val_loss: 0.7634 - val_acc: 0.5222 - val_f1: 0.5126\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5049 - acc: 0.7482 - f1: 0.7426 - val_loss: 0.7466 - val_acc: 0.5296 - val_f1: 0.5598\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4945 - acc: 0.7590 - f1: 0.7536 - val_loss: 0.7550 - val_acc: 0.5222 - val_f1: 0.5319\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4986 - acc: 0.7466 - f1: 0.7402 - val_loss: 0.7422 - val_acc: 0.5222 - val_f1: 0.5570\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4976 - acc: 0.7520 - f1: 0.7476 - val_loss: 0.7492 - val_acc: 0.5259 - val_f1: 0.5160\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5084 - acc: 0.7400 - f1: 0.7338 - val_loss: 0.7381 - val_acc: 0.5370 - val_f1: 0.5468\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4963 - acc: 0.7631 - f1: 0.7571 - val_loss: 0.7666 - val_acc: 0.5296 - val_f1: 0.5358\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4968 - acc: 0.7565 - f1: 0.7514 - val_loss: 0.7519 - val_acc: 0.5000 - val_f1: 0.5148\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4963 - acc: 0.7520 - f1: 0.7467 - val_loss: 0.7452 - val_acc: 0.5296 - val_f1: 0.5167\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4918 - acc: 0.7610 - f1: 0.7556 - val_loss: 0.7531 - val_acc: 0.5259 - val_f1: 0.5584\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4851 - acc: 0.7614 - f1: 0.7569 - val_loss: 0.7688 - val_acc: 0.4963 - val_f1: 0.4950\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4844 - acc: 0.7664 - f1: 0.7595 - val_loss: 0.7459 - val_acc: 0.5444 - val_f1: 0.5707\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4914 - acc: 0.7627 - f1: 0.7557 - val_loss: 0.7481 - val_acc: 0.5370 - val_f1: 0.5646\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4775 - acc: 0.7783 - f1: 0.7730 - val_loss: 0.7743 - val_acc: 0.5000 - val_f1: 0.5392\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4803 - acc: 0.7684 - f1: 0.7638 - val_loss: 0.7734 - val_acc: 0.5111 - val_f1: 0.5253\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4846 - acc: 0.7581 - f1: 0.7514 - val_loss: 0.7850 - val_acc: 0.5111 - val_f1: 0.5252\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4838 - acc: 0.7660 - f1: 0.7596 - val_loss: 0.7692 - val_acc: 0.5333 - val_f1: 0.5397\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4851 - acc: 0.7606 - f1: 0.7554 - val_loss: 0.7820 - val_acc: 0.5074 - val_f1: 0.5214\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.6935 - acc: 0.5340 - f1: 0.4039 - val_loss: 0.6968 - val_acc: 0.4704 - val_f1: 0.3239\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6893 - acc: 0.5529 - f1: 0.3747 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6873 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6877 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6867 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6866 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6869 - acc: 0.5571 - f1: 0.3732 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5538 - f1: 0.3569 - val_loss: 0.6929 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6865 - acc: 0.5554 - f1: 0.3760 - val_loss: 0.6936 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5546 - f1: 0.3673 - val_loss: 0.6941 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6863 - acc: 0.5538 - f1: 0.3567 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6859 - acc: 0.5542 - f1: 0.3655 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6849 - acc: 0.5538 - f1: 0.3621 - val_loss: 0.6954 - val_acc: 0.5111 - val_f1: 0.3581\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6854 - acc: 0.5562 - f1: 0.3808 - val_loss: 0.6957 - val_acc: 0.5074 - val_f1: 0.3564\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.5558 - f1: 0.3881 - val_loss: 0.6955 - val_acc: 0.5037 - val_f1: 0.3476\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6831 - acc: 0.5542 - f1: 0.3893 - val_loss: 0.6981 - val_acc: 0.4222 - val_f1: 0.3868\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.5534 - f1: 0.4375 - val_loss: 0.6982 - val_acc: 0.4481 - val_f1: 0.3989\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6817 - acc: 0.5575 - f1: 0.4357 - val_loss: 0.7002 - val_acc: 0.5074 - val_f1: 0.4010\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6826 - acc: 0.5645 - f1: 0.4396 - val_loss: 0.7006 - val_acc: 0.4630 - val_f1: 0.4032\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6805 - acc: 0.5678 - f1: 0.4550 - val_loss: 0.7003 - val_acc: 0.5111 - val_f1: 0.4003\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6794 - acc: 0.5600 - f1: 0.4240 - val_loss: 0.7017 - val_acc: 0.4630 - val_f1: 0.3959\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6805 - acc: 0.5641 - f1: 0.4456 - val_loss: 0.7020 - val_acc: 0.4259 - val_f1: 0.3888\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6808 - acc: 0.5624 - f1: 0.4711 - val_loss: 0.7031 - val_acc: 0.4259 - val_f1: 0.3825\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6783 - acc: 0.5735 - f1: 0.4969 - val_loss: 0.7028 - val_acc: 0.4333 - val_f1: 0.3929\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6801 - acc: 0.5600 - f1: 0.4886 - val_loss: 0.7026 - val_acc: 0.4481 - val_f1: 0.3967\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6773 - acc: 0.5653 - f1: 0.4543 - val_loss: 0.7042 - val_acc: 0.4778 - val_f1: 0.3985\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6772 - acc: 0.5653 - f1: 0.4536 - val_loss: 0.7033 - val_acc: 0.4407 - val_f1: 0.3841\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6766 - acc: 0.5686 - f1: 0.4796 - val_loss: 0.7046 - val_acc: 0.4519 - val_f1: 0.3978\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6761 - acc: 0.5731 - f1: 0.5177 - val_loss: 0.7061 - val_acc: 0.4556 - val_f1: 0.3948\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6728 - acc: 0.5698 - f1: 0.4904 - val_loss: 0.7029 - val_acc: 0.4667 - val_f1: 0.3821\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6738 - acc: 0.5740 - f1: 0.4942 - val_loss: 0.7047 - val_acc: 0.4630 - val_f1: 0.4089\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6721 - acc: 0.5855 - f1: 0.5191 - val_loss: 0.7056 - val_acc: 0.4741 - val_f1: 0.4151\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6725 - acc: 0.5904 - f1: 0.5303 - val_loss: 0.7074 - val_acc: 0.4519 - val_f1: 0.3777\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.5740 - f1: 0.5142 - val_loss: 0.7128 - val_acc: 0.4148 - val_f1: 0.3741\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6684 - acc: 0.5847 - f1: 0.5113 - val_loss: 0.7109 - val_acc: 0.4630 - val_f1: 0.4096\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6679 - acc: 0.5925 - f1: 0.5416 - val_loss: 0.7025 - val_acc: 0.4593 - val_f1: 0.3956\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6651 - acc: 0.5974 - f1: 0.5455 - val_loss: 0.7080 - val_acc: 0.4519 - val_f1: 0.3904\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6633 - acc: 0.6053 - f1: 0.5499 - val_loss: 0.7087 - val_acc: 0.4519 - val_f1: 0.3917\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6608 - acc: 0.6024 - f1: 0.5566 - val_loss: 0.7080 - val_acc: 0.4481 - val_f1: 0.4370\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6605 - acc: 0.6065 - f1: 0.5663 - val_loss: 0.7109 - val_acc: 0.4593 - val_f1: 0.3941\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6606 - acc: 0.6040 - f1: 0.5640 - val_loss: 0.7071 - val_acc: 0.4815 - val_f1: 0.4061\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6560 - acc: 0.6106 - f1: 0.5697 - val_loss: 0.7025 - val_acc: 0.4852 - val_f1: 0.4262\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6539 - acc: 0.6082 - f1: 0.5678 - val_loss: 0.7163 - val_acc: 0.4556 - val_f1: 0.4301\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6537 - acc: 0.6255 - f1: 0.5927 - val_loss: 0.7148 - val_acc: 0.4444 - val_f1: 0.4222\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6296 - f1: 0.5985 - val_loss: 0.7105 - val_acc: 0.4519 - val_f1: 0.3899\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6522 - acc: 0.6156 - f1: 0.5804 - val_loss: 0.7082 - val_acc: 0.4556 - val_f1: 0.4251\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6508 - acc: 0.6123 - f1: 0.5814 - val_loss: 0.7057 - val_acc: 0.4556 - val_f1: 0.4454\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6497 - acc: 0.6222 - f1: 0.5973 - val_loss: 0.7073 - val_acc: 0.4593 - val_f1: 0.4260\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6447 - acc: 0.6197 - f1: 0.5870 - val_loss: 0.7025 - val_acc: 0.5000 - val_f1: 0.4536\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6441 - acc: 0.6271 - f1: 0.6033 - val_loss: 0.7050 - val_acc: 0.4704 - val_f1: 0.4731\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6430 - acc: 0.6374 - f1: 0.6144 - val_loss: 0.7083 - val_acc: 0.4815 - val_f1: 0.4857\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6457 - acc: 0.6337 - f1: 0.6125 - val_loss: 0.7060 - val_acc: 0.4963 - val_f1: 0.4416\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6389 - acc: 0.6370 - f1: 0.6068 - val_loss: 0.7031 - val_acc: 0.4852 - val_f1: 0.4637\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6431 - acc: 0.6246 - f1: 0.6054 - val_loss: 0.7036 - val_acc: 0.5000 - val_f1: 0.4919\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6377 - acc: 0.6457 - f1: 0.6271 - val_loss: 0.6951 - val_acc: 0.5111 - val_f1: 0.5027\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6372 - acc: 0.6325 - f1: 0.6133 - val_loss: 0.7064 - val_acc: 0.5037 - val_f1: 0.5203\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6353 - acc: 0.6333 - f1: 0.6120 - val_loss: 0.7171 - val_acc: 0.4926 - val_f1: 0.4933\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6362 - acc: 0.6407 - f1: 0.6262 - val_loss: 0.7069 - val_acc: 0.5111 - val_f1: 0.5055\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6309 - acc: 0.6522 - f1: 0.6316 - val_loss: 0.7076 - val_acc: 0.5037 - val_f1: 0.4946\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6270 - acc: 0.6494 - f1: 0.6288 - val_loss: 0.7114 - val_acc: 0.4963 - val_f1: 0.4962\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6316 - acc: 0.6461 - f1: 0.6253 - val_loss: 0.7095 - val_acc: 0.4889 - val_f1: 0.4910\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6292 - acc: 0.6531 - f1: 0.6407 - val_loss: 0.7095 - val_acc: 0.4926 - val_f1: 0.4892\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6276 - acc: 0.6444 - f1: 0.6272 - val_loss: 0.7055 - val_acc: 0.4926 - val_f1: 0.4918\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6232 - acc: 0.6485 - f1: 0.6332 - val_loss: 0.7091 - val_acc: 0.5074 - val_f1: 0.5218\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6191 - acc: 0.6605 - f1: 0.6447 - val_loss: 0.7075 - val_acc: 0.5444 - val_f1: 0.5473\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6165 - acc: 0.6576 - f1: 0.6405 - val_loss: 0.7136 - val_acc: 0.5222 - val_f1: 0.5138\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6124 - acc: 0.6650 - f1: 0.6513 - val_loss: 0.7250 - val_acc: 0.5148 - val_f1: 0.5260\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6156 - acc: 0.6625 - f1: 0.6482 - val_loss: 0.7169 - val_acc: 0.5333 - val_f1: 0.5186\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6145 - acc: 0.6733 - f1: 0.6579 - val_loss: 0.7257 - val_acc: 0.5185 - val_f1: 0.5529\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6162 - acc: 0.6510 - f1: 0.6348 - val_loss: 0.7113 - val_acc: 0.5407 - val_f1: 0.5687\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6083 - acc: 0.6840 - f1: 0.6718 - val_loss: 0.7125 - val_acc: 0.5556 - val_f1: 0.5694\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6118 - acc: 0.6658 - f1: 0.6510 - val_loss: 0.7217 - val_acc: 0.5037 - val_f1: 0.5228\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6044 - acc: 0.6819 - f1: 0.6680 - val_loss: 0.7248 - val_acc: 0.5296 - val_f1: 0.5169\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6051 - acc: 0.6766 - f1: 0.6600 - val_loss: 0.7146 - val_acc: 0.5556 - val_f1: 0.5794\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6041 - acc: 0.6803 - f1: 0.6716 - val_loss: 0.7106 - val_acc: 0.5222 - val_f1: 0.5122\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5963 - acc: 0.6852 - f1: 0.6698 - val_loss: 0.7072 - val_acc: 0.5037 - val_f1: 0.5011\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5937 - acc: 0.6877 - f1: 0.6768 - val_loss: 0.7135 - val_acc: 0.5407 - val_f1: 0.5669\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5990 - acc: 0.6819 - f1: 0.6715 - val_loss: 0.7097 - val_acc: 0.5296 - val_f1: 0.5575\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5936 - acc: 0.6844 - f1: 0.6708 - val_loss: 0.7184 - val_acc: 0.5407 - val_f1: 0.5694\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5911 - acc: 0.6934 - f1: 0.6827 - val_loss: 0.7166 - val_acc: 0.4889 - val_f1: 0.4900\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5933 - acc: 0.6930 - f1: 0.6810 - val_loss: 0.7155 - val_acc: 0.5259 - val_f1: 0.5582\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5886 - acc: 0.6881 - f1: 0.6768 - val_loss: 0.7156 - val_acc: 0.5185 - val_f1: 0.5526\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5888 - acc: 0.6922 - f1: 0.6800 - val_loss: 0.7147 - val_acc: 0.5481 - val_f1: 0.5727\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5883 - acc: 0.7017 - f1: 0.6912 - val_loss: 0.7239 - val_acc: 0.5407 - val_f1: 0.5662\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5847 - acc: 0.6972 - f1: 0.6875 - val_loss: 0.7237 - val_acc: 0.5222 - val_f1: 0.5557\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5791 - acc: 0.6914 - f1: 0.6794 - val_loss: 0.7267 - val_acc: 0.5222 - val_f1: 0.5545\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5801 - acc: 0.7013 - f1: 0.6886 - val_loss: 0.7302 - val_acc: 0.5407 - val_f1: 0.5678\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5828 - acc: 0.6934 - f1: 0.6828 - val_loss: 0.7232 - val_acc: 0.5333 - val_f1: 0.5569\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5712 - acc: 0.7120 - f1: 0.7013 - val_loss: 0.7271 - val_acc: 0.5444 - val_f1: 0.5692\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5720 - acc: 0.7042 - f1: 0.6948 - val_loss: 0.7228 - val_acc: 0.5222 - val_f1: 0.5541\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5704 - acc: 0.7042 - f1: 0.6952 - val_loss: 0.7287 - val_acc: 0.5370 - val_f1: 0.5655\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5693 - acc: 0.7079 - f1: 0.6966 - val_loss: 0.7267 - val_acc: 0.5333 - val_f1: 0.5647\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5637 - acc: 0.7223 - f1: 0.7144 - val_loss: 0.7291 - val_acc: 0.5296 - val_f1: 0.5390\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5695 - acc: 0.7046 - f1: 0.6968 - val_loss: 0.7109 - val_acc: 0.5407 - val_f1: 0.5638\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5618 - acc: 0.7120 - f1: 0.7013 - val_loss: 0.7283 - val_acc: 0.5259 - val_f1: 0.5545\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5580 - acc: 0.7099 - f1: 0.6997 - val_loss: 0.7374 - val_acc: 0.5407 - val_f1: 0.5670\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5566 - acc: 0.7161 - f1: 0.7052 - val_loss: 0.7256 - val_acc: 0.5444 - val_f1: 0.5654\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5694 - acc: 0.6967 - f1: 0.6857 - val_loss: 0.7182 - val_acc: 0.5111 - val_f1: 0.5446\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5694 - acc: 0.7009 - f1: 0.6913 - val_loss: 0.7235 - val_acc: 0.5370 - val_f1: 0.5615\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5568 - acc: 0.7215 - f1: 0.7108 - val_loss: 0.7346 - val_acc: 0.5148 - val_f1: 0.5512\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5579 - acc: 0.7239 - f1: 0.7166 - val_loss: 0.7325 - val_acc: 0.5296 - val_f1: 0.5360\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5548 - acc: 0.7095 - f1: 0.7016 - val_loss: 0.7352 - val_acc: 0.5185 - val_f1: 0.5331\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5486 - acc: 0.7289 - f1: 0.7230 - val_loss: 0.7216 - val_acc: 0.5259 - val_f1: 0.5515\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.6916 - acc: 0.5303 - f1: 0.3894 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6892 - acc: 0.5529 - f1: 0.3565 - val_loss: 0.6917 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6883 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6881 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6872 - acc: 0.5529 - f1: 0.3557 - val_loss: 0.6941 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6864 - acc: 0.5542 - f1: 0.3586 - val_loss: 0.6942 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6855 - acc: 0.5534 - f1: 0.3574 - val_loss: 0.6950 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6844 - acc: 0.5542 - f1: 0.3677 - val_loss: 0.6953 - val_acc: 0.5333 - val_f1: 0.3485\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6850 - acc: 0.5492 - f1: 0.3670 - val_loss: 0.6970 - val_acc: 0.4556 - val_f1: 0.3796\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6836 - acc: 0.5534 - f1: 0.3789 - val_loss: 0.6984 - val_acc: 0.4667 - val_f1: 0.3855\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6831 - acc: 0.5554 - f1: 0.4098 - val_loss: 0.6987 - val_acc: 0.4296 - val_f1: 0.4742\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6875 - acc: 0.5484 - f1: 0.4037 - val_loss: 0.6992 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6840 - acc: 0.5542 - f1: 0.3702 - val_loss: 0.6974 - val_acc: 0.5444 - val_f1: 0.3797\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6828 - acc: 0.5542 - f1: 0.4301 - val_loss: 0.7010 - val_acc: 0.4148 - val_f1: 0.3748\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5505 - f1: 0.4448 - val_loss: 0.6979 - val_acc: 0.4444 - val_f1: 0.3885\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6845 - acc: 0.5707 - f1: 0.4954 - val_loss: 0.7010 - val_acc: 0.5259 - val_f1: 0.4042\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6812 - acc: 0.5600 - f1: 0.4225 - val_loss: 0.6981 - val_acc: 0.4556 - val_f1: 0.3958\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6803 - acc: 0.5575 - f1: 0.4531 - val_loss: 0.7010 - val_acc: 0.4593 - val_f1: 0.3888\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6826 - acc: 0.5501 - f1: 0.4696 - val_loss: 0.6994 - val_acc: 0.4852 - val_f1: 0.4027\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6805 - acc: 0.5575 - f1: 0.4231 - val_loss: 0.6993 - val_acc: 0.4815 - val_f1: 0.3926\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6817 - acc: 0.5645 - f1: 0.4607 - val_loss: 0.6968 - val_acc: 0.4852 - val_f1: 0.4016\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6791 - acc: 0.5624 - f1: 0.4493 - val_loss: 0.6968 - val_acc: 0.5370 - val_f1: 0.3899\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6792 - acc: 0.5600 - f1: 0.4417 - val_loss: 0.6973 - val_acc: 0.5000 - val_f1: 0.4152\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6801 - acc: 0.5665 - f1: 0.4640 - val_loss: 0.7018 - val_acc: 0.4444 - val_f1: 0.4685\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6782 - acc: 0.5727 - f1: 0.5023 - val_loss: 0.6988 - val_acc: 0.5222 - val_f1: 0.3808\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6773 - acc: 0.5731 - f1: 0.4954 - val_loss: 0.7030 - val_acc: 0.4741 - val_f1: 0.3951\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6753 - acc: 0.5649 - f1: 0.4580 - val_loss: 0.6975 - val_acc: 0.4889 - val_f1: 0.5047\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6754 - acc: 0.5661 - f1: 0.4884 - val_loss: 0.7015 - val_acc: 0.4519 - val_f1: 0.4082\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6742 - acc: 0.5748 - f1: 0.4996 - val_loss: 0.6966 - val_acc: 0.4963 - val_f1: 0.5519\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6730 - acc: 0.5814 - f1: 0.5248 - val_loss: 0.7020 - val_acc: 0.4741 - val_f1: 0.4645\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6715 - acc: 0.5686 - f1: 0.5012 - val_loss: 0.7056 - val_acc: 0.4444 - val_f1: 0.3899\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6723 - acc: 0.5682 - f1: 0.5030 - val_loss: 0.6974 - val_acc: 0.4963 - val_f1: 0.5317\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6666 - acc: 0.5925 - f1: 0.5436 - val_loss: 0.6995 - val_acc: 0.4889 - val_f1: 0.5399\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6691 - acc: 0.5830 - f1: 0.5361 - val_loss: 0.7065 - val_acc: 0.4741 - val_f1: 0.5432\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6674 - acc: 0.5884 - f1: 0.5455 - val_loss: 0.7048 - val_acc: 0.4667 - val_f1: 0.5116\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6655 - acc: 0.5822 - f1: 0.5324 - val_loss: 0.6997 - val_acc: 0.5111 - val_f1: 0.5486\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6629 - acc: 0.6044 - f1: 0.5701 - val_loss: 0.7016 - val_acc: 0.5000 - val_f1: 0.5558\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6629 - acc: 0.5941 - f1: 0.5539 - val_loss: 0.7003 - val_acc: 0.5037 - val_f1: 0.5387\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6612 - acc: 0.6040 - f1: 0.5734 - val_loss: 0.7004 - val_acc: 0.5000 - val_f1: 0.5364\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6612 - acc: 0.5888 - f1: 0.5559 - val_loss: 0.6973 - val_acc: 0.5407 - val_f1: 0.5249\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6603 - acc: 0.6053 - f1: 0.5775 - val_loss: 0.7110 - val_acc: 0.4667 - val_f1: 0.5382\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6577 - acc: 0.6148 - f1: 0.5870 - val_loss: 0.7002 - val_acc: 0.5000 - val_f1: 0.5284\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6551 - acc: 0.6036 - f1: 0.5733 - val_loss: 0.6945 - val_acc: 0.5222 - val_f1: 0.5298\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6570 - acc: 0.6094 - f1: 0.5817 - val_loss: 0.7039 - val_acc: 0.4963 - val_f1: 0.5359\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6576 - acc: 0.6057 - f1: 0.5732 - val_loss: 0.6987 - val_acc: 0.5185 - val_f1: 0.5516\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6573 - acc: 0.6123 - f1: 0.5785 - val_loss: 0.7063 - val_acc: 0.5000 - val_f1: 0.5400\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6526 - acc: 0.6160 - f1: 0.5998 - val_loss: 0.7112 - val_acc: 0.4778 - val_f1: 0.5309\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6538 - acc: 0.6102 - f1: 0.5817 - val_loss: 0.7071 - val_acc: 0.5037 - val_f1: 0.5631\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6477 - acc: 0.6230 - f1: 0.5984 - val_loss: 0.7019 - val_acc: 0.5259 - val_f1: 0.5624\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6465 - acc: 0.6180 - f1: 0.5890 - val_loss: 0.7052 - val_acc: 0.5148 - val_f1: 0.5498\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6471 - acc: 0.6267 - f1: 0.6058 - val_loss: 0.7065 - val_acc: 0.5185 - val_f1: 0.5537\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6451 - acc: 0.6209 - f1: 0.6020 - val_loss: 0.7129 - val_acc: 0.5000 - val_f1: 0.5572\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6418 - acc: 0.6292 - f1: 0.6020 - val_loss: 0.7075 - val_acc: 0.5407 - val_f1: 0.5859\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6427 - acc: 0.6325 - f1: 0.6131 - val_loss: 0.6988 - val_acc: 0.5407 - val_f1: 0.5566\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6356 - acc: 0.6345 - f1: 0.6127 - val_loss: 0.7222 - val_acc: 0.4815 - val_f1: 0.5441\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6395 - acc: 0.6374 - f1: 0.6209 - val_loss: 0.7186 - val_acc: 0.5074 - val_f1: 0.5668\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6336 - acc: 0.6428 - f1: 0.6264 - val_loss: 0.7036 - val_acc: 0.5333 - val_f1: 0.5435\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6363 - acc: 0.6333 - f1: 0.6107 - val_loss: 0.7176 - val_acc: 0.5074 - val_f1: 0.5665\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6341 - acc: 0.6461 - f1: 0.6260 - val_loss: 0.7019 - val_acc: 0.5481 - val_f1: 0.5833\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6331 - acc: 0.6382 - f1: 0.6224 - val_loss: 0.7049 - val_acc: 0.5741 - val_f1: 0.6069\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6293 - acc: 0.6403 - f1: 0.6212 - val_loss: 0.7102 - val_acc: 0.5407 - val_f1: 0.5846\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6299 - acc: 0.6452 - f1: 0.6253 - val_loss: 0.7296 - val_acc: 0.4963 - val_f1: 0.5321\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6265 - acc: 0.6531 - f1: 0.6385 - val_loss: 0.7202 - val_acc: 0.5444 - val_f1: 0.5625\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6216 - acc: 0.6461 - f1: 0.6285 - val_loss: 0.7132 - val_acc: 0.5333 - val_f1: 0.5783\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6243 - acc: 0.6444 - f1: 0.6214 - val_loss: 0.7105 - val_acc: 0.5185 - val_f1: 0.5700\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6254 - acc: 0.6481 - f1: 0.6375 - val_loss: 0.7024 - val_acc: 0.5296 - val_f1: 0.5744\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6184 - acc: 0.6625 - f1: 0.6454 - val_loss: 0.7162 - val_acc: 0.5148 - val_f1: 0.5654\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6234 - acc: 0.6506 - f1: 0.6417 - val_loss: 0.7025 - val_acc: 0.5444 - val_f1: 0.5903\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6179 - acc: 0.6597 - f1: 0.6423 - val_loss: 0.7133 - val_acc: 0.5222 - val_f1: 0.5751\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6125 - acc: 0.6654 - f1: 0.6534 - val_loss: 0.7141 - val_acc: 0.5333 - val_f1: 0.5748\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6133 - acc: 0.6580 - f1: 0.6453 - val_loss: 0.7126 - val_acc: 0.5407 - val_f1: 0.5342\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6123 - acc: 0.6766 - f1: 0.6584 - val_loss: 0.7280 - val_acc: 0.5148 - val_f1: 0.5710\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6101 - acc: 0.6568 - f1: 0.6458 - val_loss: 0.7183 - val_acc: 0.5481 - val_f1: 0.5869\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6074 - acc: 0.6658 - f1: 0.6518 - val_loss: 0.7148 - val_acc: 0.5407 - val_f1: 0.5672\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6083 - acc: 0.6741 - f1: 0.6629 - val_loss: 0.7156 - val_acc: 0.5222 - val_f1: 0.5759\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6015 - acc: 0.6708 - f1: 0.6562 - val_loss: 0.7129 - val_acc: 0.5444 - val_f1: 0.5693\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6026 - acc: 0.6807 - f1: 0.6704 - val_loss: 0.7312 - val_acc: 0.5148 - val_f1: 0.5254\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5969 - acc: 0.6728 - f1: 0.6620 - val_loss: 0.7194 - val_acc: 0.5333 - val_f1: 0.5608\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5948 - acc: 0.6782 - f1: 0.6655 - val_loss: 0.7335 - val_acc: 0.5296 - val_f1: 0.5373\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5956 - acc: 0.6790 - f1: 0.6679 - val_loss: 0.7207 - val_acc: 0.5222 - val_f1: 0.5732\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5956 - acc: 0.6811 - f1: 0.6677 - val_loss: 0.7303 - val_acc: 0.5074 - val_f1: 0.5211\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5913 - acc: 0.6848 - f1: 0.6745 - val_loss: 0.7161 - val_acc: 0.5296 - val_f1: 0.5442\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5850 - acc: 0.6889 - f1: 0.6722 - val_loss: 0.7333 - val_acc: 0.5296 - val_f1: 0.5796\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5911 - acc: 0.6885 - f1: 0.6795 - val_loss: 0.7289 - val_acc: 0.5259 - val_f1: 0.5717\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5855 - acc: 0.6934 - f1: 0.6840 - val_loss: 0.7515 - val_acc: 0.5333 - val_f1: 0.5564\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5892 - acc: 0.6836 - f1: 0.6714 - val_loss: 0.7440 - val_acc: 0.5296 - val_f1: 0.5540\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5867 - acc: 0.6782 - f1: 0.6673 - val_loss: 0.7411 - val_acc: 0.5074 - val_f1: 0.5629\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5775 - acc: 0.6930 - f1: 0.6837 - val_loss: 0.7295 - val_acc: 0.5370 - val_f1: 0.5374\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5820 - acc: 0.6963 - f1: 0.6871 - val_loss: 0.7302 - val_acc: 0.5296 - val_f1: 0.5802\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5734 - acc: 0.6918 - f1: 0.6799 - val_loss: 0.7360 - val_acc: 0.5222 - val_f1: 0.5312\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5724 - acc: 0.6959 - f1: 0.6849 - val_loss: 0.7435 - val_acc: 0.5148 - val_f1: 0.5509\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5622 - acc: 0.7042 - f1: 0.6949 - val_loss: 0.7460 - val_acc: 0.5222 - val_f1: 0.5562\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5691 - acc: 0.7124 - f1: 0.7015 - val_loss: 0.7415 - val_acc: 0.5074 - val_f1: 0.5467\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5731 - acc: 0.7000 - f1: 0.6932 - val_loss: 0.7518 - val_acc: 0.5111 - val_f1: 0.5691\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5719 - acc: 0.6980 - f1: 0.6875 - val_loss: 0.7432 - val_acc: 0.5111 - val_f1: 0.5251\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5648 - acc: 0.7009 - f1: 0.6925 - val_loss: 0.7462 - val_acc: 0.5148 - val_f1: 0.5260\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5665 - acc: 0.7108 - f1: 0.7006 - val_loss: 0.7563 - val_acc: 0.5333 - val_f1: 0.5626\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5591 - acc: 0.7132 - f1: 0.7040 - val_loss: 0.7592 - val_acc: 0.5000 - val_f1: 0.5408\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5573 - acc: 0.7087 - f1: 0.7003 - val_loss: 0.7400 - val_acc: 0.5148 - val_f1: 0.5501\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5523 - acc: 0.7202 - f1: 0.7125 - val_loss: 0.7492 - val_acc: 0.5185 - val_f1: 0.5287\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5548 - acc: 0.7091 - f1: 0.7021 - val_loss: 0.7411 - val_acc: 0.5259 - val_f1: 0.5501\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5618 - acc: 0.7058 - f1: 0.6945 - val_loss: 0.7556 - val_acc: 0.5333 - val_f1: 0.5622\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.6895 - acc: 0.5509 - f1: 0.3602 - val_loss: 0.6982 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6867 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.6931 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6875 - acc: 0.5521 - f1: 0.3562 - val_loss: 0.6972 - val_acc: 0.5111 - val_f1: 0.3763\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6862 - acc: 0.5546 - f1: 0.3591 - val_loss: 0.6978 - val_acc: 0.5259 - val_f1: 0.3413\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5525 - f1: 0.3565 - val_loss: 0.6952 - val_acc: 0.5259 - val_f1: 0.3413\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6862 - acc: 0.5525 - f1: 0.3556 - val_loss: 0.6949 - val_acc: 0.5296 - val_f1: 0.3519\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6861 - acc: 0.5546 - f1: 0.3709 - val_loss: 0.6989 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6885 - acc: 0.5546 - f1: 0.3845 - val_loss: 0.6935 - val_acc: 0.5444 - val_f1: 0.3868\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6849 - acc: 0.5534 - f1: 0.3564 - val_loss: 0.6977 - val_acc: 0.5148 - val_f1: 0.3966\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6848 - acc: 0.5567 - f1: 0.3776 - val_loss: 0.6949 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6848 - acc: 0.5587 - f1: 0.4108 - val_loss: 0.6992 - val_acc: 0.5333 - val_f1: 0.3709\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6848 - acc: 0.5542 - f1: 0.3885 - val_loss: 0.6952 - val_acc: 0.5333 - val_f1: 0.4134\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6833 - acc: 0.5579 - f1: 0.3908 - val_loss: 0.6996 - val_acc: 0.4444 - val_f1: 0.3924\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6823 - acc: 0.5571 - f1: 0.4381 - val_loss: 0.6981 - val_acc: 0.5037 - val_f1: 0.4061\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6826 - acc: 0.5546 - f1: 0.3849 - val_loss: 0.6972 - val_acc: 0.4333 - val_f1: 0.3857\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6814 - acc: 0.5517 - f1: 0.4327 - val_loss: 0.6968 - val_acc: 0.4111 - val_f1: 0.3783\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5653 - f1: 0.4201 - val_loss: 0.6977 - val_acc: 0.5148 - val_f1: 0.4093\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6816 - acc: 0.5575 - f1: 0.4480 - val_loss: 0.6999 - val_acc: 0.4593 - val_f1: 0.3995\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6813 - acc: 0.5616 - f1: 0.4544 - val_loss: 0.6982 - val_acc: 0.4481 - val_f1: 0.3931\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6780 - acc: 0.5558 - f1: 0.4214 - val_loss: 0.7011 - val_acc: 0.4185 - val_f1: 0.3800\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6786 - acc: 0.5567 - f1: 0.4428 - val_loss: 0.7029 - val_acc: 0.4185 - val_f1: 0.3810\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6812 - acc: 0.5571 - f1: 0.4418 - val_loss: 0.7039 - val_acc: 0.4111 - val_f1: 0.3800\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6789 - acc: 0.5616 - f1: 0.4581 - val_loss: 0.7070 - val_acc: 0.3963 - val_f1: 0.3672\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6777 - acc: 0.5686 - f1: 0.4878 - val_loss: 0.7093 - val_acc: 0.4111 - val_f1: 0.3808\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6774 - acc: 0.5748 - f1: 0.5055 - val_loss: 0.7025 - val_acc: 0.4407 - val_f1: 0.3890\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6744 - acc: 0.5797 - f1: 0.5182 - val_loss: 0.7080 - val_acc: 0.4259 - val_f1: 0.3802\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6759 - acc: 0.5690 - f1: 0.5110 - val_loss: 0.6999 - val_acc: 0.4333 - val_f1: 0.3838\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6733 - acc: 0.5727 - f1: 0.4838 - val_loss: 0.7030 - val_acc: 0.4259 - val_f1: 0.4222\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6720 - acc: 0.5810 - f1: 0.5358 - val_loss: 0.7128 - val_acc: 0.4259 - val_f1: 0.4171\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6725 - acc: 0.5748 - f1: 0.5331 - val_loss: 0.7098 - val_acc: 0.5111 - val_f1: 0.3923\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6698 - acc: 0.5764 - f1: 0.5026 - val_loss: 0.7116 - val_acc: 0.4370 - val_f1: 0.3850\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6665 - acc: 0.5851 - f1: 0.5287 - val_loss: 0.7038 - val_acc: 0.4519 - val_f1: 0.5076\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6679 - acc: 0.5979 - f1: 0.5627 - val_loss: 0.7287 - val_acc: 0.4259 - val_f1: 0.3860\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6688 - acc: 0.5884 - f1: 0.5444 - val_loss: 0.7093 - val_acc: 0.4333 - val_f1: 0.4695\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6660 - acc: 0.5925 - f1: 0.5422 - val_loss: 0.7126 - val_acc: 0.4370 - val_f1: 0.4627\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6605 - acc: 0.6135 - f1: 0.5814 - val_loss: 0.7279 - val_acc: 0.4556 - val_f1: 0.4349\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6587 - acc: 0.6082 - f1: 0.5768 - val_loss: 0.7290 - val_acc: 0.4259 - val_f1: 0.4876\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6611 - acc: 0.6127 - f1: 0.5812 - val_loss: 0.7139 - val_acc: 0.4815 - val_f1: 0.5108\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6566 - acc: 0.6086 - f1: 0.5700 - val_loss: 0.7258 - val_acc: 0.4481 - val_f1: 0.5036\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6589 - acc: 0.6065 - f1: 0.5784 - val_loss: 0.7271 - val_acc: 0.4519 - val_f1: 0.5257\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6489 - acc: 0.6127 - f1: 0.5848 - val_loss: 0.7283 - val_acc: 0.4667 - val_f1: 0.4688\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6502 - acc: 0.6164 - f1: 0.5872 - val_loss: 0.7291 - val_acc: 0.4704 - val_f1: 0.5387\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6487 - acc: 0.6304 - f1: 0.6063 - val_loss: 0.7317 - val_acc: 0.4556 - val_f1: 0.5095\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6482 - acc: 0.6218 - f1: 0.5997 - val_loss: 0.7234 - val_acc: 0.4815 - val_f1: 0.5275\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6458 - acc: 0.6226 - f1: 0.6012 - val_loss: 0.7325 - val_acc: 0.4741 - val_f1: 0.5229\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6413 - acc: 0.6325 - f1: 0.6104 - val_loss: 0.7321 - val_acc: 0.4667 - val_f1: 0.5184\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6367 - acc: 0.6428 - f1: 0.6249 - val_loss: 0.7284 - val_acc: 0.4593 - val_f1: 0.4958\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6335 - acc: 0.6461 - f1: 0.6198 - val_loss: 0.7499 - val_acc: 0.4667 - val_f1: 0.5169\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6358 - acc: 0.6399 - f1: 0.6230 - val_loss: 0.7283 - val_acc: 0.4889 - val_f1: 0.5215\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6344 - acc: 0.6337 - f1: 0.6208 - val_loss: 0.7528 - val_acc: 0.4556 - val_f1: 0.4752\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6298 - acc: 0.6510 - f1: 0.6301 - val_loss: 0.7505 - val_acc: 0.4778 - val_f1: 0.5443\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6291 - acc: 0.6461 - f1: 0.6261 - val_loss: 0.7233 - val_acc: 0.5000 - val_f1: 0.5614\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6239 - acc: 0.6560 - f1: 0.6426 - val_loss: 0.7479 - val_acc: 0.4741 - val_f1: 0.5383\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6209 - acc: 0.6547 - f1: 0.6356 - val_loss: 0.7444 - val_acc: 0.4593 - val_f1: 0.5125\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6183 - acc: 0.6539 - f1: 0.6408 - val_loss: 0.7290 - val_acc: 0.5111 - val_f1: 0.5694\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6187 - acc: 0.6613 - f1: 0.6482 - val_loss: 0.7411 - val_acc: 0.4741 - val_f1: 0.5219\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6233 - acc: 0.6485 - f1: 0.6376 - val_loss: 0.7384 - val_acc: 0.4926 - val_f1: 0.5490\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6194 - acc: 0.6555 - f1: 0.6323 - val_loss: 0.7183 - val_acc: 0.5000 - val_f1: 0.5408\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6147 - acc: 0.6646 - f1: 0.6519 - val_loss: 0.7289 - val_acc: 0.5074 - val_f1: 0.5465\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6076 - acc: 0.6716 - f1: 0.6589 - val_loss: 0.7611 - val_acc: 0.4889 - val_f1: 0.5332\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6056 - acc: 0.6675 - f1: 0.6591 - val_loss: 0.7397 - val_acc: 0.4963 - val_f1: 0.5388\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6067 - acc: 0.6691 - f1: 0.6543 - val_loss: 0.7308 - val_acc: 0.4926 - val_f1: 0.5562\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6024 - acc: 0.6790 - f1: 0.6678 - val_loss: 0.7230 - val_acc: 0.5037 - val_f1: 0.5620\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6024 - acc: 0.6728 - f1: 0.6601 - val_loss: 0.7260 - val_acc: 0.5037 - val_f1: 0.5440\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5992 - acc: 0.6877 - f1: 0.6776 - val_loss: 0.7331 - val_acc: 0.5037 - val_f1: 0.5440\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5987 - acc: 0.6786 - f1: 0.6671 - val_loss: 0.7445 - val_acc: 0.4778 - val_f1: 0.5419\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6006 - acc: 0.6819 - f1: 0.6707 - val_loss: 0.7576 - val_acc: 0.4852 - val_f1: 0.5493\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5917 - acc: 0.6786 - f1: 0.6665 - val_loss: 0.7267 - val_acc: 0.5259 - val_f1: 0.5600\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5899 - acc: 0.6881 - f1: 0.6772 - val_loss: 0.7460 - val_acc: 0.4926 - val_f1: 0.5562\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5805 - acc: 0.6988 - f1: 0.6890 - val_loss: 0.7385 - val_acc: 0.4889 - val_f1: 0.5331\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5872 - acc: 0.6939 - f1: 0.6818 - val_loss: 0.7516 - val_acc: 0.4889 - val_f1: 0.5525\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5869 - acc: 0.6930 - f1: 0.6828 - val_loss: 0.7294 - val_acc: 0.5111 - val_f1: 0.5485\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5857 - acc: 0.6902 - f1: 0.6784 - val_loss: 0.7490 - val_acc: 0.4889 - val_f1: 0.5339\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5761 - acc: 0.6934 - f1: 0.6852 - val_loss: 0.7563 - val_acc: 0.4852 - val_f1: 0.5501\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5801 - acc: 0.6976 - f1: 0.6897 - val_loss: 0.7549 - val_acc: 0.4963 - val_f1: 0.5543\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5682 - acc: 0.7009 - f1: 0.6875 - val_loss: 0.7603 - val_acc: 0.4926 - val_f1: 0.5732\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5756 - acc: 0.7054 - f1: 0.6979 - val_loss: 0.7744 - val_acc: 0.5074 - val_f1: 0.5661\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5687 - acc: 0.7091 - f1: 0.6995 - val_loss: 0.7355 - val_acc: 0.5185 - val_f1: 0.5547\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5713 - acc: 0.7050 - f1: 0.6960 - val_loss: 0.7739 - val_acc: 0.4963 - val_f1: 0.5578\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5666 - acc: 0.7128 - f1: 0.7036 - val_loss: 0.7426 - val_acc: 0.5000 - val_f1: 0.5410\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5614 - acc: 0.7112 - f1: 0.7025 - val_loss: 0.7444 - val_acc: 0.5037 - val_f1: 0.5604\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5541 - acc: 0.7194 - f1: 0.7106 - val_loss: 0.7879 - val_acc: 0.4815 - val_f1: 0.5482\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5608 - acc: 0.7087 - f1: 0.6991 - val_loss: 0.7748 - val_acc: 0.5000 - val_f1: 0.5597\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5539 - acc: 0.7194 - f1: 0.7121 - val_loss: 0.7964 - val_acc: 0.4926 - val_f1: 0.5708\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5564 - acc: 0.7095 - f1: 0.6978 - val_loss: 0.7714 - val_acc: 0.4630 - val_f1: 0.5152\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5421 - acc: 0.7268 - f1: 0.7182 - val_loss: 0.7798 - val_acc: 0.5037 - val_f1: 0.5595\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5473 - acc: 0.7153 - f1: 0.7062 - val_loss: 0.7847 - val_acc: 0.5000 - val_f1: 0.5535\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5478 - acc: 0.7141 - f1: 0.7057 - val_loss: 0.8055 - val_acc: 0.4667 - val_f1: 0.5181\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5364 - acc: 0.7285 - f1: 0.7205 - val_loss: 0.7711 - val_acc: 0.4667 - val_f1: 0.5380\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5434 - acc: 0.7223 - f1: 0.7152 - val_loss: 0.7982 - val_acc: 0.4926 - val_f1: 0.5547\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5352 - acc: 0.7330 - f1: 0.7237 - val_loss: 0.8099 - val_acc: 0.4963 - val_f1: 0.5391\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5360 - acc: 0.7297 - f1: 0.7222 - val_loss: 0.7870 - val_acc: 0.4556 - val_f1: 0.5236\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5388 - acc: 0.7322 - f1: 0.7230 - val_loss: 0.7925 - val_acc: 0.5000 - val_f1: 0.5609\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5260 - acc: 0.7437 - f1: 0.7372 - val_loss: 0.7917 - val_acc: 0.4556 - val_f1: 0.5104\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5358 - acc: 0.7248 - f1: 0.7183 - val_loss: 0.7829 - val_acc: 0.4889 - val_f1: 0.5537\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5266 - acc: 0.7487 - f1: 0.7401 - val_loss: 0.7719 - val_acc: 0.4963 - val_f1: 0.5560\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5301 - acc: 0.7351 - f1: 0.7279 - val_loss: 0.8090 - val_acc: 0.4667 - val_f1: 0.5182\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5269 - acc: 0.7351 - f1: 0.7288 - val_loss: 0.8272 - val_acc: 0.4556 - val_f1: 0.4764\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5152 - acc: 0.7524 - f1: 0.7450 - val_loss: 0.8029 - val_acc: 0.4926 - val_f1: 0.5547\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5169 - acc: 0.7421 - f1: 0.7342 - val_loss: 0.8438 - val_acc: 0.4704 - val_f1: 0.4972\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5139 - acc: 0.7474 - f1: 0.7423 - val_loss: 0.8443 - val_acc: 0.4593 - val_f1: 0.5079\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5169 - acc: 0.7478 - f1: 0.7402 - val_loss: 0.8130 - val_acc: 0.4889 - val_f1: 0.5533\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6908 - acc: 0.5385 - f1: 0.3589 - val_loss: 0.6914 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6883 - acc: 0.5538 - f1: 0.3567 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6876 - acc: 0.5534 - f1: 0.3584 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6882 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6865 - acc: 0.5534 - f1: 0.3567 - val_loss: 0.6936 - val_acc: 0.5222 - val_f1: 0.3604\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6874 - acc: 0.5521 - f1: 0.3658 - val_loss: 0.6937 - val_acc: 0.5148 - val_f1: 0.3640\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5538 - f1: 0.3642 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5546 - f1: 0.3692 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5534 - f1: 0.3588 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6828 - acc: 0.5595 - f1: 0.3903 - val_loss: 0.6953 - val_acc: 0.5333 - val_f1: 0.3695\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6847 - acc: 0.5554 - f1: 0.3967 - val_loss: 0.6937 - val_acc: 0.5259 - val_f1: 0.3833\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6838 - acc: 0.5538 - f1: 0.3934 - val_loss: 0.6939 - val_acc: 0.5037 - val_f1: 0.4034\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6831 - acc: 0.5587 - f1: 0.4193 - val_loss: 0.6951 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6839 - acc: 0.5546 - f1: 0.3811 - val_loss: 0.6936 - val_acc: 0.4667 - val_f1: 0.3965\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6833 - acc: 0.5550 - f1: 0.3906 - val_loss: 0.6941 - val_acc: 0.5333 - val_f1: 0.3820\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5550 - f1: 0.3929 - val_loss: 0.6938 - val_acc: 0.5111 - val_f1: 0.3841\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6822 - acc: 0.5529 - f1: 0.3807 - val_loss: 0.6938 - val_acc: 0.5148 - val_f1: 0.3423\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6815 - acc: 0.5649 - f1: 0.4221 - val_loss: 0.6936 - val_acc: 0.5037 - val_f1: 0.3725\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6810 - acc: 0.5608 - f1: 0.4196 - val_loss: 0.6941 - val_acc: 0.5185 - val_f1: 0.3478\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6808 - acc: 0.5567 - f1: 0.4191 - val_loss: 0.6944 - val_acc: 0.5074 - val_f1: 0.3749\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6794 - acc: 0.5657 - f1: 0.4482 - val_loss: 0.6946 - val_acc: 0.5185 - val_f1: 0.3863\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6816 - acc: 0.5649 - f1: 0.4512 - val_loss: 0.6979 - val_acc: 0.5259 - val_f1: 0.3553\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6788 - acc: 0.5698 - f1: 0.4351 - val_loss: 0.6971 - val_acc: 0.5296 - val_f1: 0.3518\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6792 - acc: 0.5707 - f1: 0.4884 - val_loss: 0.6982 - val_acc: 0.5074 - val_f1: 0.3785\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6786 - acc: 0.5670 - f1: 0.4648 - val_loss: 0.6966 - val_acc: 0.4926 - val_f1: 0.4060\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6771 - acc: 0.5682 - f1: 0.4635 - val_loss: 0.6966 - val_acc: 0.5185 - val_f1: 0.3894\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6758 - acc: 0.5748 - f1: 0.4902 - val_loss: 0.6982 - val_acc: 0.4704 - val_f1: 0.3981\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6743 - acc: 0.5830 - f1: 0.4843 - val_loss: 0.6998 - val_acc: 0.4593 - val_f1: 0.4432\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6741 - acc: 0.5781 - f1: 0.5004 - val_loss: 0.6962 - val_acc: 0.4704 - val_f1: 0.4876\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6751 - acc: 0.5752 - f1: 0.5051 - val_loss: 0.7010 - val_acc: 0.5000 - val_f1: 0.4018\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6720 - acc: 0.5797 - f1: 0.5125 - val_loss: 0.6943 - val_acc: 0.5074 - val_f1: 0.4959\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6702 - acc: 0.5859 - f1: 0.5312 - val_loss: 0.6942 - val_acc: 0.5074 - val_f1: 0.4611\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6719 - acc: 0.5789 - f1: 0.5115 - val_loss: 0.6978 - val_acc: 0.4889 - val_f1: 0.4968\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6689 - acc: 0.5888 - f1: 0.5218 - val_loss: 0.6958 - val_acc: 0.4704 - val_f1: 0.4553\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6699 - acc: 0.5871 - f1: 0.5373 - val_loss: 0.7004 - val_acc: 0.4630 - val_f1: 0.5014\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6676 - acc: 0.6028 - f1: 0.5586 - val_loss: 0.6992 - val_acc: 0.4852 - val_f1: 0.5230\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6641 - acc: 0.5966 - f1: 0.5460 - val_loss: 0.6951 - val_acc: 0.5074 - val_f1: 0.5242\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6626 - acc: 0.6003 - f1: 0.5450 - val_loss: 0.6966 - val_acc: 0.5000 - val_f1: 0.4587\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6611 - acc: 0.5974 - f1: 0.5586 - val_loss: 0.6963 - val_acc: 0.5148 - val_f1: 0.5517\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6617 - acc: 0.5958 - f1: 0.5552 - val_loss: 0.6960 - val_acc: 0.4926 - val_f1: 0.5112\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6587 - acc: 0.6090 - f1: 0.5798 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1: 0.5410\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6592 - acc: 0.6077 - f1: 0.5726 - val_loss: 0.6904 - val_acc: 0.5259 - val_f1: 0.5160\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6566 - acc: 0.5999 - f1: 0.5625 - val_loss: 0.6907 - val_acc: 0.5185 - val_f1: 0.5612\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6541 - acc: 0.6189 - f1: 0.5933 - val_loss: 0.6976 - val_acc: 0.5148 - val_f1: 0.5360\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6499 - acc: 0.6242 - f1: 0.5969 - val_loss: 0.6934 - val_acc: 0.5407 - val_f1: 0.5537\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6488 - acc: 0.6288 - f1: 0.6040 - val_loss: 0.7021 - val_acc: 0.4889 - val_f1: 0.5467\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6455 - acc: 0.6288 - f1: 0.6078 - val_loss: 0.6873 - val_acc: 0.5259 - val_f1: 0.5565\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6460 - acc: 0.6209 - f1: 0.6022 - val_loss: 0.6866 - val_acc: 0.5259 - val_f1: 0.5423\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6385 - acc: 0.6382 - f1: 0.6189 - val_loss: 0.6903 - val_acc: 0.5074 - val_f1: 0.5194\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6398 - acc: 0.6354 - f1: 0.6149 - val_loss: 0.6903 - val_acc: 0.5148 - val_f1: 0.5485\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6394 - acc: 0.6403 - f1: 0.6271 - val_loss: 0.6971 - val_acc: 0.4963 - val_f1: 0.5375\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6344 - acc: 0.6489 - f1: 0.6298 - val_loss: 0.6862 - val_acc: 0.4963 - val_f1: 0.5176\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6351 - acc: 0.6498 - f1: 0.6345 - val_loss: 0.6754 - val_acc: 0.5593 - val_f1: 0.5622\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6351 - acc: 0.6341 - f1: 0.6183 - val_loss: 0.6928 - val_acc: 0.4889 - val_f1: 0.5299\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6273 - acc: 0.6481 - f1: 0.6291 - val_loss: 0.7025 - val_acc: 0.5296 - val_f1: 0.5625\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6283 - acc: 0.6547 - f1: 0.6434 - val_loss: 0.6814 - val_acc: 0.5593 - val_f1: 0.5823\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6266 - acc: 0.6531 - f1: 0.6411 - val_loss: 0.6843 - val_acc: 0.5333 - val_f1: 0.5577\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6229 - acc: 0.6654 - f1: 0.6522 - val_loss: 0.6809 - val_acc: 0.5444 - val_f1: 0.5651\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6212 - acc: 0.6477 - f1: 0.6283 - val_loss: 0.6810 - val_acc: 0.5556 - val_f1: 0.6001\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6219 - acc: 0.6424 - f1: 0.6333 - val_loss: 0.6961 - val_acc: 0.5111 - val_f1: 0.5458\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6182 - acc: 0.6658 - f1: 0.6519 - val_loss: 0.6755 - val_acc: 0.5741 - val_f1: 0.6268\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6135 - acc: 0.6617 - f1: 0.6495 - val_loss: 0.6905 - val_acc: 0.5296 - val_f1: 0.5487\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6160 - acc: 0.6630 - f1: 0.6473 - val_loss: 0.6828 - val_acc: 0.5259 - val_f1: 0.5559\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6078 - acc: 0.6728 - f1: 0.6602 - val_loss: 0.6729 - val_acc: 0.5222 - val_f1: 0.5641\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6033 - acc: 0.6728 - f1: 0.6620 - val_loss: 0.6858 - val_acc: 0.5074 - val_f1: 0.5440\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6046 - acc: 0.6712 - f1: 0.6615 - val_loss: 0.6847 - val_acc: 0.5407 - val_f1: 0.5887\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6076 - acc: 0.6654 - f1: 0.6524 - val_loss: 0.6766 - val_acc: 0.5630 - val_f1: 0.6037\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6021 - acc: 0.6766 - f1: 0.6662 - val_loss: 0.6859 - val_acc: 0.5222 - val_f1: 0.5535\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6015 - acc: 0.6733 - f1: 0.6580 - val_loss: 0.6825 - val_acc: 0.5259 - val_f1: 0.5548\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6029 - acc: 0.6733 - f1: 0.6621 - val_loss: 0.6857 - val_acc: 0.5296 - val_f1: 0.5562\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6011 - acc: 0.6741 - f1: 0.6654 - val_loss: 0.6809 - val_acc: 0.5407 - val_f1: 0.6113\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5947 - acc: 0.6766 - f1: 0.6628 - val_loss: 0.6840 - val_acc: 0.5259 - val_f1: 0.5598\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5931 - acc: 0.6811 - f1: 0.6721 - val_loss: 0.6826 - val_acc: 0.5556 - val_f1: 0.5795\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5854 - acc: 0.6922 - f1: 0.6832 - val_loss: 0.6923 - val_acc: 0.5333 - val_f1: 0.5225\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5833 - acc: 0.6881 - f1: 0.6781 - val_loss: 0.6913 - val_acc: 0.5259 - val_f1: 0.5507\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5839 - acc: 0.6963 - f1: 0.6866 - val_loss: 0.6986 - val_acc: 0.5556 - val_f1: 0.5784\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5826 - acc: 0.6869 - f1: 0.6774 - val_loss: 0.6821 - val_acc: 0.5370 - val_f1: 0.5425\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5779 - acc: 0.7017 - f1: 0.6906 - val_loss: 0.6980 - val_acc: 0.5481 - val_f1: 0.5514\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5798 - acc: 0.6930 - f1: 0.6823 - val_loss: 0.6828 - val_acc: 0.5370 - val_f1: 0.5815\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5770 - acc: 0.7033 - f1: 0.6962 - val_loss: 0.7059 - val_acc: 0.5370 - val_f1: 0.5799\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5753 - acc: 0.6992 - f1: 0.6914 - val_loss: 0.6920 - val_acc: 0.5444 - val_f1: 0.5767\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5785 - acc: 0.7017 - f1: 0.6919 - val_loss: 0.6893 - val_acc: 0.5333 - val_f1: 0.5818\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5782 - acc: 0.6959 - f1: 0.6865 - val_loss: 0.6859 - val_acc: 0.5296 - val_f1: 0.5536\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5682 - acc: 0.7017 - f1: 0.6892 - val_loss: 0.6966 - val_acc: 0.5222 - val_f1: 0.5758\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5771 - acc: 0.6914 - f1: 0.6835 - val_loss: 0.7190 - val_acc: 0.5556 - val_f1: 0.5745\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5704 - acc: 0.7042 - f1: 0.6938 - val_loss: 0.7006 - val_acc: 0.5407 - val_f1: 0.5687\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5641 - acc: 0.7178 - f1: 0.7107 - val_loss: 0.7025 - val_acc: 0.5222 - val_f1: 0.5518\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5632 - acc: 0.7116 - f1: 0.7050 - val_loss: 0.6972 - val_acc: 0.5148 - val_f1: 0.4990\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5610 - acc: 0.7202 - f1: 0.7117 - val_loss: 0.6973 - val_acc: 0.5519 - val_f1: 0.5988\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5552 - acc: 0.7153 - f1: 0.7084 - val_loss: 0.7023 - val_acc: 0.5481 - val_f1: 0.5647\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5635 - acc: 0.7120 - f1: 0.7060 - val_loss: 0.7078 - val_acc: 0.5111 - val_f1: 0.5138\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5528 - acc: 0.7182 - f1: 0.7097 - val_loss: 0.7162 - val_acc: 0.5333 - val_f1: 0.5850\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5414 - acc: 0.7330 - f1: 0.7263 - val_loss: 0.7095 - val_acc: 0.5333 - val_f1: 0.5842\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5473 - acc: 0.7141 - f1: 0.7037 - val_loss: 0.7023 - val_acc: 0.5444 - val_f1: 0.5561\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5506 - acc: 0.7211 - f1: 0.7152 - val_loss: 0.7256 - val_acc: 0.5222 - val_f1: 0.5522\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5406 - acc: 0.7334 - f1: 0.7261 - val_loss: 0.7181 - val_acc: 0.5519 - val_f1: 0.5975\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5509 - acc: 0.7194 - f1: 0.7116 - val_loss: 0.7213 - val_acc: 0.5259 - val_f1: 0.5432\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5398 - acc: 0.7326 - f1: 0.7250 - val_loss: 0.7228 - val_acc: 0.5259 - val_f1: 0.5264\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5386 - acc: 0.7322 - f1: 0.7258 - val_loss: 0.7185 - val_acc: 0.5222 - val_f1: 0.5761\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5335 - acc: 0.7367 - f1: 0.7273 - val_loss: 0.7228 - val_acc: 0.5481 - val_f1: 0.6161\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5360 - acc: 0.7334 - f1: 0.7277 - val_loss: 0.7175 - val_acc: 0.5444 - val_f1: 0.5720\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5391 - acc: 0.7293 - f1: 0.7174 - val_loss: 0.7163 - val_acc: 0.5074 - val_f1: 0.5664\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5344 - acc: 0.7355 - f1: 0.7289 - val_loss: 0.7262 - val_acc: 0.5444 - val_f1: 0.5630\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5276 - acc: 0.7392 - f1: 0.7335 - val_loss: 0.7448 - val_acc: 0.5333 - val_f1: 0.5472\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5300 - acc: 0.7351 - f1: 0.7285 - val_loss: 0.7247 - val_acc: 0.5222 - val_f1: 0.5520\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5247 - acc: 0.7569 - f1: 0.7497 - val_loss: 0.7305 - val_acc: 0.5296 - val_f1: 0.5743\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5214 - acc: 0.7400 - f1: 0.7324 - val_loss: 0.7325 - val_acc: 0.5185 - val_f1: 0.5374\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5277 - acc: 0.7363 - f1: 0.7289 - val_loss: 0.7338 - val_acc: 0.5407 - val_f1: 0.5594\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5211 - acc: 0.7355 - f1: 0.7312 - val_loss: 0.7459 - val_acc: 0.5296 - val_f1: 0.5559\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5225 - acc: 0.7400 - f1: 0.7329 - val_loss: 0.7408 - val_acc: 0.5333 - val_f1: 0.5840\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5151 - acc: 0.7450 - f1: 0.7372 - val_loss: 0.7451 - val_acc: 0.5148 - val_f1: 0.5653\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5191 - acc: 0.7404 - f1: 0.7341 - val_loss: 0.7528 - val_acc: 0.5074 - val_f1: 0.5254\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5101 - acc: 0.7540 - f1: 0.7478 - val_loss: 0.7450 - val_acc: 0.5148 - val_f1: 0.5629\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5071 - acc: 0.7635 - f1: 0.7568 - val_loss: 0.7600 - val_acc: 0.4963 - val_f1: 0.5520\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5154 - acc: 0.7429 - f1: 0.7380 - val_loss: 0.7375 - val_acc: 0.5407 - val_f1: 0.5896\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5066 - acc: 0.7590 - f1: 0.7512 - val_loss: 0.7528 - val_acc: 0.5407 - val_f1: 0.5902\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5013 - acc: 0.7614 - f1: 0.7558 - val_loss: 0.7346 - val_acc: 0.5148 - val_f1: 0.5352\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5056 - acc: 0.7561 - f1: 0.7502 - val_loss: 0.7483 - val_acc: 0.4926 - val_f1: 0.5499\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5034 - acc: 0.7536 - f1: 0.7472 - val_loss: 0.7604 - val_acc: 0.5222 - val_f1: 0.5570\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4982 - acc: 0.7643 - f1: 0.7579 - val_loss: 0.7578 - val_acc: 0.5074 - val_f1: 0.5404\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5010 - acc: 0.7623 - f1: 0.7558 - val_loss: 0.7505 - val_acc: 0.5074 - val_f1: 0.5449\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4971 - acc: 0.7594 - f1: 0.7525 - val_loss: 0.7639 - val_acc: 0.5111 - val_f1: 0.5326\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4945 - acc: 0.7656 - f1: 0.7603 - val_loss: 0.7620 - val_acc: 0.5074 - val_f1: 0.5463\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4845 - acc: 0.7705 - f1: 0.7648 - val_loss: 0.7607 - val_acc: 0.5259 - val_f1: 0.5779\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4940 - acc: 0.7684 - f1: 0.7608 - val_loss: 0.7623 - val_acc: 0.5259 - val_f1: 0.5432\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4941 - acc: 0.7569 - f1: 0.7494 - val_loss: 0.7640 - val_acc: 0.5037 - val_f1: 0.5575\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4775 - acc: 0.7771 - f1: 0.7724 - val_loss: 0.7692 - val_acc: 0.5259 - val_f1: 0.5995\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4898 - acc: 0.7660 - f1: 0.7596 - val_loss: 0.7896 - val_acc: 0.5259 - val_f1: 0.5693\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4848 - acc: 0.7676 - f1: 0.7618 - val_loss: 0.7872 - val_acc: 0.5185 - val_f1: 0.6180\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4794 - acc: 0.7717 - f1: 0.7667 - val_loss: 0.7753 - val_acc: 0.5111 - val_f1: 0.5619\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4847 - acc: 0.7672 - f1: 0.7622 - val_loss: 0.7678 - val_acc: 0.5259 - val_f1: 0.5728\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4826 - acc: 0.7697 - f1: 0.7625 - val_loss: 0.8030 - val_acc: 0.4963 - val_f1: 0.5218\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4817 - acc: 0.7693 - f1: 0.7641 - val_loss: 0.7667 - val_acc: 0.5037 - val_f1: 0.5639\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4819 - acc: 0.7684 - f1: 0.7630 - val_loss: 0.7810 - val_acc: 0.5222 - val_f1: 0.5706\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4790 - acc: 0.7792 - f1: 0.7742 - val_loss: 0.8052 - val_acc: 0.5000 - val_f1: 0.5352\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4732 - acc: 0.7734 - f1: 0.7674 - val_loss: 0.8011 - val_acc: 0.4963 - val_f1: 0.5778\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4726 - acc: 0.7647 - f1: 0.7588 - val_loss: 0.7782 - val_acc: 0.5222 - val_f1: 0.6201\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4726 - acc: 0.7754 - f1: 0.7694 - val_loss: 0.8121 - val_acc: 0.5074 - val_f1: 0.5591\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4681 - acc: 0.7820 - f1: 0.7768 - val_loss: 0.7911 - val_acc: 0.5148 - val_f1: 0.5719\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4735 - acc: 0.7829 - f1: 0.7781 - val_loss: 0.7998 - val_acc: 0.5296 - val_f1: 0.5756\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4611 - acc: 0.7849 - f1: 0.7806 - val_loss: 0.8092 - val_acc: 0.4963 - val_f1: 0.5803\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4638 - acc: 0.7808 - f1: 0.7761 - val_loss: 0.8177 - val_acc: 0.5444 - val_f1: 0.5858\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4649 - acc: 0.7800 - f1: 0.7750 - val_loss: 0.7922 - val_acc: 0.5074 - val_f1: 0.5661\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4720 - acc: 0.7750 - f1: 0.7701 - val_loss: 0.8156 - val_acc: 0.5148 - val_f1: 0.5650\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4617 - acc: 0.7792 - f1: 0.7741 - val_loss: 0.8078 - val_acc: 0.5185 - val_f1: 0.5939\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4613 - acc: 0.7886 - f1: 0.7834 - val_loss: 0.7928 - val_acc: 0.5333 - val_f1: 0.6078\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4580 - acc: 0.7837 - f1: 0.7803 - val_loss: 0.8297 - val_acc: 0.5037 - val_f1: 0.5565\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4596 - acc: 0.7849 - f1: 0.7788 - val_loss: 0.7953 - val_acc: 0.5148 - val_f1: 0.5651\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4620 - acc: 0.7804 - f1: 0.7759 - val_loss: 0.8367 - val_acc: 0.5037 - val_f1: 0.5626\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4522 - acc: 0.7882 - f1: 0.7831 - val_loss: 0.8226 - val_acc: 0.5111 - val_f1: 0.6124\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4471 - acc: 0.8018 - f1: 0.7966 - val_loss: 0.8254 - val_acc: 0.5000 - val_f1: 0.5833\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4447 - acc: 0.7915 - f1: 0.7867 - val_loss: 0.8286 - val_acc: 0.5111 - val_f1: 0.5698\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4605 - acc: 0.7824 - f1: 0.7776 - val_loss: 0.8497 - val_acc: 0.5000 - val_f1: 0.6045\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4468 - acc: 0.7989 - f1: 0.7945 - val_loss: 0.8462 - val_acc: 0.4963 - val_f1: 0.5057\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4511 - acc: 0.7820 - f1: 0.7768 - val_loss: 0.8517 - val_acc: 0.5074 - val_f1: 0.5595\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4436 - acc: 0.7944 - f1: 0.7908 - val_loss: 0.8541 - val_acc: 0.5000 - val_f1: 0.5599\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4410 - acc: 0.8068 - f1: 0.8035 - val_loss: 0.8388 - val_acc: 0.5111 - val_f1: 0.5899\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4391 - acc: 0.7940 - f1: 0.7892 - val_loss: 0.8592 - val_acc: 0.5037 - val_f1: 0.5439\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4470 - acc: 0.7849 - f1: 0.7802 - val_loss: 0.8601 - val_acc: 0.4852 - val_f1: 0.5440\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4391 - acc: 0.7960 - f1: 0.7918 - val_loss: 0.8407 - val_acc: 0.5148 - val_f1: 0.5698\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4445 - acc: 0.7960 - f1: 0.7914 - val_loss: 0.8396 - val_acc: 0.5074 - val_f1: 0.5854\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4429 - acc: 0.8035 - f1: 0.7993 - val_loss: 0.8409 - val_acc: 0.5000 - val_f1: 0.5609\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4246 - acc: 0.8043 - f1: 0.7992 - val_loss: 0.8565 - val_acc: 0.5000 - val_f1: 0.5599\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4326 - acc: 0.8002 - f1: 0.7961 - val_loss: 0.8568 - val_acc: 0.5148 - val_f1: 0.5915\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6917 - acc: 0.5336 - f1: 0.3721 - val_loss: 0.6931 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5525 - f1: 0.3555 - val_loss: 0.6933 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6874 - acc: 0.5529 - f1: 0.3556 - val_loss: 0.6933 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6870 - acc: 0.5529 - f1: 0.3558 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6867 - acc: 0.5505 - f1: 0.3619 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5525 - f1: 0.3563 - val_loss: 0.6975 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6862 - acc: 0.5472 - f1: 0.3833 - val_loss: 0.6956 - val_acc: 0.4741 - val_f1: 0.4067\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6875 - acc: 0.5546 - f1: 0.3693 - val_loss: 0.6974 - val_acc: 0.5370 - val_f1: 0.3762\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6857 - acc: 0.5534 - f1: 0.3633 - val_loss: 0.6977 - val_acc: 0.5037 - val_f1: 0.3967\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6849 - acc: 0.5554 - f1: 0.3944 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6851 - acc: 0.5492 - f1: 0.4048 - val_loss: 0.7008 - val_acc: 0.4481 - val_f1: 0.3874\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6837 - acc: 0.5521 - f1: 0.3933 - val_loss: 0.6984 - val_acc: 0.4778 - val_f1: 0.3743\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6836 - acc: 0.5604 - f1: 0.4182 - val_loss: 0.6934 - val_acc: 0.5333 - val_f1: 0.3485\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6830 - acc: 0.5529 - f1: 0.4071 - val_loss: 0.6922 - val_acc: 0.5444 - val_f1: 0.4688\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6818 - acc: 0.5600 - f1: 0.4221 - val_loss: 0.6922 - val_acc: 0.5407 - val_f1: 0.4520\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6807 - acc: 0.5645 - f1: 0.4671 - val_loss: 0.6969 - val_acc: 0.5148 - val_f1: 0.3751\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6816 - acc: 0.5484 - f1: 0.4137 - val_loss: 0.6982 - val_acc: 0.4593 - val_f1: 0.5105\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6850 - acc: 0.5464 - f1: 0.4818 - val_loss: 0.6972 - val_acc: 0.5148 - val_f1: 0.3738\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6816 - acc: 0.5579 - f1: 0.4322 - val_loss: 0.6998 - val_acc: 0.4370 - val_f1: 0.4363\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6807 - acc: 0.5608 - f1: 0.4474 - val_loss: 0.6939 - val_acc: 0.4815 - val_f1: 0.3741\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6815 - acc: 0.5538 - f1: 0.4237 - val_loss: 0.6999 - val_acc: 0.4593 - val_f1: 0.4111\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6797 - acc: 0.5637 - f1: 0.4895 - val_loss: 0.6920 - val_acc: 0.5333 - val_f1: 0.3485\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6803 - acc: 0.5756 - f1: 0.4629 - val_loss: 0.6996 - val_acc: 0.4222 - val_f1: 0.3854\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6789 - acc: 0.5579 - f1: 0.4797 - val_loss: 0.6935 - val_acc: 0.5259 - val_f1: 0.3697\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6777 - acc: 0.5645 - f1: 0.4780 - val_loss: 0.6945 - val_acc: 0.5037 - val_f1: 0.3797\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6782 - acc: 0.5649 - f1: 0.4914 - val_loss: 0.6954 - val_acc: 0.5037 - val_f1: 0.3669\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6756 - acc: 0.5793 - f1: 0.5141 - val_loss: 0.7015 - val_acc: 0.4889 - val_f1: 0.3876\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6785 - acc: 0.5674 - f1: 0.4884 - val_loss: 0.6984 - val_acc: 0.4852 - val_f1: 0.4160\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6746 - acc: 0.5703 - f1: 0.4991 - val_loss: 0.6992 - val_acc: 0.5074 - val_f1: 0.3775\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6741 - acc: 0.5698 - f1: 0.4822 - val_loss: 0.6968 - val_acc: 0.5148 - val_f1: 0.3751\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6750 - acc: 0.5764 - f1: 0.5135 - val_loss: 0.7017 - val_acc: 0.5037 - val_f1: 0.3936\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6733 - acc: 0.5806 - f1: 0.5195 - val_loss: 0.7018 - val_acc: 0.4889 - val_f1: 0.4033\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6732 - acc: 0.5768 - f1: 0.5188 - val_loss: 0.6966 - val_acc: 0.5259 - val_f1: 0.5686\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6722 - acc: 0.5801 - f1: 0.5327 - val_loss: 0.7059 - val_acc: 0.4704 - val_f1: 0.4748\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6703 - acc: 0.5789 - f1: 0.5356 - val_loss: 0.7034 - val_acc: 0.5185 - val_f1: 0.4148\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6691 - acc: 0.5810 - f1: 0.5267 - val_loss: 0.7112 - val_acc: 0.4704 - val_f1: 0.4178\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6704 - acc: 0.5793 - f1: 0.5346 - val_loss: 0.7018 - val_acc: 0.5074 - val_f1: 0.5213\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.5867 - f1: 0.5453 - val_loss: 0.7025 - val_acc: 0.5259 - val_f1: 0.5492\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6666 - acc: 0.5888 - f1: 0.5547 - val_loss: 0.7048 - val_acc: 0.5259 - val_f1: 0.5518\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6660 - acc: 0.5921 - f1: 0.5446 - val_loss: 0.6990 - val_acc: 0.5444 - val_f1: 0.5589\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6672 - acc: 0.5962 - f1: 0.5689 - val_loss: 0.7259 - val_acc: 0.4704 - val_f1: 0.3888\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6673 - acc: 0.5830 - f1: 0.5309 - val_loss: 0.7184 - val_acc: 0.5037 - val_f1: 0.3770\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6648 - acc: 0.5929 - f1: 0.5478 - val_loss: 0.7123 - val_acc: 0.5000 - val_f1: 0.4491\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6598 - acc: 0.5950 - f1: 0.5592 - val_loss: 0.7126 - val_acc: 0.5037 - val_f1: 0.5039\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6619 - acc: 0.5933 - f1: 0.5442 - val_loss: 0.7119 - val_acc: 0.5185 - val_f1: 0.4432\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6584 - acc: 0.6246 - f1: 0.5950 - val_loss: 0.7465 - val_acc: 0.4852 - val_f1: 0.3869\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6592 - acc: 0.5925 - f1: 0.5567 - val_loss: 0.7204 - val_acc: 0.5111 - val_f1: 0.3862\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6583 - acc: 0.6007 - f1: 0.5693 - val_loss: 0.7128 - val_acc: 0.5222 - val_f1: 0.5501\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6567 - acc: 0.5999 - f1: 0.5637 - val_loss: 0.7187 - val_acc: 0.4963 - val_f1: 0.4513\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6578 - acc: 0.6077 - f1: 0.5905 - val_loss: 0.7152 - val_acc: 0.5296 - val_f1: 0.4584\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6542 - acc: 0.6057 - f1: 0.5663 - val_loss: 0.7107 - val_acc: 0.5185 - val_f1: 0.5304\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6493 - acc: 0.6209 - f1: 0.5975 - val_loss: 0.7154 - val_acc: 0.5370 - val_f1: 0.5576\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6557 - acc: 0.6110 - f1: 0.5889 - val_loss: 0.7123 - val_acc: 0.5259 - val_f1: 0.5629\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6540 - acc: 0.6061 - f1: 0.5728 - val_loss: 0.7188 - val_acc: 0.5370 - val_f1: 0.5229\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6493 - acc: 0.6218 - f1: 0.5970 - val_loss: 0.7157 - val_acc: 0.5185 - val_f1: 0.5552\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6487 - acc: 0.6251 - f1: 0.6034 - val_loss: 0.7052 - val_acc: 0.5481 - val_f1: 0.5681\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6461 - acc: 0.6172 - f1: 0.5882 - val_loss: 0.7118 - val_acc: 0.5407 - val_f1: 0.5800\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6447 - acc: 0.6230 - f1: 0.6032 - val_loss: 0.7155 - val_acc: 0.5593 - val_f1: 0.5422\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6446 - acc: 0.6271 - f1: 0.6043 - val_loss: 0.7238 - val_acc: 0.5444 - val_f1: 0.5428\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6440 - acc: 0.6329 - f1: 0.6105 - val_loss: 0.7210 - val_acc: 0.5407 - val_f1: 0.5382\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6426 - acc: 0.6288 - f1: 0.6161 - val_loss: 0.7249 - val_acc: 0.5333 - val_f1: 0.5168\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6452 - acc: 0.6180 - f1: 0.5849 - val_loss: 0.7150 - val_acc: 0.5556 - val_f1: 0.5903\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6397 - acc: 0.6288 - f1: 0.6097 - val_loss: 0.7176 - val_acc: 0.5481 - val_f1: 0.5741\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6376 - acc: 0.6354 - f1: 0.6147 - val_loss: 0.7425 - val_acc: 0.5481 - val_f1: 0.5720\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.6432 - f1: 0.6186 - val_loss: 0.7184 - val_acc: 0.5333 - val_f1: 0.5743\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6374 - acc: 0.6329 - f1: 0.6183 - val_loss: 0.7248 - val_acc: 0.5481 - val_f1: 0.5876\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6364 - acc: 0.6341 - f1: 0.6165 - val_loss: 0.7220 - val_acc: 0.5630 - val_f1: 0.5906\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6382 - acc: 0.6506 - f1: 0.6347 - val_loss: 0.7200 - val_acc: 0.5667 - val_f1: 0.6022\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6358 - acc: 0.6403 - f1: 0.6237 - val_loss: 0.7187 - val_acc: 0.5556 - val_f1: 0.5921\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6381 - acc: 0.6354 - f1: 0.6195 - val_loss: 0.7272 - val_acc: 0.5667 - val_f1: 0.5868\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6353 - acc: 0.6374 - f1: 0.6243 - val_loss: 0.7164 - val_acc: 0.5630 - val_f1: 0.5908\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6274 - acc: 0.6399 - f1: 0.6211 - val_loss: 0.7178 - val_acc: 0.5519 - val_f1: 0.5874\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6262 - acc: 0.6560 - f1: 0.6428 - val_loss: 0.7298 - val_acc: 0.5556 - val_f1: 0.5634\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6308 - acc: 0.6465 - f1: 0.6263 - val_loss: 0.7118 - val_acc: 0.5556 - val_f1: 0.5968\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6197 - acc: 0.6613 - f1: 0.6505 - val_loss: 0.7408 - val_acc: 0.5741 - val_f1: 0.5683\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6213 - acc: 0.6485 - f1: 0.6353 - val_loss: 0.7313 - val_acc: 0.5370 - val_f1: 0.5468\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6189 - acc: 0.6593 - f1: 0.6455 - val_loss: 0.7254 - val_acc: 0.5741 - val_f1: 0.6007\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6236 - acc: 0.6617 - f1: 0.6466 - val_loss: 0.7134 - val_acc: 0.5519 - val_f1: 0.5841\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6236 - acc: 0.6452 - f1: 0.6247 - val_loss: 0.7234 - val_acc: 0.5556 - val_f1: 0.5931\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6185 - acc: 0.6469 - f1: 0.6337 - val_loss: 0.7260 - val_acc: 0.5407 - val_f1: 0.5562\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6122 - acc: 0.6671 - f1: 0.6556 - val_loss: 0.7191 - val_acc: 0.5556 - val_f1: 0.5923\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6161 - acc: 0.6708 - f1: 0.6598 - val_loss: 0.7152 - val_acc: 0.5296 - val_f1: 0.5639\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6142 - acc: 0.6605 - f1: 0.6466 - val_loss: 0.7196 - val_acc: 0.5630 - val_f1: 0.5938\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6180 - acc: 0.6580 - f1: 0.6447 - val_loss: 0.7165 - val_acc: 0.5407 - val_f1: 0.5740\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6115 - acc: 0.6712 - f1: 0.6613 - val_loss: 0.7314 - val_acc: 0.5519 - val_f1: 0.5844\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6078 - acc: 0.6708 - f1: 0.6569 - val_loss: 0.7213 - val_acc: 0.5333 - val_f1: 0.5759\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6100 - acc: 0.6646 - f1: 0.6557 - val_loss: 0.7152 - val_acc: 0.5444 - val_f1: 0.5863\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6123 - acc: 0.6720 - f1: 0.6614 - val_loss: 0.7280 - val_acc: 0.5667 - val_f1: 0.5904\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6043 - acc: 0.6625 - f1: 0.6505 - val_loss: 0.7337 - val_acc: 0.5444 - val_f1: 0.5784\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6061 - acc: 0.6757 - f1: 0.6649 - val_loss: 0.7162 - val_acc: 0.5519 - val_f1: 0.5831\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6045 - acc: 0.6646 - f1: 0.6520 - val_loss: 0.7448 - val_acc: 0.5556 - val_f1: 0.5885\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6080 - acc: 0.6568 - f1: 0.6433 - val_loss: 0.7512 - val_acc: 0.5630 - val_f1: 0.5546\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6020 - acc: 0.6745 - f1: 0.6636 - val_loss: 0.7293 - val_acc: 0.5556 - val_f1: 0.5812\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5947 - acc: 0.6926 - f1: 0.6795 - val_loss: 0.7307 - val_acc: 0.5556 - val_f1: 0.5851\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5940 - acc: 0.6955 - f1: 0.6842 - val_loss: 0.7240 - val_acc: 0.5481 - val_f1: 0.5818\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5967 - acc: 0.6844 - f1: 0.6756 - val_loss: 0.7427 - val_acc: 0.5370 - val_f1: 0.5754\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6004 - acc: 0.6716 - f1: 0.6639 - val_loss: 0.7298 - val_acc: 0.5296 - val_f1: 0.5658\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5951 - acc: 0.6902 - f1: 0.6764 - val_loss: 0.7304 - val_acc: 0.5333 - val_f1: 0.5699\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5932 - acc: 0.6844 - f1: 0.6758 - val_loss: 0.7334 - val_acc: 0.5481 - val_f1: 0.5771\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5929 - acc: 0.6897 - f1: 0.6776 - val_loss: 0.7405 - val_acc: 0.5259 - val_f1: 0.5540\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5913 - acc: 0.6906 - f1: 0.6828 - val_loss: 0.7262 - val_acc: 0.5444 - val_f1: 0.5737\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5842 - acc: 0.6934 - f1: 0.6828 - val_loss: 0.7356 - val_acc: 0.5296 - val_f1: 0.5665\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5851 - acc: 0.6889 - f1: 0.6815 - val_loss: 0.7322 - val_acc: 0.5296 - val_f1: 0.5726\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5835 - acc: 0.6869 - f1: 0.6786 - val_loss: 0.7680 - val_acc: 0.5519 - val_f1: 0.5734\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5858 - acc: 0.6910 - f1: 0.6833 - val_loss: 0.7519 - val_acc: 0.5556 - val_f1: 0.5815\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5947 - acc: 0.6696 - f1: 0.6547 - val_loss: 0.7279 - val_acc: 0.5296 - val_f1: 0.5641\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5792 - acc: 0.6980 - f1: 0.6871 - val_loss: 0.7302 - val_acc: 0.5296 - val_f1: 0.5719\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5790 - acc: 0.6992 - f1: 0.6901 - val_loss: 0.7348 - val_acc: 0.5296 - val_f1: 0.5642\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5733 - acc: 0.7000 - f1: 0.6908 - val_loss: 0.7458 - val_acc: 0.5481 - val_f1: 0.5745\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5727 - acc: 0.7070 - f1: 0.6956 - val_loss: 0.7345 - val_acc: 0.5370 - val_f1: 0.5749\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5776 - acc: 0.6914 - f1: 0.6853 - val_loss: 0.7448 - val_acc: 0.5333 - val_f1: 0.5700\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5791 - acc: 0.6984 - f1: 0.6852 - val_loss: 0.7330 - val_acc: 0.5370 - val_f1: 0.5774\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5806 - acc: 0.6926 - f1: 0.6860 - val_loss: 0.7506 - val_acc: 0.5407 - val_f1: 0.5761\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5735 - acc: 0.6992 - f1: 0.6868 - val_loss: 0.7290 - val_acc: 0.5185 - val_f1: 0.5635\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5704 - acc: 0.7017 - f1: 0.6933 - val_loss: 0.7463 - val_acc: 0.5333 - val_f1: 0.5650\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5663 - acc: 0.7145 - f1: 0.7068 - val_loss: 0.7431 - val_acc: 0.5185 - val_f1: 0.5588\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5704 - acc: 0.7042 - f1: 0.6960 - val_loss: 0.7518 - val_acc: 0.5259 - val_f1: 0.5654\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5693 - acc: 0.7005 - f1: 0.6891 - val_loss: 0.7529 - val_acc: 0.5259 - val_f1: 0.5645\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5617 - acc: 0.7186 - f1: 0.7113 - val_loss: 0.7447 - val_acc: 0.5222 - val_f1: 0.5633\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5622 - acc: 0.7178 - f1: 0.7106 - val_loss: 0.7600 - val_acc: 0.5370 - val_f1: 0.5733\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5593 - acc: 0.7120 - f1: 0.7032 - val_loss: 0.7342 - val_acc: 0.5222 - val_f1: 0.5711\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5670 - acc: 0.7033 - f1: 0.6962 - val_loss: 0.7541 - val_acc: 0.5444 - val_f1: 0.5784\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6901 - acc: 0.5468 - f1: 0.3824 - val_loss: 0.6943 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6883 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6950 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6880 - acc: 0.5534 - f1: 0.3552 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6879 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6931 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6861 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6873 - acc: 0.5525 - f1: 0.3565 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5525 - f1: 0.3556 - val_loss: 0.6933 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6857 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6846 - acc: 0.5534 - f1: 0.3569 - val_loss: 0.6922 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6833 - acc: 0.5554 - f1: 0.3611 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6837 - acc: 0.5538 - f1: 0.3663 - val_loss: 0.6928 - val_acc: 0.5259 - val_f1: 0.3462\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6855 - acc: 0.5521 - f1: 0.3602 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6815 - acc: 0.5554 - f1: 0.3926 - val_loss: 0.6963 - val_acc: 0.5333 - val_f1: 0.3531\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6869 - acc: 0.5492 - f1: 0.4225 - val_loss: 0.6962 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6823 - acc: 0.5517 - f1: 0.3573 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6824 - acc: 0.5587 - f1: 0.3919 - val_loss: 0.6920 - val_acc: 0.5259 - val_f1: 0.4710\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6815 - acc: 0.5591 - f1: 0.4256 - val_loss: 0.6956 - val_acc: 0.4889 - val_f1: 0.3810\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6802 - acc: 0.5575 - f1: 0.4273 - val_loss: 0.6889 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6793 - acc: 0.5674 - f1: 0.4572 - val_loss: 0.6960 - val_acc: 0.4815 - val_f1: 0.3675\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6781 - acc: 0.5670 - f1: 0.4456 - val_loss: 0.6963 - val_acc: 0.5000 - val_f1: 0.5126\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6772 - acc: 0.5707 - f1: 0.4854 - val_loss: 0.6917 - val_acc: 0.5370 - val_f1: 0.3587\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6778 - acc: 0.5723 - f1: 0.5048 - val_loss: 0.6952 - val_acc: 0.5111 - val_f1: 0.4235\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6744 - acc: 0.5756 - f1: 0.4701 - val_loss: 0.6929 - val_acc: 0.5111 - val_f1: 0.4696\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6749 - acc: 0.5682 - f1: 0.4940 - val_loss: 0.6974 - val_acc: 0.5148 - val_f1: 0.4764\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6740 - acc: 0.5694 - f1: 0.5091 - val_loss: 0.6931 - val_acc: 0.5370 - val_f1: 0.3939\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6715 - acc: 0.5781 - f1: 0.5114 - val_loss: 0.6961 - val_acc: 0.5037 - val_f1: 0.4585\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6706 - acc: 0.5674 - f1: 0.4989 - val_loss: 0.6941 - val_acc: 0.5037 - val_f1: 0.4377\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6687 - acc: 0.5843 - f1: 0.5378 - val_loss: 0.6959 - val_acc: 0.5000 - val_f1: 0.4472\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6695 - acc: 0.5876 - f1: 0.5525 - val_loss: 0.6933 - val_acc: 0.5222 - val_f1: 0.4829\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6647 - acc: 0.6090 - f1: 0.5637 - val_loss: 0.6944 - val_acc: 0.5407 - val_f1: 0.4398\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6642 - acc: 0.5991 - f1: 0.5658 - val_loss: 0.6960 - val_acc: 0.5111 - val_f1: 0.4523\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6641 - acc: 0.6003 - f1: 0.5562 - val_loss: 0.6868 - val_acc: 0.5704 - val_f1: 0.4990\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6643 - acc: 0.6007 - f1: 0.5702 - val_loss: 0.6880 - val_acc: 0.5593 - val_f1: 0.5319\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6612 - acc: 0.5962 - f1: 0.5589 - val_loss: 0.6945 - val_acc: 0.5259 - val_f1: 0.4812\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6622 - acc: 0.6036 - f1: 0.5764 - val_loss: 0.7035 - val_acc: 0.5259 - val_f1: 0.4807\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6594 - acc: 0.5962 - f1: 0.5614 - val_loss: 0.6960 - val_acc: 0.5296 - val_f1: 0.4896\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6594 - acc: 0.6020 - f1: 0.5757 - val_loss: 0.6976 - val_acc: 0.5259 - val_f1: 0.4725\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6573 - acc: 0.6180 - f1: 0.5942 - val_loss: 0.6981 - val_acc: 0.5444 - val_f1: 0.5052\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6561 - acc: 0.6139 - f1: 0.5883 - val_loss: 0.7007 - val_acc: 0.5222 - val_f1: 0.4593\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6550 - acc: 0.6119 - f1: 0.5848 - val_loss: 0.7036 - val_acc: 0.5296 - val_f1: 0.4788\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6551 - acc: 0.6160 - f1: 0.5871 - val_loss: 0.6933 - val_acc: 0.5444 - val_f1: 0.4733\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6552 - acc: 0.5979 - f1: 0.5820 - val_loss: 0.7016 - val_acc: 0.5444 - val_f1: 0.4885\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6524 - acc: 0.6131 - f1: 0.5835 - val_loss: 0.6988 - val_acc: 0.5333 - val_f1: 0.5346\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6492 - acc: 0.6304 - f1: 0.6107 - val_loss: 0.7042 - val_acc: 0.5444 - val_f1: 0.5196\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6474 - acc: 0.6168 - f1: 0.5886 - val_loss: 0.6994 - val_acc: 0.5519 - val_f1: 0.5212\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6467 - acc: 0.6242 - f1: 0.6078 - val_loss: 0.7044 - val_acc: 0.5259 - val_f1: 0.4299\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6464 - acc: 0.6230 - f1: 0.6053 - val_loss: 0.7092 - val_acc: 0.5333 - val_f1: 0.4857\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6410 - acc: 0.6288 - f1: 0.6060 - val_loss: 0.7036 - val_acc: 0.5481 - val_f1: 0.4866\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6421 - acc: 0.6209 - f1: 0.6011 - val_loss: 0.7076 - val_acc: 0.5407 - val_f1: 0.4829\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6405 - acc: 0.6395 - f1: 0.6183 - val_loss: 0.7193 - val_acc: 0.5259 - val_f1: 0.4207\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6445 - acc: 0.6242 - f1: 0.6088 - val_loss: 0.7105 - val_acc: 0.5556 - val_f1: 0.5339\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6383 - acc: 0.6337 - f1: 0.6141 - val_loss: 0.7132 - val_acc: 0.5185 - val_f1: 0.4096\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6366 - acc: 0.6386 - f1: 0.6249 - val_loss: 0.7053 - val_acc: 0.5407 - val_f1: 0.5113\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6379 - acc: 0.6308 - f1: 0.6110 - val_loss: 0.7155 - val_acc: 0.5444 - val_f1: 0.4554\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6333 - acc: 0.6345 - f1: 0.6171 - val_loss: 0.7231 - val_acc: 0.5370 - val_f1: 0.4349\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6321 - acc: 0.6424 - f1: 0.6323 - val_loss: 0.7172 - val_acc: 0.5444 - val_f1: 0.4546\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6342 - acc: 0.6440 - f1: 0.6260 - val_loss: 0.7007 - val_acc: 0.5519 - val_f1: 0.5545\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6299 - acc: 0.6485 - f1: 0.6298 - val_loss: 0.7253 - val_acc: 0.5111 - val_f1: 0.4112\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6270 - acc: 0.6469 - f1: 0.6295 - val_loss: 0.7175 - val_acc: 0.5296 - val_f1: 0.5477\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6265 - acc: 0.6555 - f1: 0.6374 - val_loss: 0.7140 - val_acc: 0.5556 - val_f1: 0.5437\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6270 - acc: 0.6448 - f1: 0.6327 - val_loss: 0.7123 - val_acc: 0.5481 - val_f1: 0.5255\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6178 - acc: 0.6642 - f1: 0.6535 - val_loss: 0.7238 - val_acc: 0.5481 - val_f1: 0.5158\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6228 - acc: 0.6465 - f1: 0.6305 - val_loss: 0.7049 - val_acc: 0.5815 - val_f1: 0.5503\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6224 - acc: 0.6605 - f1: 0.6436 - val_loss: 0.7207 - val_acc: 0.5667 - val_f1: 0.5140\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6171 - acc: 0.6584 - f1: 0.6445 - val_loss: 0.7159 - val_acc: 0.5370 - val_f1: 0.5191\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6113 - acc: 0.6724 - f1: 0.6583 - val_loss: 0.7266 - val_acc: 0.5296 - val_f1: 0.4744\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6086 - acc: 0.6761 - f1: 0.6641 - val_loss: 0.7277 - val_acc: 0.5370 - val_f1: 0.5192\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6113 - acc: 0.6634 - f1: 0.6498 - val_loss: 0.7150 - val_acc: 0.5741 - val_f1: 0.5349\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6043 - acc: 0.6757 - f1: 0.6646 - val_loss: 0.7372 - val_acc: 0.5407 - val_f1: 0.5217\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6019 - acc: 0.6745 - f1: 0.6619 - val_loss: 0.7407 - val_acc: 0.5556 - val_f1: 0.5403\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6047 - acc: 0.6733 - f1: 0.6624 - val_loss: 0.7208 - val_acc: 0.5481 - val_f1: 0.5299\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6038 - acc: 0.6712 - f1: 0.6557 - val_loss: 0.7449 - val_acc: 0.5259 - val_f1: 0.4946\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5976 - acc: 0.6848 - f1: 0.6747 - val_loss: 0.7395 - val_acc: 0.5704 - val_f1: 0.5359\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5903 - acc: 0.6930 - f1: 0.6814 - val_loss: 0.7491 - val_acc: 0.5519 - val_f1: 0.5315\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5895 - acc: 0.6877 - f1: 0.6763 - val_loss: 0.7496 - val_acc: 0.5630 - val_f1: 0.5442\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5857 - acc: 0.6852 - f1: 0.6766 - val_loss: 0.7460 - val_acc: 0.5222 - val_f1: 0.4743\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5827 - acc: 0.6914 - f1: 0.6764 - val_loss: 0.7265 - val_acc: 0.5481 - val_f1: 0.5398\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5879 - acc: 0.6836 - f1: 0.6759 - val_loss: 0.7457 - val_acc: 0.5667 - val_f1: 0.5344\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5827 - acc: 0.6951 - f1: 0.6825 - val_loss: 0.7516 - val_acc: 0.5593 - val_f1: 0.5626\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5780 - acc: 0.6947 - f1: 0.6785 - val_loss: 0.7257 - val_acc: 0.5630 - val_f1: 0.5624\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5816 - acc: 0.6984 - f1: 0.6902 - val_loss: 0.7586 - val_acc: 0.5704 - val_f1: 0.5793\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5790 - acc: 0.7021 - f1: 0.6929 - val_loss: 0.7752 - val_acc: 0.5630 - val_f1: 0.5223\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5766 - acc: 0.7009 - f1: 0.6887 - val_loss: 0.7474 - val_acc: 0.5815 - val_f1: 0.5642\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5689 - acc: 0.7070 - f1: 0.6987 - val_loss: 0.8069 - val_acc: 0.5630 - val_f1: 0.4912\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5736 - acc: 0.6976 - f1: 0.6881 - val_loss: 0.7563 - val_acc: 0.5704 - val_f1: 0.5494\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5779 - acc: 0.6996 - f1: 0.6868 - val_loss: 0.7454 - val_acc: 0.5778 - val_f1: 0.5586\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5773 - acc: 0.6934 - f1: 0.6857 - val_loss: 0.7528 - val_acc: 0.5630 - val_f1: 0.5490\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5682 - acc: 0.6996 - f1: 0.6902 - val_loss: 0.7394 - val_acc: 0.5481 - val_f1: 0.5419\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5643 - acc: 0.7025 - f1: 0.6905 - val_loss: 0.7455 - val_acc: 0.5704 - val_f1: 0.5709\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5555 - acc: 0.7219 - f1: 0.7142 - val_loss: 0.7630 - val_acc: 0.5741 - val_f1: 0.5598\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5607 - acc: 0.7054 - f1: 0.6974 - val_loss: 0.7899 - val_acc: 0.5667 - val_f1: 0.5308\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5625 - acc: 0.7087 - f1: 0.6978 - val_loss: 0.7462 - val_acc: 0.5630 - val_f1: 0.5580\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5577 - acc: 0.6988 - f1: 0.6925 - val_loss: 0.7565 - val_acc: 0.5778 - val_f1: 0.6000\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5580 - acc: 0.7095 - f1: 0.7029 - val_loss: 0.7722 - val_acc: 0.5704 - val_f1: 0.5353\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5528 - acc: 0.7190 - f1: 0.7115 - val_loss: 0.7423 - val_acc: 0.5444 - val_f1: 0.5911\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5538 - acc: 0.7149 - f1: 0.7069 - val_loss: 0.7517 - val_acc: 0.5889 - val_f1: 0.5889\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5474 - acc: 0.7202 - f1: 0.7106 - val_loss: 0.7656 - val_acc: 0.5778 - val_f1: 0.5842\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5485 - acc: 0.7256 - f1: 0.7173 - val_loss: 0.7309 - val_acc: 0.5519 - val_f1: 0.5763\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5437 - acc: 0.7285 - f1: 0.7213 - val_loss: 0.7436 - val_acc: 0.5741 - val_f1: 0.6009\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5421 - acc: 0.7206 - f1: 0.7144 - val_loss: 0.7484 - val_acc: 0.5926 - val_f1: 0.6150\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5413 - acc: 0.7248 - f1: 0.7150 - val_loss: 0.7588 - val_acc: 0.5741 - val_f1: 0.6027\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5346 - acc: 0.7363 - f1: 0.7274 - val_loss: 0.7522 - val_acc: 0.5519 - val_f1: 0.5972\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5371 - acc: 0.7314 - f1: 0.7243 - val_loss: 0.7950 - val_acc: 0.5704 - val_f1: 0.5526\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5430 - acc: 0.7211 - f1: 0.7140 - val_loss: 0.7619 - val_acc: 0.5556 - val_f1: 0.5790\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5366 - acc: 0.7351 - f1: 0.7289 - val_loss: 0.7939 - val_acc: 0.5556 - val_f1: 0.5361\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5365 - acc: 0.7252 - f1: 0.7165 - val_loss: 0.7764 - val_acc: 0.5704 - val_f1: 0.5661\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5386 - acc: 0.7219 - f1: 0.7145 - val_loss: 0.7906 - val_acc: 0.5704 - val_f1: 0.5515\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5331 - acc: 0.7309 - f1: 0.7235 - val_loss: 0.7525 - val_acc: 0.5667 - val_f1: 0.5473\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5320 - acc: 0.7239 - f1: 0.7162 - val_loss: 0.7580 - val_acc: 0.5778 - val_f1: 0.5890\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5241 - acc: 0.7367 - f1: 0.7308 - val_loss: 0.7814 - val_acc: 0.5556 - val_f1: 0.5758\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5320 - acc: 0.7231 - f1: 0.7160 - val_loss: 0.7770 - val_acc: 0.5667 - val_f1: 0.5595\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5221 - acc: 0.7351 - f1: 0.7289 - val_loss: 0.7909 - val_acc: 0.5815 - val_f1: 0.5506\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5160 - acc: 0.7495 - f1: 0.7419 - val_loss: 0.7712 - val_acc: 0.5593 - val_f1: 0.5786\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5225 - acc: 0.7384 - f1: 0.7305 - val_loss: 0.7754 - val_acc: 0.5444 - val_f1: 0.5499\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5112 - acc: 0.7429 - f1: 0.7355 - val_loss: 0.8050 - val_acc: 0.5667 - val_f1: 0.5752\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5103 - acc: 0.7392 - f1: 0.7315 - val_loss: 0.7887 - val_acc: 0.5667 - val_f1: 0.5858\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5107 - acc: 0.7557 - f1: 0.7496 - val_loss: 0.7769 - val_acc: 0.5704 - val_f1: 0.5568\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5149 - acc: 0.7466 - f1: 0.7401 - val_loss: 0.7802 - val_acc: 0.5481 - val_f1: 0.5710\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5150 - acc: 0.7458 - f1: 0.7391 - val_loss: 0.7845 - val_acc: 0.5519 - val_f1: 0.5548\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5012 - acc: 0.7412 - f1: 0.7351 - val_loss: 0.7695 - val_acc: 0.5370 - val_f1: 0.5328\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5043 - acc: 0.7495 - f1: 0.7421 - val_loss: 0.7970 - val_acc: 0.5519 - val_f1: 0.5779\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4956 - acc: 0.7639 - f1: 0.7566 - val_loss: 0.7976 - val_acc: 0.5407 - val_f1: 0.5433\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4989 - acc: 0.7441 - f1: 0.7351 - val_loss: 0.7712 - val_acc: 0.5333 - val_f1: 0.5662\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4993 - acc: 0.7450 - f1: 0.7401 - val_loss: 0.7914 - val_acc: 0.5852 - val_f1: 0.5913\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5007 - acc: 0.7495 - f1: 0.7437 - val_loss: 0.7876 - val_acc: 0.5407 - val_f1: 0.5486\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4947 - acc: 0.7548 - f1: 0.7474 - val_loss: 0.7951 - val_acc: 0.5296 - val_f1: 0.5183\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4916 - acc: 0.7618 - f1: 0.7562 - val_loss: 0.7885 - val_acc: 0.5296 - val_f1: 0.5900\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4982 - acc: 0.7528 - f1: 0.7459 - val_loss: 0.7896 - val_acc: 0.5444 - val_f1: 0.5443\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4899 - acc: 0.7602 - f1: 0.7545 - val_loss: 0.7920 - val_acc: 0.5593 - val_f1: 0.5889\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4946 - acc: 0.7491 - f1: 0.7433 - val_loss: 0.7810 - val_acc: 0.5444 - val_f1: 0.5757\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4918 - acc: 0.7499 - f1: 0.7428 - val_loss: 0.7886 - val_acc: 0.5370 - val_f1: 0.5702\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4974 - acc: 0.7561 - f1: 0.7502 - val_loss: 0.7899 - val_acc: 0.5370 - val_f1: 0.5435\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6892 - acc: 0.5426 - f1: 0.3641 - val_loss: 0.6940 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6887 - acc: 0.5529 - f1: 0.3778 - val_loss: 0.6941 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6872 - acc: 0.5542 - f1: 0.3587 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6875 - acc: 0.5534 - f1: 0.3584 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5558 - f1: 0.3754 - val_loss: 0.6945 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6877 - acc: 0.5534 - f1: 0.3575 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6862 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6860 - acc: 0.5542 - f1: 0.3578 - val_loss: 0.6936 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6855 - acc: 0.5542 - f1: 0.3671 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6854 - acc: 0.5542 - f1: 0.3670 - val_loss: 0.6946 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6842 - acc: 0.5509 - f1: 0.3622 - val_loss: 0.6931 - val_acc: 0.5111 - val_f1: 0.4491\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6844 - acc: 0.5583 - f1: 0.4117 - val_loss: 0.6941 - val_acc: 0.4778 - val_f1: 0.4133\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.5525 - f1: 0.3957 - val_loss: 0.6952 - val_acc: 0.5185 - val_f1: 0.3717\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6847 - acc: 0.5546 - f1: 0.4432 - val_loss: 0.6978 - val_acc: 0.5222 - val_f1: 0.3573\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6859 - acc: 0.5571 - f1: 0.4038 - val_loss: 0.6936 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6832 - acc: 0.5538 - f1: 0.3708 - val_loss: 0.6946 - val_acc: 0.5037 - val_f1: 0.3624\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6817 - acc: 0.5558 - f1: 0.4177 - val_loss: 0.6950 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6850 - acc: 0.5608 - f1: 0.4173 - val_loss: 0.6936 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6816 - acc: 0.5567 - f1: 0.3876 - val_loss: 0.6944 - val_acc: 0.5074 - val_f1: 0.3792\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6814 - acc: 0.5670 - f1: 0.4536 - val_loss: 0.6959 - val_acc: 0.5148 - val_f1: 0.3507\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6817 - acc: 0.5665 - f1: 0.4675 - val_loss: 0.6945 - val_acc: 0.5185 - val_f1: 0.3482\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6808 - acc: 0.5637 - f1: 0.4114 - val_loss: 0.6954 - val_acc: 0.4815 - val_f1: 0.3879\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6817 - acc: 0.5661 - f1: 0.4392 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6794 - acc: 0.5641 - f1: 0.4316 - val_loss: 0.6951 - val_acc: 0.4704 - val_f1: 0.3890\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6780 - acc: 0.5703 - f1: 0.4721 - val_loss: 0.6970 - val_acc: 0.5296 - val_f1: 0.3610\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6785 - acc: 0.5731 - f1: 0.4721 - val_loss: 0.6940 - val_acc: 0.5222 - val_f1: 0.3667\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6788 - acc: 0.5711 - f1: 0.4738 - val_loss: 0.6970 - val_acc: 0.5296 - val_f1: 0.3608\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6740 - acc: 0.5764 - f1: 0.4741 - val_loss: 0.6949 - val_acc: 0.4630 - val_f1: 0.4717\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6745 - acc: 0.5756 - f1: 0.5028 - val_loss: 0.6949 - val_acc: 0.5111 - val_f1: 0.4023\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6745 - acc: 0.5764 - f1: 0.5129 - val_loss: 0.6984 - val_acc: 0.4815 - val_f1: 0.3640\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6717 - acc: 0.5859 - f1: 0.5283 - val_loss: 0.6940 - val_acc: 0.5037 - val_f1: 0.3990\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6705 - acc: 0.5810 - f1: 0.5062 - val_loss: 0.6951 - val_acc: 0.4852 - val_f1: 0.4946\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6696 - acc: 0.5818 - f1: 0.5125 - val_loss: 0.6990 - val_acc: 0.4889 - val_f1: 0.3871\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6688 - acc: 0.5929 - f1: 0.5488 - val_loss: 0.7008 - val_acc: 0.4667 - val_f1: 0.4941\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6652 - acc: 0.5880 - f1: 0.5319 - val_loss: 0.7021 - val_acc: 0.4963 - val_f1: 0.3930\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6678 - acc: 0.5888 - f1: 0.5476 - val_loss: 0.6977 - val_acc: 0.5111 - val_f1: 0.3700\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6657 - acc: 0.5966 - f1: 0.5416 - val_loss: 0.6925 - val_acc: 0.5259 - val_f1: 0.5077\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6588 - acc: 0.6032 - f1: 0.5562 - val_loss: 0.6962 - val_acc: 0.5074 - val_f1: 0.5400\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6585 - acc: 0.6065 - f1: 0.5780 - val_loss: 0.6946 - val_acc: 0.5333 - val_f1: 0.5622\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6576 - acc: 0.6044 - f1: 0.5638 - val_loss: 0.6953 - val_acc: 0.5074 - val_f1: 0.5153\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6640 - acc: 0.5929 - f1: 0.5607 - val_loss: 0.7006 - val_acc: 0.5370 - val_f1: 0.4550\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6595 - acc: 0.6077 - f1: 0.5762 - val_loss: 0.6982 - val_acc: 0.5333 - val_f1: 0.4861\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6597 - acc: 0.5983 - f1: 0.5354 - val_loss: 0.6938 - val_acc: 0.5222 - val_f1: 0.5424\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6592 - acc: 0.6094 - f1: 0.5817 - val_loss: 0.6946 - val_acc: 0.5259 - val_f1: 0.5292\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6515 - acc: 0.6168 - f1: 0.5839 - val_loss: 0.6853 - val_acc: 0.5667 - val_f1: 0.5767\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6488 - acc: 0.6189 - f1: 0.5886 - val_loss: 0.6930 - val_acc: 0.5519 - val_f1: 0.5705\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6531 - acc: 0.6222 - f1: 0.6026 - val_loss: 0.6972 - val_acc: 0.5556 - val_f1: 0.5670\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6509 - acc: 0.6189 - f1: 0.5882 - val_loss: 0.6903 - val_acc: 0.5630 - val_f1: 0.5567\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6497 - acc: 0.6180 - f1: 0.5969 - val_loss: 0.6914 - val_acc: 0.5556 - val_f1: 0.5595\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6479 - acc: 0.6172 - f1: 0.5939 - val_loss: 0.6897 - val_acc: 0.5667 - val_f1: 0.5676\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6442 - acc: 0.6325 - f1: 0.6090 - val_loss: 0.6986 - val_acc: 0.5370 - val_f1: 0.5627\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6381 - acc: 0.6370 - f1: 0.6177 - val_loss: 0.6985 - val_acc: 0.5370 - val_f1: 0.5397\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6430 - acc: 0.6304 - f1: 0.6048 - val_loss: 0.7019 - val_acc: 0.5148 - val_f1: 0.5273\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6400 - acc: 0.6415 - f1: 0.6293 - val_loss: 0.6961 - val_acc: 0.5519 - val_f1: 0.5473\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6407 - acc: 0.6362 - f1: 0.6100 - val_loss: 0.6961 - val_acc: 0.5407 - val_f1: 0.5637\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6416 - acc: 0.6164 - f1: 0.5969 - val_loss: 0.7069 - val_acc: 0.5296 - val_f1: 0.5357\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6374 - acc: 0.6271 - f1: 0.6035 - val_loss: 0.7145 - val_acc: 0.5000 - val_f1: 0.5411\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6404 - acc: 0.6316 - f1: 0.6150 - val_loss: 0.6940 - val_acc: 0.5593 - val_f1: 0.5800\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6340 - acc: 0.6502 - f1: 0.6294 - val_loss: 0.7078 - val_acc: 0.5296 - val_f1: 0.5712\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6313 - acc: 0.6395 - f1: 0.6199 - val_loss: 0.6926 - val_acc: 0.5407 - val_f1: 0.5651\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6266 - acc: 0.6440 - f1: 0.6269 - val_loss: 0.7024 - val_acc: 0.5667 - val_f1: 0.5942\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6282 - acc: 0.6597 - f1: 0.6448 - val_loss: 0.7206 - val_acc: 0.4815 - val_f1: 0.5228\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6295 - acc: 0.6485 - f1: 0.6302 - val_loss: 0.7069 - val_acc: 0.5259 - val_f1: 0.5343\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6246 - acc: 0.6498 - f1: 0.6338 - val_loss: 0.7203 - val_acc: 0.5074 - val_f1: 0.5326\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6270 - acc: 0.6345 - f1: 0.6162 - val_loss: 0.7166 - val_acc: 0.5333 - val_f1: 0.5652\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6252 - acc: 0.6564 - f1: 0.6427 - val_loss: 0.7001 - val_acc: 0.5444 - val_f1: 0.5777\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6235 - acc: 0.6650 - f1: 0.6467 - val_loss: 0.7199 - val_acc: 0.5222 - val_f1: 0.5466\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6183 - acc: 0.6564 - f1: 0.6436 - val_loss: 0.7155 - val_acc: 0.5370 - val_f1: 0.5644\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6202 - acc: 0.6514 - f1: 0.6325 - val_loss: 0.7105 - val_acc: 0.5296 - val_f1: 0.5703\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6195 - acc: 0.6502 - f1: 0.6361 - val_loss: 0.7259 - val_acc: 0.4963 - val_f1: 0.5131\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6167 - acc: 0.6555 - f1: 0.6444 - val_loss: 0.7210 - val_acc: 0.5333 - val_f1: 0.5678\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6122 - acc: 0.6621 - f1: 0.6463 - val_loss: 0.7347 - val_acc: 0.4926 - val_f1: 0.5152\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6092 - acc: 0.6696 - f1: 0.6555 - val_loss: 0.7034 - val_acc: 0.5370 - val_f1: 0.5543\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6106 - acc: 0.6696 - f1: 0.6533 - val_loss: 0.6987 - val_acc: 0.5296 - val_f1: 0.5740\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6083 - acc: 0.6737 - f1: 0.6625 - val_loss: 0.7223 - val_acc: 0.5370 - val_f1: 0.5629\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6108 - acc: 0.6625 - f1: 0.6474 - val_loss: 0.7211 - val_acc: 0.5370 - val_f1: 0.5658\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6014 - acc: 0.6687 - f1: 0.6566 - val_loss: 0.7362 - val_acc: 0.5185 - val_f1: 0.5481\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6045 - acc: 0.6687 - f1: 0.6576 - val_loss: 0.7389 - val_acc: 0.4815 - val_f1: 0.4864\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6030 - acc: 0.6700 - f1: 0.6562 - val_loss: 0.7191 - val_acc: 0.5148 - val_f1: 0.5171\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5995 - acc: 0.6708 - f1: 0.6613 - val_loss: 0.7267 - val_acc: 0.5259 - val_f1: 0.5393\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5998 - acc: 0.6691 - f1: 0.6543 - val_loss: 0.7173 - val_acc: 0.5185 - val_f1: 0.5555\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6025 - acc: 0.6733 - f1: 0.6623 - val_loss: 0.7189 - val_acc: 0.5185 - val_f1: 0.5485\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5930 - acc: 0.6782 - f1: 0.6656 - val_loss: 0.7299 - val_acc: 0.5222 - val_f1: 0.5344\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5893 - acc: 0.6827 - f1: 0.6714 - val_loss: 0.7257 - val_acc: 0.5074 - val_f1: 0.5302\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5932 - acc: 0.6766 - f1: 0.6634 - val_loss: 0.7178 - val_acc: 0.5296 - val_f1: 0.5809\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5926 - acc: 0.6807 - f1: 0.6670 - val_loss: 0.7251 - val_acc: 0.5148 - val_f1: 0.5357\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5928 - acc: 0.6782 - f1: 0.6725 - val_loss: 0.7291 - val_acc: 0.5148 - val_f1: 0.5535\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5903 - acc: 0.6860 - f1: 0.6720 - val_loss: 0.7317 - val_acc: 0.4926 - val_f1: 0.4826\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5898 - acc: 0.6893 - f1: 0.6801 - val_loss: 0.7405 - val_acc: 0.5000 - val_f1: 0.5248\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5883 - acc: 0.6827 - f1: 0.6713 - val_loss: 0.7180 - val_acc: 0.4852 - val_f1: 0.4927\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5834 - acc: 0.6939 - f1: 0.6838 - val_loss: 0.7416 - val_acc: 0.4926 - val_f1: 0.4805\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5822 - acc: 0.6955 - f1: 0.6859 - val_loss: 0.7244 - val_acc: 0.5148 - val_f1: 0.5331\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5777 - acc: 0.6963 - f1: 0.6851 - val_loss: 0.7403 - val_acc: 0.4815 - val_f1: 0.4679\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5783 - acc: 0.6897 - f1: 0.6777 - val_loss: 0.7418 - val_acc: 0.5148 - val_f1: 0.5331\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5739 - acc: 0.7009 - f1: 0.6906 - val_loss: 0.7540 - val_acc: 0.4963 - val_f1: 0.5303\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5749 - acc: 0.6922 - f1: 0.6838 - val_loss: 0.7552 - val_acc: 0.5074 - val_f1: 0.5422\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5777 - acc: 0.7025 - f1: 0.6930 - val_loss: 0.7449 - val_acc: 0.5037 - val_f1: 0.5281\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5738 - acc: 0.7000 - f1: 0.6888 - val_loss: 0.7410 - val_acc: 0.4852 - val_f1: 0.5164\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5756 - acc: 0.6910 - f1: 0.6801 - val_loss: 0.7491 - val_acc: 0.4963 - val_f1: 0.4945\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5759 - acc: 0.6947 - f1: 0.6851 - val_loss: 0.7398 - val_acc: 0.5148 - val_f1: 0.5273\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5655 - acc: 0.7021 - f1: 0.6932 - val_loss: 0.7508 - val_acc: 0.4852 - val_f1: 0.5150\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5588 - acc: 0.7103 - f1: 0.7010 - val_loss: 0.7369 - val_acc: 0.5185 - val_f1: 0.5389\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5590 - acc: 0.7095 - f1: 0.7019 - val_loss: 0.7492 - val_acc: 0.4889 - val_f1: 0.5145\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5622 - acc: 0.7046 - f1: 0.6929 - val_loss: 0.7406 - val_acc: 0.5333 - val_f1: 0.5447\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5668 - acc: 0.7021 - f1: 0.6945 - val_loss: 0.7290 - val_acc: 0.5407 - val_f1: 0.5461\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5661 - acc: 0.7029 - f1: 0.6918 - val_loss: 0.7342 - val_acc: 0.4926 - val_f1: 0.4981\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5614 - acc: 0.7087 - f1: 0.6988 - val_loss: 0.7422 - val_acc: 0.4889 - val_f1: 0.4735\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5579 - acc: 0.7186 - f1: 0.7100 - val_loss: 0.7522 - val_acc: 0.4889 - val_f1: 0.4961\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5568 - acc: 0.7132 - f1: 0.7050 - val_loss: 0.7463 - val_acc: 0.5000 - val_f1: 0.5233\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5550 - acc: 0.7108 - f1: 0.7003 - val_loss: 0.7455 - val_acc: 0.4852 - val_f1: 0.4702\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5594 - acc: 0.7066 - f1: 0.6975 - val_loss: 0.7514 - val_acc: 0.4963 - val_f1: 0.4776\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5433 - acc: 0.7165 - f1: 0.7080 - val_loss: 0.7500 - val_acc: 0.4889 - val_f1: 0.4761\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5532 - acc: 0.7128 - f1: 0.7036 - val_loss: 0.7491 - val_acc: 0.4778 - val_f1: 0.4719\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5503 - acc: 0.7165 - f1: 0.7100 - val_loss: 0.7573 - val_acc: 0.4852 - val_f1: 0.4726\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5534 - acc: 0.7145 - f1: 0.7063 - val_loss: 0.7521 - val_acc: 0.5000 - val_f1: 0.5024\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5468 - acc: 0.7165 - f1: 0.7080 - val_loss: 0.7783 - val_acc: 0.4815 - val_f1: 0.5084\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5454 - acc: 0.7231 - f1: 0.7147 - val_loss: 0.7733 - val_acc: 0.4889 - val_f1: 0.4749\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5418 - acc: 0.7178 - f1: 0.7110 - val_loss: 0.7655 - val_acc: 0.4963 - val_f1: 0.5016\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5455 - acc: 0.7194 - f1: 0.7124 - val_loss: 0.7502 - val_acc: 0.5037 - val_f1: 0.4870\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5461 - acc: 0.7141 - f1: 0.7069 - val_loss: 0.7677 - val_acc: 0.4963 - val_f1: 0.4763\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5416 - acc: 0.7211 - f1: 0.7074 - val_loss: 0.7791 - val_acc: 0.4444 - val_f1: 0.4538\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5399 - acc: 0.7231 - f1: 0.7178 - val_loss: 0.7864 - val_acc: 0.4852 - val_f1: 0.4563\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5423 - acc: 0.7165 - f1: 0.7088 - val_loss: 0.7680 - val_acc: 0.4889 - val_f1: 0.4814\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5361 - acc: 0.7276 - f1: 0.7201 - val_loss: 0.7492 - val_acc: 0.5000 - val_f1: 0.4888\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5463 - acc: 0.7161 - f1: 0.7070 - val_loss: 0.7747 - val_acc: 0.4815 - val_f1: 0.4707\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5331 - acc: 0.7227 - f1: 0.7165 - val_loss: 0.7596 - val_acc: 0.4778 - val_f1: 0.4757\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5385 - acc: 0.7252 - f1: 0.7170 - val_loss: 0.7593 - val_acc: 0.4778 - val_f1: 0.4501\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5353 - acc: 0.7235 - f1: 0.7159 - val_loss: 0.7715 - val_acc: 0.4852 - val_f1: 0.4976\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5401 - acc: 0.7227 - f1: 0.7143 - val_loss: 0.7683 - val_acc: 0.4963 - val_f1: 0.5063\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5317 - acc: 0.7314 - f1: 0.7246 - val_loss: 0.7682 - val_acc: 0.4778 - val_f1: 0.4729\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5310 - acc: 0.7268 - f1: 0.7196 - val_loss: 0.7730 - val_acc: 0.4889 - val_f1: 0.4997\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5239 - acc: 0.7289 - f1: 0.7218 - val_loss: 0.7714 - val_acc: 0.4704 - val_f1: 0.4856\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5365 - acc: 0.7231 - f1: 0.7155 - val_loss: 0.7438 - val_acc: 0.5000 - val_f1: 0.5067\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5278 - acc: 0.7268 - f1: 0.7201 - val_loss: 0.7693 - val_acc: 0.4926 - val_f1: 0.5012\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5288 - acc: 0.7293 - f1: 0.7213 - val_loss: 0.7734 - val_acc: 0.4963 - val_f1: 0.5040\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5239 - acc: 0.7388 - f1: 0.7320 - val_loss: 0.7719 - val_acc: 0.5074 - val_f1: 0.5138\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5218 - acc: 0.7425 - f1: 0.7350 - val_loss: 0.7608 - val_acc: 0.4963 - val_f1: 0.4783\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5165 - acc: 0.7445 - f1: 0.7371 - val_loss: 0.7684 - val_acc: 0.4963 - val_f1: 0.4789\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5221 - acc: 0.7392 - f1: 0.7329 - val_loss: 0.7619 - val_acc: 0.4815 - val_f1: 0.4731\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5146 - acc: 0.7433 - f1: 0.7363 - val_loss: 0.7915 - val_acc: 0.4667 - val_f1: 0.4689\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5222 - acc: 0.7351 - f1: 0.7291 - val_loss: 0.7815 - val_acc: 0.4926 - val_f1: 0.4954\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5072 - acc: 0.7487 - f1: 0.7418 - val_loss: 0.7897 - val_acc: 0.4778 - val_f1: 0.4718\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5218 - acc: 0.7392 - f1: 0.7338 - val_loss: 0.7791 - val_acc: 0.4741 - val_f1: 0.4778\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5157 - acc: 0.7433 - f1: 0.7360 - val_loss: 0.7751 - val_acc: 0.4963 - val_f1: 0.4567\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5098 - acc: 0.7482 - f1: 0.7396 - val_loss: 0.7730 - val_acc: 0.4778 - val_f1: 0.4748\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6911 - acc: 0.5496 - f1: 0.3693 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6891 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6889 - acc: 0.5529 - f1: 0.3555 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6883 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6956 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5542 - f1: 0.3594 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6869 - acc: 0.5550 - f1: 0.3630 - val_loss: 0.6951 - val_acc: 0.4815 - val_f1: 0.3506\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6859 - acc: 0.5554 - f1: 0.3690 - val_loss: 0.6954 - val_acc: 0.4926 - val_f1: 0.3612\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6853 - acc: 0.5517 - f1: 0.3626 - val_loss: 0.6958 - val_acc: 0.4185 - val_f1: 0.3790\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6872 - acc: 0.5546 - f1: 0.4296 - val_loss: 0.6978 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6865 - acc: 0.5550 - f1: 0.3627 - val_loss: 0.6972 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6846 - acc: 0.5542 - f1: 0.3716 - val_loss: 0.6970 - val_acc: 0.5296 - val_f1: 0.3473\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6848 - acc: 0.5525 - f1: 0.3858 - val_loss: 0.6980 - val_acc: 0.5259 - val_f1: 0.3552\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6849 - acc: 0.5521 - f1: 0.4140 - val_loss: 0.6968 - val_acc: 0.4926 - val_f1: 0.3685\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6830 - acc: 0.5558 - f1: 0.3833 - val_loss: 0.6962 - val_acc: 0.5333 - val_f1: 0.3533\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6851 - acc: 0.5525 - f1: 0.3990 - val_loss: 0.6974 - val_acc: 0.5296 - val_f1: 0.3473\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6827 - acc: 0.5571 - f1: 0.3770 - val_loss: 0.6991 - val_acc: 0.4889 - val_f1: 0.3688\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5554 - f1: 0.4280 - val_loss: 0.6985 - val_acc: 0.5185 - val_f1: 0.3800\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6827 - acc: 0.5562 - f1: 0.4172 - val_loss: 0.6979 - val_acc: 0.4815 - val_f1: 0.3534\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6817 - acc: 0.5546 - f1: 0.3916 - val_loss: 0.7008 - val_acc: 0.4741 - val_f1: 0.3867\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6820 - acc: 0.5583 - f1: 0.4667 - val_loss: 0.7035 - val_acc: 0.4741 - val_f1: 0.3849\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6812 - acc: 0.5562 - f1: 0.4084 - val_loss: 0.7036 - val_acc: 0.4519 - val_f1: 0.3768\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6798 - acc: 0.5542 - f1: 0.4220 - val_loss: 0.7031 - val_acc: 0.4815 - val_f1: 0.3758\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6790 - acc: 0.5628 - f1: 0.4640 - val_loss: 0.7026 - val_acc: 0.4815 - val_f1: 0.3881\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6792 - acc: 0.5558 - f1: 0.4683 - val_loss: 0.7066 - val_acc: 0.4741 - val_f1: 0.3961\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6795 - acc: 0.5575 - f1: 0.4064 - val_loss: 0.7065 - val_acc: 0.4630 - val_f1: 0.3975\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6796 - acc: 0.5637 - f1: 0.4720 - val_loss: 0.7090 - val_acc: 0.4481 - val_f1: 0.3934\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6768 - acc: 0.5608 - f1: 0.4571 - val_loss: 0.7081 - val_acc: 0.4296 - val_f1: 0.3769\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6753 - acc: 0.5719 - f1: 0.4823 - val_loss: 0.7090 - val_acc: 0.3963 - val_f1: 0.3515\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6770 - acc: 0.5670 - f1: 0.4895 - val_loss: 0.7101 - val_acc: 0.4296 - val_f1: 0.3724\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6725 - acc: 0.5773 - f1: 0.5172 - val_loss: 0.7131 - val_acc: 0.4444 - val_f1: 0.3878\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6747 - acc: 0.5612 - f1: 0.4959 - val_loss: 0.7119 - val_acc: 0.4296 - val_f1: 0.3826\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6721 - acc: 0.5748 - f1: 0.4837 - val_loss: 0.7137 - val_acc: 0.4296 - val_f1: 0.3874\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6725 - acc: 0.5740 - f1: 0.5089 - val_loss: 0.7146 - val_acc: 0.3852 - val_f1: 0.3434\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6719 - acc: 0.5731 - f1: 0.5182 - val_loss: 0.7219 - val_acc: 0.4296 - val_f1: 0.3790\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6720 - acc: 0.5760 - f1: 0.5272 - val_loss: 0.7144 - val_acc: 0.4111 - val_f1: 0.3727\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.5764 - f1: 0.5226 - val_loss: 0.7155 - val_acc: 0.4370 - val_f1: 0.3786\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6692 - acc: 0.5859 - f1: 0.5357 - val_loss: 0.7195 - val_acc: 0.4370 - val_f1: 0.3876\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6658 - acc: 0.5731 - f1: 0.5229 - val_loss: 0.7200 - val_acc: 0.4593 - val_f1: 0.3950\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6653 - acc: 0.5863 - f1: 0.5379 - val_loss: 0.7221 - val_acc: 0.4259 - val_f1: 0.3810\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6667 - acc: 0.5925 - f1: 0.5541 - val_loss: 0.7200 - val_acc: 0.4667 - val_f1: 0.4012\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6642 - acc: 0.5834 - f1: 0.5561 - val_loss: 0.7256 - val_acc: 0.4296 - val_f1: 0.3713\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6636 - acc: 0.5880 - f1: 0.5291 - val_loss: 0.7261 - val_acc: 0.4370 - val_f1: 0.3913\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6614 - acc: 0.6003 - f1: 0.5723 - val_loss: 0.7247 - val_acc: 0.4333 - val_f1: 0.3875\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6602 - acc: 0.5987 - f1: 0.5682 - val_loss: 0.7255 - val_acc: 0.4333 - val_f1: 0.3837\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6615 - acc: 0.5896 - f1: 0.5596 - val_loss: 0.7409 - val_acc: 0.4593 - val_f1: 0.3741\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6618 - acc: 0.5962 - f1: 0.5503 - val_loss: 0.7273 - val_acc: 0.4407 - val_f1: 0.4337\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6603 - acc: 0.5933 - f1: 0.5622 - val_loss: 0.7391 - val_acc: 0.4370 - val_f1: 0.3903\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6578 - acc: 0.5970 - f1: 0.5571 - val_loss: 0.7287 - val_acc: 0.4704 - val_f1: 0.4072\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6583 - acc: 0.6020 - f1: 0.5870 - val_loss: 0.7194 - val_acc: 0.4333 - val_f1: 0.3748\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6583 - acc: 0.5979 - f1: 0.5631 - val_loss: 0.7345 - val_acc: 0.4593 - val_f1: 0.4006\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6521 - acc: 0.6110 - f1: 0.5904 - val_loss: 0.7402 - val_acc: 0.5037 - val_f1: 0.3852\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6537 - acc: 0.6049 - f1: 0.5724 - val_loss: 0.7391 - val_acc: 0.4667 - val_f1: 0.3956\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6501 - acc: 0.6139 - f1: 0.5855 - val_loss: 0.7380 - val_acc: 0.4481 - val_f1: 0.3954\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6486 - acc: 0.6230 - f1: 0.6037 - val_loss: 0.7353 - val_acc: 0.4519 - val_f1: 0.4992\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6516 - acc: 0.6168 - f1: 0.5964 - val_loss: 0.7453 - val_acc: 0.4815 - val_f1: 0.4407\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6483 - acc: 0.6193 - f1: 0.5995 - val_loss: 0.7407 - val_acc: 0.4778 - val_f1: 0.4002\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6456 - acc: 0.6230 - f1: 0.6015 - val_loss: 0.7379 - val_acc: 0.4778 - val_f1: 0.4534\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6428 - acc: 0.6275 - f1: 0.6074 - val_loss: 0.7351 - val_acc: 0.4889 - val_f1: 0.5241\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6429 - acc: 0.6271 - f1: 0.6019 - val_loss: 0.7471 - val_acc: 0.4667 - val_f1: 0.5276\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6413 - acc: 0.6337 - f1: 0.6119 - val_loss: 0.7547 - val_acc: 0.5111 - val_f1: 0.4158\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6407 - acc: 0.6292 - f1: 0.6132 - val_loss: 0.7428 - val_acc: 0.4593 - val_f1: 0.4491\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6441 - acc: 0.6185 - f1: 0.5951 - val_loss: 0.7284 - val_acc: 0.4778 - val_f1: 0.5179\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6383 - acc: 0.6296 - f1: 0.6150 - val_loss: 0.7488 - val_acc: 0.4815 - val_f1: 0.5272\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6348 - acc: 0.6374 - f1: 0.6169 - val_loss: 0.7425 - val_acc: 0.4630 - val_f1: 0.4455\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6349 - acc: 0.6440 - f1: 0.6274 - val_loss: 0.7498 - val_acc: 0.4778 - val_f1: 0.3908\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6287 - acc: 0.6543 - f1: 0.6395 - val_loss: 0.7430 - val_acc: 0.4963 - val_f1: 0.5322\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6302 - acc: 0.6452 - f1: 0.6274 - val_loss: 0.7451 - val_acc: 0.4593 - val_f1: 0.4939\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6239 - acc: 0.6543 - f1: 0.6387 - val_loss: 0.7435 - val_acc: 0.4963 - val_f1: 0.4639\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6236 - acc: 0.6473 - f1: 0.6298 - val_loss: 0.7470 - val_acc: 0.4667 - val_f1: 0.5311\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6221 - acc: 0.6613 - f1: 0.6450 - val_loss: 0.7434 - val_acc: 0.5000 - val_f1: 0.5512\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6256 - acc: 0.6535 - f1: 0.6426 - val_loss: 0.7671 - val_acc: 0.4926 - val_f1: 0.5319\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6196 - acc: 0.6572 - f1: 0.6406 - val_loss: 0.7646 - val_acc: 0.4741 - val_f1: 0.4105\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6207 - acc: 0.6485 - f1: 0.6395 - val_loss: 0.7644 - val_acc: 0.4889 - val_f1: 0.4099\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6158 - acc: 0.6539 - f1: 0.6352 - val_loss: 0.7612 - val_acc: 0.4963 - val_f1: 0.5524\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6170 - acc: 0.6679 - f1: 0.6542 - val_loss: 0.7664 - val_acc: 0.5000 - val_f1: 0.5385\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6097 - acc: 0.6642 - f1: 0.6508 - val_loss: 0.7533 - val_acc: 0.5222 - val_f1: 0.5512\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6114 - acc: 0.6634 - f1: 0.6482 - val_loss: 0.7543 - val_acc: 0.4815 - val_f1: 0.5016\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6028 - acc: 0.6720 - f1: 0.6601 - val_loss: 0.7617 - val_acc: 0.5074 - val_f1: 0.5522\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5995 - acc: 0.6774 - f1: 0.6672 - val_loss: 0.7691 - val_acc: 0.4815 - val_f1: 0.5358\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6092 - acc: 0.6609 - f1: 0.6504 - val_loss: 0.7878 - val_acc: 0.5148 - val_f1: 0.4371\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6035 - acc: 0.6766 - f1: 0.6641 - val_loss: 0.7847 - val_acc: 0.4852 - val_f1: 0.4655\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6028 - acc: 0.6815 - f1: 0.6693 - val_loss: 0.7770 - val_acc: 0.5111 - val_f1: 0.5600\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6051 - acc: 0.6749 - f1: 0.6646 - val_loss: 0.7690 - val_acc: 0.5000 - val_f1: 0.4771\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5912 - acc: 0.6852 - f1: 0.6754 - val_loss: 0.7903 - val_acc: 0.4963 - val_f1: 0.4256\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5983 - acc: 0.6733 - f1: 0.6632 - val_loss: 0.7748 - val_acc: 0.5148 - val_f1: 0.4810\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5885 - acc: 0.6864 - f1: 0.6765 - val_loss: 0.7874 - val_acc: 0.5111 - val_f1: 0.4902\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5931 - acc: 0.6819 - f1: 0.6701 - val_loss: 0.7626 - val_acc: 0.5000 - val_f1: 0.5546\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5924 - acc: 0.6889 - f1: 0.6769 - val_loss: 0.7692 - val_acc: 0.5074 - val_f1: 0.5570\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5932 - acc: 0.6844 - f1: 0.6759 - val_loss: 0.7883 - val_acc: 0.5185 - val_f1: 0.4893\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5816 - acc: 0.6959 - f1: 0.6838 - val_loss: 0.8007 - val_acc: 0.5000 - val_f1: 0.4809\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5859 - acc: 0.6893 - f1: 0.6816 - val_loss: 0.7991 - val_acc: 0.5111 - val_f1: 0.4878\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5776 - acc: 0.6947 - f1: 0.6852 - val_loss: 0.7938 - val_acc: 0.5333 - val_f1: 0.5051\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5839 - acc: 0.6934 - f1: 0.6830 - val_loss: 0.7988 - val_acc: 0.5148 - val_f1: 0.4888\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5836 - acc: 0.6910 - f1: 0.6823 - val_loss: 0.7987 - val_acc: 0.5148 - val_f1: 0.4946\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5765 - acc: 0.6910 - f1: 0.6793 - val_loss: 0.7957 - val_acc: 0.5074 - val_f1: 0.4921\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5778 - acc: 0.6918 - f1: 0.6849 - val_loss: 0.8123 - val_acc: 0.5111 - val_f1: 0.4911\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5697 - acc: 0.7079 - f1: 0.6975 - val_loss: 0.8140 - val_acc: 0.4926 - val_f1: 0.5150\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5698 - acc: 0.7079 - f1: 0.7004 - val_loss: 0.8057 - val_acc: 0.4963 - val_f1: 0.4783\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5676 - acc: 0.6922 - f1: 0.6848 - val_loss: 0.8224 - val_acc: 0.5222 - val_f1: 0.5354\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5677 - acc: 0.7058 - f1: 0.6974 - val_loss: 0.8229 - val_acc: 0.5148 - val_f1: 0.4942\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5656 - acc: 0.7037 - f1: 0.6923 - val_loss: 0.8027 - val_acc: 0.5185 - val_f1: 0.4937\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5674 - acc: 0.6980 - f1: 0.6901 - val_loss: 0.8059 - val_acc: 0.5037 - val_f1: 0.4893\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6901 - acc: 0.5517 - f1: 0.3637 - val_loss: 0.6906 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6886 - acc: 0.5534 - f1: 0.3564 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6879 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6919 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6877 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6864 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6857 - acc: 0.5538 - f1: 0.3571 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6857 - acc: 0.5546 - f1: 0.3593 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6848 - acc: 0.5529 - f1: 0.3714 - val_loss: 0.6984 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6851 - acc: 0.5567 - f1: 0.3677 - val_loss: 0.6943 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6837 - acc: 0.5567 - f1: 0.3657 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.5538 - f1: 0.3633 - val_loss: 0.6929 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6852 - acc: 0.5529 - f1: 0.3657 - val_loss: 0.6938 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6837 - acc: 0.5562 - f1: 0.3649 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 0.5501 - f1: 0.3772 - val_loss: 0.6961 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6848 - acc: 0.5529 - f1: 0.3631 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.5567 - f1: 0.3749 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6830 - acc: 0.5554 - f1: 0.3980 - val_loss: 0.6919 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6817 - acc: 0.5587 - f1: 0.3866 - val_loss: 0.6924 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.5517 - f1: 0.3787 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6787 - acc: 0.5624 - f1: 0.3965 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6801 - acc: 0.5538 - f1: 0.4066 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6783 - acc: 0.5674 - f1: 0.4533 - val_loss: 0.6933 - val_acc: 0.5370 - val_f1: 0.3871\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6772 - acc: 0.5661 - f1: 0.4745 - val_loss: 0.6911 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6759 - acc: 0.5715 - f1: 0.4480 - val_loss: 0.6918 - val_acc: 0.5444 - val_f1: 0.3828\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6824 - acc: 0.5595 - f1: 0.4698 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6767 - acc: 0.5612 - f1: 0.4379 - val_loss: 0.6934 - val_acc: 0.5333 - val_f1: 0.3485\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6752 - acc: 0.5843 - f1: 0.4985 - val_loss: 0.6941 - val_acc: 0.5333 - val_f1: 0.3844\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6741 - acc: 0.5764 - f1: 0.4871 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.4090\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.5904 - f1: 0.5475 - val_loss: 0.6910 - val_acc: 0.5333 - val_f1: 0.3576\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6700 - acc: 0.5773 - f1: 0.4991 - val_loss: 0.6933 - val_acc: 0.5111 - val_f1: 0.4452\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.5756 - f1: 0.5199 - val_loss: 0.6887 - val_acc: 0.5370 - val_f1: 0.3543\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6661 - acc: 0.5896 - f1: 0.5475 - val_loss: 0.6911 - val_acc: 0.5370 - val_f1: 0.5507\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6662 - acc: 0.5933 - f1: 0.5402 - val_loss: 0.6897 - val_acc: 0.5593 - val_f1: 0.4706\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6681 - acc: 0.5933 - f1: 0.5535 - val_loss: 0.6910 - val_acc: 0.5481 - val_f1: 0.5707\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6674 - acc: 0.5785 - f1: 0.5273 - val_loss: 0.6942 - val_acc: 0.5259 - val_f1: 0.3639\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6648 - acc: 0.5859 - f1: 0.5298 - val_loss: 0.6944 - val_acc: 0.5185 - val_f1: 0.4671\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6632 - acc: 0.5954 - f1: 0.5640 - val_loss: 0.6890 - val_acc: 0.5519 - val_f1: 0.5251\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6599 - acc: 0.5995 - f1: 0.5649 - val_loss: 0.6946 - val_acc: 0.4815 - val_f1: 0.5208\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6600 - acc: 0.6069 - f1: 0.5608 - val_loss: 0.6914 - val_acc: 0.5148 - val_f1: 0.5231\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6610 - acc: 0.6152 - f1: 0.5926 - val_loss: 0.6906 - val_acc: 0.5407 - val_f1: 0.5545\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6569 - acc: 0.6065 - f1: 0.5786 - val_loss: 0.6901 - val_acc: 0.5333 - val_f1: 0.5530\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6564 - acc: 0.5987 - f1: 0.5635 - val_loss: 0.6871 - val_acc: 0.5444 - val_f1: 0.5842\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6581 - acc: 0.6115 - f1: 0.5945 - val_loss: 0.6884 - val_acc: 0.5593 - val_f1: 0.5398\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6580 - acc: 0.6148 - f1: 0.5767 - val_loss: 0.6902 - val_acc: 0.5593 - val_f1: 0.5427\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6572 - acc: 0.6160 - f1: 0.5973 - val_loss: 0.6874 - val_acc: 0.5444 - val_f1: 0.4781\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6547 - acc: 0.6123 - f1: 0.5632 - val_loss: 0.6912 - val_acc: 0.5370 - val_f1: 0.5355\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6504 - acc: 0.6180 - f1: 0.6029 - val_loss: 0.6894 - val_acc: 0.5556 - val_f1: 0.4997\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6496 - acc: 0.6131 - f1: 0.5870 - val_loss: 0.6867 - val_acc: 0.5704 - val_f1: 0.5243\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6463 - acc: 0.6222 - f1: 0.5963 - val_loss: 0.6872 - val_acc: 0.5556 - val_f1: 0.5068\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6478 - acc: 0.6164 - f1: 0.5936 - val_loss: 0.6870 - val_acc: 0.5630 - val_f1: 0.5013\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6421 - acc: 0.6275 - f1: 0.6094 - val_loss: 0.6888 - val_acc: 0.5296 - val_f1: 0.5419\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6460 - acc: 0.6288 - f1: 0.6052 - val_loss: 0.6863 - val_acc: 0.5481 - val_f1: 0.5103\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6437 - acc: 0.6197 - f1: 0.6029 - val_loss: 0.6890 - val_acc: 0.5852 - val_f1: 0.5894\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6451 - acc: 0.6288 - f1: 0.6054 - val_loss: 0.6889 - val_acc: 0.5296 - val_f1: 0.5082\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6405 - acc: 0.6395 - f1: 0.6210 - val_loss: 0.6802 - val_acc: 0.5481 - val_f1: 0.4802\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6382 - acc: 0.6358 - f1: 0.6169 - val_loss: 0.6896 - val_acc: 0.5481 - val_f1: 0.5650\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6353 - acc: 0.6382 - f1: 0.6201 - val_loss: 0.6890 - val_acc: 0.5259 - val_f1: 0.4994\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6382 - acc: 0.6366 - f1: 0.6182 - val_loss: 0.6884 - val_acc: 0.5704 - val_f1: 0.5139\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6347 - acc: 0.6452 - f1: 0.6297 - val_loss: 0.6895 - val_acc: 0.5593 - val_f1: 0.5419\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6298 - acc: 0.6461 - f1: 0.6306 - val_loss: 0.6903 - val_acc: 0.5630 - val_f1: 0.5766\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6326 - acc: 0.6510 - f1: 0.6385 - val_loss: 0.6911 - val_acc: 0.5519 - val_f1: 0.5285\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6280 - acc: 0.6419 - f1: 0.6263 - val_loss: 0.6915 - val_acc: 0.5370 - val_f1: 0.4502\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6321 - acc: 0.6378 - f1: 0.6192 - val_loss: 0.6930 - val_acc: 0.5444 - val_f1: 0.5345\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6291 - acc: 0.6399 - f1: 0.6199 - val_loss: 0.6918 - val_acc: 0.5333 - val_f1: 0.4957\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6264 - acc: 0.6502 - f1: 0.6394 - val_loss: 0.6951 - val_acc: 0.5444 - val_f1: 0.5261\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6228 - acc: 0.6531 - f1: 0.6354 - val_loss: 0.6956 - val_acc: 0.5519 - val_f1: 0.5180\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6224 - acc: 0.6588 - f1: 0.6464 - val_loss: 0.6988 - val_acc: 0.5111 - val_f1: 0.4912\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6235 - acc: 0.6551 - f1: 0.6416 - val_loss: 0.6930 - val_acc: 0.5370 - val_f1: 0.5298\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6204 - acc: 0.6617 - f1: 0.6492 - val_loss: 0.6933 - val_acc: 0.5593 - val_f1: 0.5332\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6217 - acc: 0.6473 - f1: 0.6344 - val_loss: 0.6971 - val_acc: 0.5556 - val_f1: 0.5018\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6145 - acc: 0.6593 - f1: 0.6429 - val_loss: 0.6947 - val_acc: 0.5444 - val_f1: 0.5280\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6155 - acc: 0.6588 - f1: 0.6451 - val_loss: 0.6927 - val_acc: 0.5444 - val_f1: 0.5060\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6190 - acc: 0.6617 - f1: 0.6508 - val_loss: 0.7177 - val_acc: 0.5259 - val_f1: 0.4030\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6127 - acc: 0.6638 - f1: 0.6503 - val_loss: 0.7043 - val_acc: 0.5444 - val_f1: 0.4691\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6103 - acc: 0.6634 - f1: 0.6456 - val_loss: 0.7033 - val_acc: 0.5481 - val_f1: 0.5111\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6099 - acc: 0.6753 - f1: 0.6668 - val_loss: 0.7107 - val_acc: 0.5519 - val_f1: 0.5029\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6059 - acc: 0.6667 - f1: 0.6487 - val_loss: 0.7000 - val_acc: 0.5519 - val_f1: 0.4916\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6090 - acc: 0.6794 - f1: 0.6726 - val_loss: 0.7005 - val_acc: 0.5296 - val_f1: 0.4961\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6077 - acc: 0.6733 - f1: 0.6615 - val_loss: 0.7024 - val_acc: 0.5148 - val_f1: 0.5244\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6044 - acc: 0.6749 - f1: 0.6616 - val_loss: 0.7017 - val_acc: 0.5444 - val_f1: 0.5137\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6063 - acc: 0.6728 - f1: 0.6613 - val_loss: 0.6939 - val_acc: 0.5741 - val_f1: 0.5690\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5991 - acc: 0.6720 - f1: 0.6593 - val_loss: 0.6955 - val_acc: 0.5593 - val_f1: 0.5232\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5988 - acc: 0.6741 - f1: 0.6642 - val_loss: 0.7092 - val_acc: 0.5370 - val_f1: 0.5461\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5960 - acc: 0.6630 - f1: 0.6491 - val_loss: 0.6966 - val_acc: 0.5667 - val_f1: 0.5631\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6005 - acc: 0.6803 - f1: 0.6700 - val_loss: 0.7047 - val_acc: 0.5556 - val_f1: 0.5181\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5974 - acc: 0.6728 - f1: 0.6615 - val_loss: 0.7028 - val_acc: 0.5370 - val_f1: 0.4921\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5967 - acc: 0.6885 - f1: 0.6781 - val_loss: 0.7110 - val_acc: 0.5074 - val_f1: 0.5409\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5992 - acc: 0.6774 - f1: 0.6660 - val_loss: 0.7060 - val_acc: 0.5444 - val_f1: 0.5299\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5903 - acc: 0.6864 - f1: 0.6765 - val_loss: 0.7052 - val_acc: 0.5481 - val_f1: 0.5438\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5905 - acc: 0.6906 - f1: 0.6784 - val_loss: 0.7014 - val_acc: 0.5481 - val_f1: 0.5222\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5882 - acc: 0.6873 - f1: 0.6775 - val_loss: 0.7186 - val_acc: 0.5296 - val_f1: 0.5187\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5919 - acc: 0.6782 - f1: 0.6687 - val_loss: 0.7069 - val_acc: 0.5407 - val_f1: 0.4903\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5807 - acc: 0.7033 - f1: 0.6934 - val_loss: 0.7190 - val_acc: 0.5444 - val_f1: 0.5397\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5869 - acc: 0.6819 - f1: 0.6730 - val_loss: 0.7114 - val_acc: 0.5630 - val_f1: 0.5104\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5801 - acc: 0.6914 - f1: 0.6833 - val_loss: 0.7177 - val_acc: 0.5481 - val_f1: 0.5101\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5683 - acc: 0.7145 - f1: 0.7051 - val_loss: 0.7207 - val_acc: 0.5370 - val_f1: 0.4931\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5768 - acc: 0.6930 - f1: 0.6828 - val_loss: 0.7145 - val_acc: 0.5407 - val_f1: 0.5078\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5734 - acc: 0.7042 - f1: 0.6949 - val_loss: 0.7253 - val_acc: 0.5259 - val_f1: 0.5002\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5730 - acc: 0.6885 - f1: 0.6781 - val_loss: 0.7202 - val_acc: 0.5296 - val_f1: 0.4853\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5746 - acc: 0.6856 - f1: 0.6741 - val_loss: 0.7249 - val_acc: 0.5111 - val_f1: 0.4843\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5765 - acc: 0.6984 - f1: 0.6906 - val_loss: 0.7025 - val_acc: 0.5741 - val_f1: 0.5482\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5761 - acc: 0.6906 - f1: 0.6812 - val_loss: 0.7073 - val_acc: 0.5370 - val_f1: 0.5334\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5640 - acc: 0.7013 - f1: 0.6931 - val_loss: 0.7012 - val_acc: 0.5333 - val_f1: 0.5261\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5678 - acc: 0.7083 - f1: 0.7012 - val_loss: 0.7052 - val_acc: 0.5481 - val_f1: 0.5360\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5663 - acc: 0.7037 - f1: 0.6967 - val_loss: 0.7052 - val_acc: 0.5556 - val_f1: 0.5642\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5628 - acc: 0.7033 - f1: 0.6939 - val_loss: 0.7005 - val_acc: 0.5481 - val_f1: 0.5602\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5610 - acc: 0.7087 - f1: 0.7009 - val_loss: 0.7064 - val_acc: 0.5630 - val_f1: 0.5305\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5664 - acc: 0.7013 - f1: 0.6915 - val_loss: 0.7070 - val_acc: 0.5333 - val_f1: 0.5094\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5600 - acc: 0.7211 - f1: 0.7123 - val_loss: 0.7055 - val_acc: 0.5556 - val_f1: 0.5395\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5534 - acc: 0.7145 - f1: 0.7069 - val_loss: 0.7056 - val_acc: 0.5593 - val_f1: 0.5322\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5596 - acc: 0.7079 - f1: 0.7005 - val_loss: 0.7163 - val_acc: 0.5333 - val_f1: 0.4979\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5598 - acc: 0.7075 - f1: 0.6981 - val_loss: 0.7171 - val_acc: 0.5481 - val_f1: 0.5212\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5452 - acc: 0.7083 - f1: 0.6997 - val_loss: 0.7172 - val_acc: 0.5333 - val_f1: 0.5155\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5481 - acc: 0.7215 - f1: 0.7148 - val_loss: 0.7033 - val_acc: 0.5630 - val_f1: 0.5819\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5517 - acc: 0.7132 - f1: 0.7064 - val_loss: 0.7054 - val_acc: 0.5852 - val_f1: 0.5841\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5494 - acc: 0.7124 - f1: 0.7043 - val_loss: 0.7079 - val_acc: 0.5519 - val_f1: 0.5399\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5427 - acc: 0.7309 - f1: 0.7241 - val_loss: 0.7143 - val_acc: 0.5444 - val_f1: 0.5530\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5450 - acc: 0.7116 - f1: 0.7054 - val_loss: 0.7216 - val_acc: 0.5556 - val_f1: 0.5375\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5489 - acc: 0.7132 - f1: 0.7051 - val_loss: 0.7141 - val_acc: 0.5333 - val_f1: 0.5302\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5393 - acc: 0.7289 - f1: 0.7201 - val_loss: 0.7182 - val_acc: 0.5556 - val_f1: 0.5489\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5442 - acc: 0.7281 - f1: 0.7217 - val_loss: 0.7120 - val_acc: 0.5407 - val_f1: 0.5501\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5448 - acc: 0.7223 - f1: 0.7151 - val_loss: 0.7097 - val_acc: 0.5593 - val_f1: 0.5954\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5466 - acc: 0.7231 - f1: 0.7171 - val_loss: 0.7137 - val_acc: 0.5556 - val_f1: 0.5778\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5418 - acc: 0.7276 - f1: 0.7233 - val_loss: 0.7094 - val_acc: 0.5519 - val_f1: 0.5677\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5357 - acc: 0.7281 - f1: 0.7186 - val_loss: 0.6975 - val_acc: 0.5111 - val_f1: 0.5238\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5339 - acc: 0.7388 - f1: 0.7334 - val_loss: 0.7139 - val_acc: 0.5407 - val_f1: 0.5453\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5318 - acc: 0.7322 - f1: 0.7241 - val_loss: 0.7148 - val_acc: 0.5519 - val_f1: 0.5601\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5306 - acc: 0.7305 - f1: 0.7248 - val_loss: 0.7050 - val_acc: 0.5111 - val_f1: 0.5434\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5379 - acc: 0.7351 - f1: 0.7274 - val_loss: 0.7125 - val_acc: 0.5407 - val_f1: 0.5651\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5374 - acc: 0.7289 - f1: 0.7233 - val_loss: 0.7210 - val_acc: 0.5444 - val_f1: 0.5158\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5326 - acc: 0.7281 - f1: 0.7195 - val_loss: 0.7207 - val_acc: 0.5481 - val_f1: 0.5724\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5318 - acc: 0.7404 - f1: 0.7336 - val_loss: 0.7033 - val_acc: 0.5667 - val_f1: 0.5614\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5352 - acc: 0.7239 - f1: 0.7161 - val_loss: 0.7228 - val_acc: 0.5519 - val_f1: 0.5484\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5243 - acc: 0.7281 - f1: 0.7228 - val_loss: 0.7213 - val_acc: 0.5444 - val_f1: 0.5387\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5160 - acc: 0.7487 - f1: 0.7403 - val_loss: 0.7121 - val_acc: 0.5481 - val_f1: 0.5821\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5205 - acc: 0.7326 - f1: 0.7252 - val_loss: 0.7299 - val_acc: 0.4815 - val_f1: 0.5202\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5267 - acc: 0.7375 - f1: 0.7327 - val_loss: 0.7158 - val_acc: 0.5185 - val_f1: 0.5700\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5207 - acc: 0.7445 - f1: 0.7392 - val_loss: 0.7140 - val_acc: 0.5259 - val_f1: 0.5545\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5201 - acc: 0.7355 - f1: 0.7306 - val_loss: 0.7328 - val_acc: 0.5444 - val_f1: 0.5396\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5222 - acc: 0.7322 - f1: 0.7255 - val_loss: 0.7223 - val_acc: 0.5519 - val_f1: 0.5402\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5163 - acc: 0.7375 - f1: 0.7293 - val_loss: 0.7228 - val_acc: 0.5148 - val_f1: 0.5516\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5179 - acc: 0.7338 - f1: 0.7294 - val_loss: 0.7196 - val_acc: 0.5074 - val_f1: 0.5417\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5087 - acc: 0.7474 - f1: 0.7411 - val_loss: 0.7142 - val_acc: 0.5593 - val_f1: 0.5897\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5143 - acc: 0.7437 - f1: 0.7385 - val_loss: 0.7203 - val_acc: 0.5259 - val_f1: 0.5237\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5142 - acc: 0.7425 - f1: 0.7362 - val_loss: 0.7380 - val_acc: 0.5481 - val_f1: 0.5400\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5059 - acc: 0.7487 - f1: 0.7433 - val_loss: 0.7350 - val_acc: 0.5111 - val_f1: 0.5194\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5119 - acc: 0.7355 - f1: 0.7277 - val_loss: 0.7259 - val_acc: 0.5481 - val_f1: 0.5449\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5069 - acc: 0.7594 - f1: 0.7551 - val_loss: 0.7425 - val_acc: 0.5370 - val_f1: 0.5522\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5071 - acc: 0.7437 - f1: 0.7380 - val_loss: 0.7192 - val_acc: 0.5148 - val_f1: 0.5491\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5191 - acc: 0.7417 - f1: 0.7367 - val_loss: 0.7391 - val_acc: 0.4963 - val_f1: 0.5126\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5120 - acc: 0.7470 - f1: 0.7408 - val_loss: 0.7338 - val_acc: 0.5333 - val_f1: 0.5367\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5005 - acc: 0.7553 - f1: 0.7503 - val_loss: 0.7298 - val_acc: 0.5185 - val_f1: 0.5534\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5041 - acc: 0.7511 - f1: 0.7460 - val_loss: 0.7338 - val_acc: 0.4926 - val_f1: 0.5357\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5033 - acc: 0.7462 - f1: 0.7410 - val_loss: 0.7253 - val_acc: 0.5222 - val_f1: 0.5561\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5007 - acc: 0.7524 - f1: 0.7466 - val_loss: 0.7261 - val_acc: 0.5148 - val_f1: 0.5724\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6894 - acc: 0.5476 - f1: 0.3659 - val_loss: 0.6909 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6879 - acc: 0.5521 - f1: 0.3594 - val_loss: 0.6924 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6869 - acc: 0.5538 - f1: 0.3574 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6874 - acc: 0.5538 - f1: 0.3585 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6873 - acc: 0.5538 - f1: 0.3572 - val_loss: 0.6941 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5513 - f1: 0.3598 - val_loss: 0.6946 - val_acc: 0.5148 - val_f1: 0.3678\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5542 - f1: 0.3630 - val_loss: 0.6952 - val_acc: 0.5074 - val_f1: 0.3650\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6853 - acc: 0.5501 - f1: 0.3750 - val_loss: 0.6943 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 0.5332 - f1: 0.4105 - val_loss: 0.6938 - val_acc: 0.4481 - val_f1: 0.3613\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6884 - acc: 0.5459 - f1: 0.3810 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6885 - acc: 0.5492 - f1: 0.3911 - val_loss: 0.6949 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6856 - acc: 0.5538 - f1: 0.3594 - val_loss: 0.6939 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6848 - acc: 0.5546 - f1: 0.3598 - val_loss: 0.6953 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6849 - acc: 0.5534 - f1: 0.3629 - val_loss: 0.6955 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6837 - acc: 0.5608 - f1: 0.4113 - val_loss: 0.6959 - val_acc: 0.5074 - val_f1: 0.3816\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6841 - acc: 0.5505 - f1: 0.3816 - val_loss: 0.6959 - val_acc: 0.4704 - val_f1: 0.3989\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6850 - acc: 0.5558 - f1: 0.3874 - val_loss: 0.6966 - val_acc: 0.4741 - val_f1: 0.3911\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6827 - acc: 0.5538 - f1: 0.4110 - val_loss: 0.6963 - val_acc: 0.4889 - val_f1: 0.3848\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6829 - acc: 0.5567 - f1: 0.4109 - val_loss: 0.6975 - val_acc: 0.4519 - val_f1: 0.4087\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6829 - acc: 0.5661 - f1: 0.4285 - val_loss: 0.6969 - val_acc: 0.4741 - val_f1: 0.3881\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6817 - acc: 0.5587 - f1: 0.4268 - val_loss: 0.6966 - val_acc: 0.4852 - val_f1: 0.3944\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6818 - acc: 0.5579 - f1: 0.4080 - val_loss: 0.6983 - val_acc: 0.4259 - val_f1: 0.3905\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6807 - acc: 0.5707 - f1: 0.4778 - val_loss: 0.6965 - val_acc: 0.4444 - val_f1: 0.3970\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6806 - acc: 0.5554 - f1: 0.4460 - val_loss: 0.6973 - val_acc: 0.4667 - val_f1: 0.5037\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6805 - acc: 0.5608 - f1: 0.4609 - val_loss: 0.6980 - val_acc: 0.4556 - val_f1: 0.4087\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6799 - acc: 0.5690 - f1: 0.4463 - val_loss: 0.6971 - val_acc: 0.4815 - val_f1: 0.4750\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6792 - acc: 0.5785 - f1: 0.5160 - val_loss: 0.6959 - val_acc: 0.5259 - val_f1: 0.3946\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6784 - acc: 0.5711 - f1: 0.4423 - val_loss: 0.6934 - val_acc: 0.4963 - val_f1: 0.4894\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6784 - acc: 0.5649 - f1: 0.4801 - val_loss: 0.6978 - val_acc: 0.4815 - val_f1: 0.4108\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6764 - acc: 0.5637 - f1: 0.4729 - val_loss: 0.6945 - val_acc: 0.5148 - val_f1: 0.5511\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6777 - acc: 0.5711 - f1: 0.4869 - val_loss: 0.6983 - val_acc: 0.5222 - val_f1: 0.5671\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6766 - acc: 0.5773 - f1: 0.5187 - val_loss: 0.6945 - val_acc: 0.5444 - val_f1: 0.5517\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6743 - acc: 0.5801 - f1: 0.5233 - val_loss: 0.6961 - val_acc: 0.5370 - val_f1: 0.5821\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.5801 - f1: 0.5028 - val_loss: 0.7026 - val_acc: 0.5259 - val_f1: 0.5700\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.5793 - f1: 0.5357 - val_loss: 0.6992 - val_acc: 0.5333 - val_f1: 0.5832\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6699 - acc: 0.5822 - f1: 0.5424 - val_loss: 0.7041 - val_acc: 0.5296 - val_f1: 0.5616\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6705 - acc: 0.5748 - f1: 0.5255 - val_loss: 0.7002 - val_acc: 0.5444 - val_f1: 0.5577\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6692 - acc: 0.5806 - f1: 0.5194 - val_loss: 0.7027 - val_acc: 0.5333 - val_f1: 0.5822\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6687 - acc: 0.5826 - f1: 0.5462 - val_loss: 0.6956 - val_acc: 0.5630 - val_f1: 0.5593\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6702 - acc: 0.5818 - f1: 0.5386 - val_loss: 0.7034 - val_acc: 0.5259 - val_f1: 0.5525\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6654 - acc: 0.5941 - f1: 0.5557 - val_loss: 0.6966 - val_acc: 0.5741 - val_f1: 0.5986\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6644 - acc: 0.5999 - f1: 0.5676 - val_loss: 0.7039 - val_acc: 0.5407 - val_f1: 0.5591\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6655 - acc: 0.5851 - f1: 0.5418 - val_loss: 0.6944 - val_acc: 0.5407 - val_f1: 0.5670\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6608 - acc: 0.6049 - f1: 0.5688 - val_loss: 0.7075 - val_acc: 0.5148 - val_f1: 0.5713\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6591 - acc: 0.6003 - f1: 0.5656 - val_loss: 0.6954 - val_acc: 0.5519 - val_f1: 0.5728\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6624 - acc: 0.6003 - f1: 0.5704 - val_loss: 0.7045 - val_acc: 0.5407 - val_f1: 0.5702\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6593 - acc: 0.5991 - f1: 0.5747 - val_loss: 0.6968 - val_acc: 0.5407 - val_f1: 0.5813\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6569 - acc: 0.6086 - f1: 0.5785 - val_loss: 0.7069 - val_acc: 0.5556 - val_f1: 0.5927\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6542 - acc: 0.6102 - f1: 0.5846 - val_loss: 0.6973 - val_acc: 0.5444 - val_f1: 0.5661\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6506 - acc: 0.6115 - f1: 0.5803 - val_loss: 0.7012 - val_acc: 0.5296 - val_f1: 0.5390\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6575 - acc: 0.6049 - f1: 0.5873 - val_loss: 0.7099 - val_acc: 0.5296 - val_f1: 0.5720\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6493 - acc: 0.6271 - f1: 0.5991 - val_loss: 0.7029 - val_acc: 0.5481 - val_f1: 0.5682\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6508 - acc: 0.6197 - f1: 0.6018 - val_loss: 0.7097 - val_acc: 0.5370 - val_f1: 0.5794\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6530 - acc: 0.6213 - f1: 0.5971 - val_loss: 0.7018 - val_acc: 0.5407 - val_f1: 0.5575\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6488 - acc: 0.6218 - f1: 0.5986 - val_loss: 0.7019 - val_acc: 0.5444 - val_f1: 0.5796\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6473 - acc: 0.6255 - f1: 0.6098 - val_loss: 0.7039 - val_acc: 0.5370 - val_f1: 0.5519\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6425 - acc: 0.6218 - f1: 0.5969 - val_loss: 0.7050 - val_acc: 0.5333 - val_f1: 0.5396\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6421 - acc: 0.6321 - f1: 0.6147 - val_loss: 0.7035 - val_acc: 0.5259 - val_f1: 0.5475\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6394 - acc: 0.6337 - f1: 0.6193 - val_loss: 0.7051 - val_acc: 0.5481 - val_f1: 0.5655\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6422 - acc: 0.6271 - f1: 0.6054 - val_loss: 0.7052 - val_acc: 0.5333 - val_f1: 0.5597\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6426 - acc: 0.6349 - f1: 0.6122 - val_loss: 0.7014 - val_acc: 0.5444 - val_f1: 0.5456\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6403 - acc: 0.6366 - f1: 0.6215 - val_loss: 0.7139 - val_acc: 0.5296 - val_f1: 0.5416\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6402 - acc: 0.6391 - f1: 0.6197 - val_loss: 0.7023 - val_acc: 0.5519 - val_f1: 0.5687\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6360 - acc: 0.6382 - f1: 0.6238 - val_loss: 0.7109 - val_acc: 0.5148 - val_f1: 0.5447\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6343 - acc: 0.6465 - f1: 0.6346 - val_loss: 0.7019 - val_acc: 0.5185 - val_f1: 0.5276\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6355 - acc: 0.6370 - f1: 0.6143 - val_loss: 0.7035 - val_acc: 0.5074 - val_f1: 0.5444\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6308 - acc: 0.6473 - f1: 0.6327 - val_loss: 0.7008 - val_acc: 0.5481 - val_f1: 0.5672\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6277 - acc: 0.6547 - f1: 0.6386 - val_loss: 0.6961 - val_acc: 0.5333 - val_f1: 0.5615\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6332 - acc: 0.6382 - f1: 0.6211 - val_loss: 0.7056 - val_acc: 0.5222 - val_f1: 0.5538\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6316 - acc: 0.6481 - f1: 0.6350 - val_loss: 0.6991 - val_acc: 0.5333 - val_f1: 0.5350\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6248 - acc: 0.6498 - f1: 0.6295 - val_loss: 0.6979 - val_acc: 0.5222 - val_f1: 0.5315\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6247 - acc: 0.6543 - f1: 0.6432 - val_loss: 0.7015 - val_acc: 0.5333 - val_f1: 0.5380\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6289 - acc: 0.6502 - f1: 0.6331 - val_loss: 0.7048 - val_acc: 0.5148 - val_f1: 0.5456\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6278 - acc: 0.6531 - f1: 0.6380 - val_loss: 0.6973 - val_acc: 0.5407 - val_f1: 0.5344\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6260 - acc: 0.6514 - f1: 0.6342 - val_loss: 0.7016 - val_acc: 0.5333 - val_f1: 0.5317\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6175 - acc: 0.6642 - f1: 0.6555 - val_loss: 0.7057 - val_acc: 0.5296 - val_f1: 0.5528\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6190 - acc: 0.6568 - f1: 0.6398 - val_loss: 0.7053 - val_acc: 0.5111 - val_f1: 0.5242\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6181 - acc: 0.6634 - f1: 0.6520 - val_loss: 0.6990 - val_acc: 0.5444 - val_f1: 0.5362\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6136 - acc: 0.6650 - f1: 0.6519 - val_loss: 0.6986 - val_acc: 0.5259 - val_f1: 0.5302\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6152 - acc: 0.6675 - f1: 0.6559 - val_loss: 0.7018 - val_acc: 0.5370 - val_f1: 0.5585\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6115 - acc: 0.6675 - f1: 0.6526 - val_loss: 0.6970 - val_acc: 0.5296 - val_f1: 0.5601\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6095 - acc: 0.6679 - f1: 0.6583 - val_loss: 0.7116 - val_acc: 0.5185 - val_f1: 0.5235\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6109 - acc: 0.6712 - f1: 0.6574 - val_loss: 0.6996 - val_acc: 0.5222 - val_f1: 0.5535\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6161 - acc: 0.6667 - f1: 0.6572 - val_loss: 0.7034 - val_acc: 0.5370 - val_f1: 0.5612\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6068 - acc: 0.6700 - f1: 0.6574 - val_loss: 0.6991 - val_acc: 0.5519 - val_f1: 0.5699\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6094 - acc: 0.6650 - f1: 0.6546 - val_loss: 0.7016 - val_acc: 0.5370 - val_f1: 0.5572\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6135 - acc: 0.6650 - f1: 0.6511 - val_loss: 0.7022 - val_acc: 0.5296 - val_f1: 0.5568\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6085 - acc: 0.6716 - f1: 0.6602 - val_loss: 0.7007 - val_acc: 0.5222 - val_f1: 0.5529\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6039 - acc: 0.6823 - f1: 0.6682 - val_loss: 0.7020 - val_acc: 0.5333 - val_f1: 0.5593\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6049 - acc: 0.6811 - f1: 0.6707 - val_loss: 0.7016 - val_acc: 0.5407 - val_f1: 0.5667\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6013 - acc: 0.6700 - f1: 0.6604 - val_loss: 0.6929 - val_acc: 0.5593 - val_f1: 0.5172\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5998 - acc: 0.6728 - f1: 0.6567 - val_loss: 0.6963 - val_acc: 0.5519 - val_f1: 0.5480\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5946 - acc: 0.6852 - f1: 0.6774 - val_loss: 0.6964 - val_acc: 0.5519 - val_f1: 0.5506\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5961 - acc: 0.6815 - f1: 0.6691 - val_loss: 0.7198 - val_acc: 0.4963 - val_f1: 0.5178\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6003 - acc: 0.6778 - f1: 0.6685 - val_loss: 0.7014 - val_acc: 0.5481 - val_f1: 0.5619\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5907 - acc: 0.6926 - f1: 0.6812 - val_loss: 0.7148 - val_acc: 0.5148 - val_f1: 0.5246\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5905 - acc: 0.6893 - f1: 0.6800 - val_loss: 0.7106 - val_acc: 0.5222 - val_f1: 0.5547\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5934 - acc: 0.6831 - f1: 0.6747 - val_loss: 0.7095 - val_acc: 0.5333 - val_f1: 0.5576\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5919 - acc: 0.6967 - f1: 0.6845 - val_loss: 0.7078 - val_acc: 0.5111 - val_f1: 0.5425\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5854 - acc: 0.6951 - f1: 0.6849 - val_loss: 0.7097 - val_acc: 0.5481 - val_f1: 0.5709\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5864 - acc: 0.6980 - f1: 0.6909 - val_loss: 0.7089 - val_acc: 0.5481 - val_f1: 0.5185\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 21ms/step - loss: 0.6900 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6912 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6880 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6879 - acc: 0.5546 - f1: 0.3590 - val_loss: 0.6924 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6882 - acc: 0.5529 - f1: 0.3585 - val_loss: 0.6904 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6879 - acc: 0.5517 - f1: 0.3549 - val_loss: 0.6915 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6865 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.6929 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6860 - acc: 0.5534 - f1: 0.3579 - val_loss: 0.6916 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6854 - acc: 0.5534 - f1: 0.3577 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6866 - acc: 0.5538 - f1: 0.3585 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6846 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 0.5571 - f1: 0.3746 - val_loss: 0.6945 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6843 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6950 - val_acc: 0.5222 - val_f1: 0.3627\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6847 - acc: 0.5550 - f1: 0.3645 - val_loss: 0.6928 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5529 - f1: 0.3738 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6840 - acc: 0.5521 - f1: 0.3953 - val_loss: 0.6920 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6829 - acc: 0.5538 - f1: 0.3680 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6827 - acc: 0.5583 - f1: 0.3778 - val_loss: 0.6917 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5550 - f1: 0.3921 - val_loss: 0.6980 - val_acc: 0.4407 - val_f1: 0.3836\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6826 - acc: 0.5521 - f1: 0.3865 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6826 - acc: 0.5521 - f1: 0.4054 - val_loss: 0.6960 - val_acc: 0.5259 - val_f1: 0.3553\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6808 - acc: 0.5571 - f1: 0.4004 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6783 - acc: 0.5632 - f1: 0.4078 - val_loss: 0.6967 - val_acc: 0.4444 - val_f1: 0.3910\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6779 - acc: 0.5645 - f1: 0.4626 - val_loss: 0.6944 - val_acc: 0.5037 - val_f1: 0.4233\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6822 - acc: 0.5459 - f1: 0.4459 - val_loss: 0.6985 - val_acc: 0.4407 - val_f1: 0.3931\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6813 - acc: 0.5645 - f1: 0.4491 - val_loss: 0.6936 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6772 - acc: 0.5583 - f1: 0.4025 - val_loss: 0.6966 - val_acc: 0.5222 - val_f1: 0.3943\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6766 - acc: 0.5558 - f1: 0.4301 - val_loss: 0.6944 - val_acc: 0.5185 - val_f1: 0.3957\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6745 - acc: 0.5645 - f1: 0.4758 - val_loss: 0.7034 - val_acc: 0.4407 - val_f1: 0.3932\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6736 - acc: 0.5756 - f1: 0.5045 - val_loss: 0.6992 - val_acc: 0.4741 - val_f1: 0.4176\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6731 - acc: 0.5735 - f1: 0.4900 - val_loss: 0.7023 - val_acc: 0.4593 - val_f1: 0.3934\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.5703 - f1: 0.4909 - val_loss: 0.6979 - val_acc: 0.4815 - val_f1: 0.4042\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6701 - acc: 0.5880 - f1: 0.5362 - val_loss: 0.7071 - val_acc: 0.4667 - val_f1: 0.4046\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6705 - acc: 0.5838 - f1: 0.5272 - val_loss: 0.6986 - val_acc: 0.4815 - val_f1: 0.4397\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6715 - acc: 0.5752 - f1: 0.5076 - val_loss: 0.7060 - val_acc: 0.4519 - val_f1: 0.4097\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.6044 - f1: 0.5682 - val_loss: 0.7051 - val_acc: 0.4889 - val_f1: 0.4364\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6690 - acc: 0.5921 - f1: 0.5559 - val_loss: 0.7107 - val_acc: 0.4444 - val_f1: 0.4023\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6680 - acc: 0.5863 - f1: 0.5244 - val_loss: 0.7110 - val_acc: 0.4222 - val_f1: 0.3835\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6640 - acc: 0.5954 - f1: 0.5666 - val_loss: 0.7158 - val_acc: 0.4481 - val_f1: 0.4079\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6639 - acc: 0.5941 - f1: 0.5449 - val_loss: 0.7123 - val_acc: 0.4370 - val_f1: 0.3996\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6616 - acc: 0.5979 - f1: 0.5537 - val_loss: 0.7133 - val_acc: 0.4333 - val_f1: 0.3964\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6609 - acc: 0.6020 - f1: 0.5735 - val_loss: 0.7157 - val_acc: 0.4407 - val_f1: 0.3941\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6641 - acc: 0.5991 - f1: 0.5668 - val_loss: 0.7148 - val_acc: 0.4556 - val_f1: 0.4122\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6602 - acc: 0.6073 - f1: 0.5698 - val_loss: 0.7064 - val_acc: 0.4630 - val_f1: 0.4087\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6579 - acc: 0.6073 - f1: 0.5739 - val_loss: 0.7275 - val_acc: 0.4407 - val_f1: 0.4026\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6573 - acc: 0.6135 - f1: 0.5846 - val_loss: 0.7101 - val_acc: 0.4667 - val_f1: 0.4107\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6502 - acc: 0.6172 - f1: 0.5949 - val_loss: 0.7171 - val_acc: 0.4741 - val_f1: 0.4262\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6540 - acc: 0.6201 - f1: 0.5932 - val_loss: 0.7214 - val_acc: 0.4407 - val_f1: 0.4025\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6543 - acc: 0.6115 - f1: 0.5816 - val_loss: 0.7147 - val_acc: 0.4444 - val_f1: 0.3966\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6517 - acc: 0.6082 - f1: 0.5796 - val_loss: 0.7251 - val_acc: 0.4926 - val_f1: 0.4384\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6442 - acc: 0.6263 - f1: 0.6031 - val_loss: 0.7302 - val_acc: 0.4333 - val_f1: 0.3881\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6474 - acc: 0.6226 - f1: 0.5975 - val_loss: 0.7278 - val_acc: 0.4741 - val_f1: 0.4262\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6447 - acc: 0.6246 - f1: 0.6066 - val_loss: 0.7113 - val_acc: 0.4593 - val_f1: 0.4069\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6418 - acc: 0.6271 - f1: 0.6037 - val_loss: 0.7409 - val_acc: 0.4333 - val_f1: 0.3970\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6510 - acc: 0.6164 - f1: 0.5962 - val_loss: 0.7272 - val_acc: 0.4593 - val_f1: 0.4138\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6449 - acc: 0.6292 - f1: 0.6102 - val_loss: 0.7433 - val_acc: 0.4741 - val_f1: 0.4261\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6399 - acc: 0.6341 - f1: 0.6082 - val_loss: 0.7404 - val_acc: 0.4444 - val_f1: 0.4024\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6373 - acc: 0.6337 - f1: 0.6171 - val_loss: 0.7452 - val_acc: 0.4370 - val_f1: 0.3907\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6365 - acc: 0.6415 - f1: 0.6220 - val_loss: 0.7366 - val_acc: 0.4667 - val_f1: 0.4205\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6343 - acc: 0.6341 - f1: 0.6117 - val_loss: 0.7582 - val_acc: 0.4370 - val_f1: 0.4306\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6368 - acc: 0.6457 - f1: 0.6260 - val_loss: 0.7353 - val_acc: 0.4741 - val_f1: 0.4261\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6333 - acc: 0.6444 - f1: 0.6300 - val_loss: 0.7441 - val_acc: 0.4556 - val_f1: 0.4126\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6358 - acc: 0.6349 - f1: 0.6090 - val_loss: 0.7409 - val_acc: 0.4741 - val_f1: 0.4166\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6296 - acc: 0.6407 - f1: 0.6268 - val_loss: 0.7669 - val_acc: 0.4593 - val_f1: 0.4156\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6313 - acc: 0.6415 - f1: 0.6241 - val_loss: 0.7688 - val_acc: 0.4333 - val_f1: 0.3974\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6270 - acc: 0.6411 - f1: 0.6202 - val_loss: 0.7674 - val_acc: 0.4667 - val_f1: 0.4373\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6278 - acc: 0.6597 - f1: 0.6484 - val_loss: 0.7497 - val_acc: 0.4667 - val_f1: 0.4122\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6287 - acc: 0.6485 - f1: 0.6245 - val_loss: 0.7759 - val_acc: 0.4778 - val_f1: 0.4593\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6245 - acc: 0.6514 - f1: 0.6363 - val_loss: 0.7621 - val_acc: 0.4926 - val_f1: 0.4562\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6233 - acc: 0.6576 - f1: 0.6424 - val_loss: 0.7767 - val_acc: 0.4741 - val_f1: 0.4174\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6237 - acc: 0.6625 - f1: 0.6518 - val_loss: 0.7874 - val_acc: 0.4815 - val_f1: 0.4227\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6185 - acc: 0.6613 - f1: 0.6441 - val_loss: 0.7747 - val_acc: 0.4926 - val_f1: 0.4695\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6141 - acc: 0.6642 - f1: 0.6485 - val_loss: 0.8024 - val_acc: 0.4667 - val_f1: 0.4370\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6133 - acc: 0.6588 - f1: 0.6429 - val_loss: 0.7872 - val_acc: 0.4481 - val_f1: 0.4245\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6156 - acc: 0.6642 - f1: 0.6534 - val_loss: 0.7844 - val_acc: 0.4593 - val_f1: 0.4069\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6096 - acc: 0.6679 - f1: 0.6493 - val_loss: 0.8114 - val_acc: 0.4593 - val_f1: 0.4613\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6153 - acc: 0.6584 - f1: 0.6500 - val_loss: 0.8092 - val_acc: 0.4741 - val_f1: 0.4569\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6083 - acc: 0.6716 - f1: 0.6556 - val_loss: 0.7821 - val_acc: 0.4593 - val_f1: 0.4627\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.6125 - acc: 0.6683 - f1: 0.6560 - val_loss: 0.8055 - val_acc: 0.4815 - val_f1: 0.4619\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6066 - acc: 0.6687 - f1: 0.6539 - val_loss: 0.8012 - val_acc: 0.4704 - val_f1: 0.4697\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6070 - acc: 0.6675 - f1: 0.6550 - val_loss: 0.8096 - val_acc: 0.4815 - val_f1: 0.4786\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6053 - acc: 0.6687 - f1: 0.6576 - val_loss: 0.8173 - val_acc: 0.4741 - val_f1: 0.4430\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5994 - acc: 0.6831 - f1: 0.6668 - val_loss: 0.8099 - val_acc: 0.4741 - val_f1: 0.4572\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6043 - acc: 0.6778 - f1: 0.6695 - val_loss: 0.8251 - val_acc: 0.5000 - val_f1: 0.4612\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6036 - acc: 0.6704 - f1: 0.6509 - val_loss: 0.8339 - val_acc: 0.4741 - val_f1: 0.4562\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5909 - acc: 0.6848 - f1: 0.6746 - val_loss: 0.8136 - val_acc: 0.4815 - val_f1: 0.4488\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5932 - acc: 0.6844 - f1: 0.6719 - val_loss: 0.8526 - val_acc: 0.4815 - val_f1: 0.4781\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5923 - acc: 0.6778 - f1: 0.6656 - val_loss: 0.8207 - val_acc: 0.4630 - val_f1: 0.4898\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5964 - acc: 0.6691 - f1: 0.6557 - val_loss: 0.8285 - val_acc: 0.4852 - val_f1: 0.4811\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5938 - acc: 0.6910 - f1: 0.6789 - val_loss: 0.8627 - val_acc: 0.4852 - val_f1: 0.4503\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5912 - acc: 0.6815 - f1: 0.6702 - val_loss: 0.8446 - val_acc: 0.4704 - val_f1: 0.4405\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5840 - acc: 0.6885 - f1: 0.6736 - val_loss: 0.8226 - val_acc: 0.4815 - val_f1: 0.4777\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5870 - acc: 0.6959 - f1: 0.6858 - val_loss: 0.8446 - val_acc: 0.4778 - val_f1: 0.4600\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5842 - acc: 0.6943 - f1: 0.6823 - val_loss: 0.8199 - val_acc: 0.4556 - val_f1: 0.4304\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5820 - acc: 0.6967 - f1: 0.6837 - val_loss: 0.8404 - val_acc: 0.4667 - val_f1: 0.4376\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5783 - acc: 0.7042 - f1: 0.6960 - val_loss: 0.8524 - val_acc: 0.4704 - val_f1: 0.4405\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5826 - acc: 0.6897 - f1: 0.6761 - val_loss: 0.8368 - val_acc: 0.4407 - val_f1: 0.4193\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5774 - acc: 0.6996 - f1: 0.6914 - val_loss: 0.8352 - val_acc: 0.4667 - val_f1: 0.4382\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5822 - acc: 0.6980 - f1: 0.6863 - val_loss: 0.8252 - val_acc: 0.4444 - val_f1: 0.4509\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5836 - acc: 0.7021 - f1: 0.6920 - val_loss: 0.8675 - val_acc: 0.5037 - val_f1: 0.4380\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5738 - acc: 0.6976 - f1: 0.6877 - val_loss: 0.8285 - val_acc: 0.4778 - val_f1: 0.5012\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5633 - acc: 0.7153 - f1: 0.7035 - val_loss: 0.8791 - val_acc: 0.4667 - val_f1: 0.4376\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5700 - acc: 0.7062 - f1: 0.6972 - val_loss: 0.8369 - val_acc: 0.4556 - val_f1: 0.4592\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5767 - acc: 0.7128 - f1: 0.7051 - val_loss: 0.8649 - val_acc: 0.4444 - val_f1: 0.3865\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5617 - acc: 0.7066 - f1: 0.6959 - val_loss: 0.8751 - val_acc: 0.4296 - val_f1: 0.3746\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6889 - acc: 0.5529 - f1: 0.3780 - val_loss: 0.6933 - val_acc: 0.5259 - val_f1: 0.3732\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6880 - acc: 0.5517 - f1: 0.3955 - val_loss: 0.6965 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6886 - acc: 0.5558 - f1: 0.3650 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6870 - acc: 0.5542 - f1: 0.3622 - val_loss: 0.6928 - val_acc: 0.5370 - val_f1: 0.3801\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6878 - acc: 0.5480 - f1: 0.3610 - val_loss: 0.6948 - val_acc: 0.4185 - val_f1: 0.4147\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6862 - acc: 0.5484 - f1: 0.3895 - val_loss: 0.6944 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6859 - acc: 0.5554 - f1: 0.3693 - val_loss: 0.6950 - val_acc: 0.4148 - val_f1: 0.4997\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6852 - acc: 0.5521 - f1: 0.3700 - val_loss: 0.6957 - val_acc: 0.4481 - val_f1: 0.4974\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6854 - acc: 0.5517 - f1: 0.4022 - val_loss: 0.6968 - val_acc: 0.4259 - val_f1: 0.4668\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6842 - acc: 0.5525 - f1: 0.3974 - val_loss: 0.6955 - val_acc: 0.4481 - val_f1: 0.3879\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6844 - acc: 0.5480 - f1: 0.3913 - val_loss: 0.6962 - val_acc: 0.4222 - val_f1: 0.3803\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6833 - acc: 0.5538 - f1: 0.3905 - val_loss: 0.6969 - val_acc: 0.4111 - val_f1: 0.4274\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6824 - acc: 0.5517 - f1: 0.4399 - val_loss: 0.6983 - val_acc: 0.4148 - val_f1: 0.4282\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6844 - acc: 0.5616 - f1: 0.4100 - val_loss: 0.6963 - val_acc: 0.4370 - val_f1: 0.3856\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6827 - acc: 0.5632 - f1: 0.4113 - val_loss: 0.6994 - val_acc: 0.5407 - val_f1: 0.4195\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6810 - acc: 0.5612 - f1: 0.4435 - val_loss: 0.6980 - val_acc: 0.5185 - val_f1: 0.3891\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6805 - acc: 0.5645 - f1: 0.4357 - val_loss: 0.6992 - val_acc: 0.4407 - val_f1: 0.4331\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6773 - acc: 0.5661 - f1: 0.4716 - val_loss: 0.7017 - val_acc: 0.5074 - val_f1: 0.3931\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6813 - acc: 0.5682 - f1: 0.4681 - val_loss: 0.7003 - val_acc: 0.4630 - val_f1: 0.4159\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6777 - acc: 0.5703 - f1: 0.4681 - val_loss: 0.7015 - val_acc: 0.4519 - val_f1: 0.4101\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6773 - acc: 0.5653 - f1: 0.4704 - val_loss: 0.7018 - val_acc: 0.4519 - val_f1: 0.4088\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6764 - acc: 0.5657 - f1: 0.5120 - val_loss: 0.7077 - val_acc: 0.4481 - val_f1: 0.4727\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6761 - acc: 0.5558 - f1: 0.4550 - val_loss: 0.7056 - val_acc: 0.4778 - val_f1: 0.4239\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6728 - acc: 0.5838 - f1: 0.5165 - val_loss: 0.7030 - val_acc: 0.4444 - val_f1: 0.4493\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6732 - acc: 0.5785 - f1: 0.5233 - val_loss: 0.7085 - val_acc: 0.4593 - val_f1: 0.4145\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6727 - acc: 0.5818 - f1: 0.5189 - val_loss: 0.7140 - val_acc: 0.4630 - val_f1: 0.4103\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6734 - acc: 0.5698 - f1: 0.5141 - val_loss: 0.7118 - val_acc: 0.4593 - val_f1: 0.4128\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.5773 - f1: 0.5033 - val_loss: 0.7067 - val_acc: 0.4741 - val_f1: 0.4215\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6694 - acc: 0.5946 - f1: 0.5463 - val_loss: 0.7090 - val_acc: 0.4481 - val_f1: 0.4523\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6700 - acc: 0.5748 - f1: 0.5103 - val_loss: 0.7158 - val_acc: 0.4481 - val_f1: 0.4079\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6683 - acc: 0.5880 - f1: 0.5468 - val_loss: 0.7163 - val_acc: 0.4370 - val_f1: 0.4953\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6672 - acc: 0.5867 - f1: 0.5414 - val_loss: 0.7141 - val_acc: 0.4519 - val_f1: 0.4085\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6643 - acc: 0.5904 - f1: 0.5566 - val_loss: 0.7186 - val_acc: 0.4593 - val_f1: 0.5322\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6629 - acc: 0.5917 - f1: 0.5516 - val_loss: 0.7227 - val_acc: 0.4370 - val_f1: 0.3999\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6638 - acc: 0.5979 - f1: 0.5589 - val_loss: 0.7188 - val_acc: 0.4630 - val_f1: 0.4932\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6606 - acc: 0.6123 - f1: 0.5782 - val_loss: 0.7204 - val_acc: 0.4519 - val_f1: 0.5272\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6574 - acc: 0.6139 - f1: 0.5809 - val_loss: 0.7214 - val_acc: 0.4630 - val_f1: 0.5333\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6610 - acc: 0.5991 - f1: 0.5663 - val_loss: 0.7155 - val_acc: 0.5000 - val_f1: 0.5686\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6567 - acc: 0.6152 - f1: 0.5832 - val_loss: 0.7213 - val_acc: 0.4852 - val_f1: 0.5670\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6568 - acc: 0.6152 - f1: 0.5864 - val_loss: 0.7242 - val_acc: 0.4741 - val_f1: 0.4813\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6520 - acc: 0.6283 - f1: 0.6055 - val_loss: 0.7227 - val_acc: 0.4815 - val_f1: 0.5436\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6521 - acc: 0.6234 - f1: 0.5901 - val_loss: 0.7339 - val_acc: 0.4778 - val_f1: 0.5651\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6502 - acc: 0.6296 - f1: 0.6111 - val_loss: 0.7281 - val_acc: 0.4852 - val_f1: 0.4940\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6538 - acc: 0.6201 - f1: 0.5998 - val_loss: 0.7304 - val_acc: 0.4741 - val_f1: 0.5276\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6488 - acc: 0.6218 - f1: 0.5914 - val_loss: 0.7211 - val_acc: 0.4852 - val_f1: 0.5020\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6484 - acc: 0.6275 - f1: 0.6064 - val_loss: 0.7159 - val_acc: 0.4926 - val_f1: 0.5282\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6432 - acc: 0.6341 - f1: 0.6056 - val_loss: 0.7315 - val_acc: 0.4704 - val_f1: 0.5187\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6437 - acc: 0.6358 - f1: 0.6141 - val_loss: 0.7199 - val_acc: 0.4704 - val_f1: 0.5194\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6449 - acc: 0.6374 - f1: 0.6197 - val_loss: 0.7242 - val_acc: 0.4852 - val_f1: 0.5293\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6444 - acc: 0.6374 - f1: 0.6183 - val_loss: 0.7164 - val_acc: 0.5037 - val_f1: 0.5670\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6371 - acc: 0.6419 - f1: 0.6197 - val_loss: 0.7356 - val_acc: 0.4852 - val_f1: 0.5229\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6391 - acc: 0.6374 - f1: 0.6195 - val_loss: 0.7273 - val_acc: 0.5037 - val_f1: 0.5315\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6397 - acc: 0.6374 - f1: 0.6172 - val_loss: 0.7266 - val_acc: 0.4704 - val_f1: 0.4786\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6375 - acc: 0.6358 - f1: 0.6147 - val_loss: 0.7268 - val_acc: 0.5000 - val_f1: 0.5251\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6317 - acc: 0.6477 - f1: 0.6276 - val_loss: 0.7388 - val_acc: 0.4704 - val_f1: 0.5203\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6330 - acc: 0.6349 - f1: 0.6115 - val_loss: 0.7327 - val_acc: 0.4815 - val_f1: 0.5175\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6265 - acc: 0.6444 - f1: 0.6270 - val_loss: 0.7281 - val_acc: 0.5000 - val_f1: 0.5373\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6227 - acc: 0.6588 - f1: 0.6408 - val_loss: 0.7401 - val_acc: 0.4889 - val_f1: 0.5416\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6263 - acc: 0.6510 - f1: 0.6398 - val_loss: 0.7295 - val_acc: 0.4963 - val_f1: 0.5473\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6202 - acc: 0.6601 - f1: 0.6451 - val_loss: 0.7376 - val_acc: 0.5000 - val_f1: 0.5491\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6183 - acc: 0.6642 - f1: 0.6487 - val_loss: 0.7396 - val_acc: 0.4852 - val_f1: 0.5442\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6138 - acc: 0.6696 - f1: 0.6542 - val_loss: 0.7488 - val_acc: 0.4593 - val_f1: 0.5089\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6150 - acc: 0.6737 - f1: 0.6628 - val_loss: 0.7607 - val_acc: 0.4667 - val_f1: 0.5095\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6159 - acc: 0.6584 - f1: 0.6419 - val_loss: 0.7598 - val_acc: 0.4630 - val_f1: 0.5115\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6183 - acc: 0.6584 - f1: 0.6443 - val_loss: 0.7492 - val_acc: 0.4852 - val_f1: 0.5273\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6110 - acc: 0.6749 - f1: 0.6670 - val_loss: 0.7398 - val_acc: 0.4778 - val_f1: 0.5203\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6065 - acc: 0.6815 - f1: 0.6689 - val_loss: 0.7395 - val_acc: 0.4963 - val_f1: 0.5491\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6089 - acc: 0.6720 - f1: 0.6582 - val_loss: 0.7616 - val_acc: 0.4630 - val_f1: 0.5077\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6084 - acc: 0.6786 - f1: 0.6660 - val_loss: 0.7541 - val_acc: 0.4963 - val_f1: 0.5346\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6031 - acc: 0.6766 - f1: 0.6650 - val_loss: 0.7670 - val_acc: 0.4852 - val_f1: 0.5360\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6078 - acc: 0.6803 - f1: 0.6688 - val_loss: 0.7592 - val_acc: 0.4704 - val_f1: 0.5285\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5965 - acc: 0.6914 - f1: 0.6777 - val_loss: 0.7376 - val_acc: 0.5000 - val_f1: 0.5375\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5920 - acc: 0.6827 - f1: 0.6712 - val_loss: 0.7652 - val_acc: 0.4741 - val_f1: 0.5393\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5939 - acc: 0.6799 - f1: 0.6702 - val_loss: 0.7938 - val_acc: 0.4778 - val_f1: 0.5358\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5940 - acc: 0.6770 - f1: 0.6606 - val_loss: 0.7489 - val_acc: 0.4778 - val_f1: 0.5372\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5920 - acc: 0.6897 - f1: 0.6812 - val_loss: 0.7627 - val_acc: 0.4778 - val_f1: 0.5418\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5888 - acc: 0.6881 - f1: 0.6729 - val_loss: 0.7703 - val_acc: 0.4667 - val_f1: 0.4962\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5816 - acc: 0.6930 - f1: 0.6847 - val_loss: 0.7417 - val_acc: 0.4889 - val_f1: 0.5472\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5786 - acc: 0.6947 - f1: 0.6831 - val_loss: 0.7660 - val_acc: 0.4963 - val_f1: 0.5361\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5786 - acc: 0.6959 - f1: 0.6839 - val_loss: 0.7558 - val_acc: 0.4852 - val_f1: 0.5477\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5785 - acc: 0.6939 - f1: 0.6855 - val_loss: 0.7544 - val_acc: 0.4704 - val_f1: 0.4815\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5845 - acc: 0.7005 - f1: 0.6876 - val_loss: 0.7546 - val_acc: 0.5000 - val_f1: 0.5375\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5725 - acc: 0.7017 - f1: 0.6945 - val_loss: 0.7654 - val_acc: 0.4593 - val_f1: 0.4726\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5718 - acc: 0.7033 - f1: 0.6928 - val_loss: 0.7667 - val_acc: 0.4593 - val_f1: 0.4914\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5770 - acc: 0.6939 - f1: 0.6805 - val_loss: 0.7664 - val_acc: 0.4889 - val_f1: 0.5309\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5698 - acc: 0.6980 - f1: 0.6876 - val_loss: 0.7466 - val_acc: 0.4852 - val_f1: 0.5298\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5584 - acc: 0.7165 - f1: 0.7105 - val_loss: 0.7883 - val_acc: 0.4852 - val_f1: 0.5420\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5687 - acc: 0.7083 - f1: 0.6966 - val_loss: 0.7535 - val_acc: 0.4630 - val_f1: 0.5137\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5619 - acc: 0.7070 - f1: 0.6974 - val_loss: 0.7693 - val_acc: 0.5000 - val_f1: 0.5307\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5566 - acc: 0.7223 - f1: 0.7152 - val_loss: 0.7853 - val_acc: 0.4815 - val_f1: 0.5157\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5545 - acc: 0.7235 - f1: 0.7151 - val_loss: 0.7782 - val_acc: 0.4926 - val_f1: 0.5146\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5518 - acc: 0.7165 - f1: 0.7087 - val_loss: 0.7699 - val_acc: 0.4815 - val_f1: 0.5206\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5488 - acc: 0.7149 - f1: 0.7035 - val_loss: 0.7566 - val_acc: 0.4667 - val_f1: 0.5152\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5521 - acc: 0.7186 - f1: 0.7111 - val_loss: 0.7897 - val_acc: 0.4815 - val_f1: 0.4825\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5443 - acc: 0.7272 - f1: 0.7191 - val_loss: 0.7846 - val_acc: 0.4889 - val_f1: 0.4914\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5442 - acc: 0.7239 - f1: 0.7171 - val_loss: 0.7647 - val_acc: 0.5037 - val_f1: 0.4826\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5440 - acc: 0.7289 - f1: 0.7188 - val_loss: 0.7878 - val_acc: 0.5000 - val_f1: 0.5363\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5409 - acc: 0.7239 - f1: 0.7169 - val_loss: 0.7697 - val_acc: 0.5074 - val_f1: 0.5158\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5341 - acc: 0.7322 - f1: 0.7252 - val_loss: 0.7698 - val_acc: 0.4815 - val_f1: 0.4999\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5395 - acc: 0.7322 - f1: 0.7254 - val_loss: 0.7834 - val_acc: 0.5000 - val_f1: 0.4837\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5341 - acc: 0.7425 - f1: 0.7342 - val_loss: 0.8128 - val_acc: 0.4926 - val_f1: 0.4826\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5388 - acc: 0.7194 - f1: 0.7102 - val_loss: 0.7865 - val_acc: 0.5037 - val_f1: 0.5019\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5245 - acc: 0.7429 - f1: 0.7367 - val_loss: 0.7709 - val_acc: 0.4963 - val_f1: 0.5290\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6897 - acc: 0.5538 - f1: 0.3609 - val_loss: 0.6922 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6879 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6879 - acc: 0.5529 - f1: 0.3565 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6888 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6923 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6865 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.6977 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6887 - acc: 0.5538 - f1: 0.3592 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6886 - acc: 0.5538 - f1: 0.3578 - val_loss: 0.6938 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6878 - acc: 0.5534 - f1: 0.3578 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6861 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6933 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5538 - f1: 0.3567 - val_loss: 0.6939 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6857 - acc: 0.5571 - f1: 0.3772 - val_loss: 0.6997 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6836 - acc: 0.5538 - f1: 0.3570 - val_loss: 0.6939 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6814 - acc: 0.5583 - f1: 0.3912 - val_loss: 0.6959 - val_acc: 0.5259 - val_f1: 0.3942\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6790 - acc: 0.5591 - f1: 0.4115 - val_loss: 0.6976 - val_acc: 0.5370 - val_f1: 0.3743\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6821 - acc: 0.5529 - f1: 0.4069 - val_loss: 0.6967 - val_acc: 0.4370 - val_f1: 0.4011\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6831 - acc: 0.5604 - f1: 0.4692 - val_loss: 0.6964 - val_acc: 0.5222 - val_f1: 0.4072\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6796 - acc: 0.5645 - f1: 0.4240 - val_loss: 0.6956 - val_acc: 0.5333 - val_f1: 0.3987\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6791 - acc: 0.5591 - f1: 0.4921 - val_loss: 0.6972 - val_acc: 0.5259 - val_f1: 0.3990\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6814 - acc: 0.5649 - f1: 0.4397 - val_loss: 0.7006 - val_acc: 0.4852 - val_f1: 0.4004\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6799 - acc: 0.5595 - f1: 0.4478 - val_loss: 0.7013 - val_acc: 0.4593 - val_f1: 0.3969\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6776 - acc: 0.5595 - f1: 0.4674 - val_loss: 0.7020 - val_acc: 0.4778 - val_f1: 0.3928\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6772 - acc: 0.5628 - f1: 0.4912 - val_loss: 0.6964 - val_acc: 0.4704 - val_f1: 0.4071\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6742 - acc: 0.5814 - f1: 0.5006 - val_loss: 0.7028 - val_acc: 0.4667 - val_f1: 0.3892\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6755 - acc: 0.5744 - f1: 0.5121 - val_loss: 0.7099 - val_acc: 0.4259 - val_f1: 0.3870\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6746 - acc: 0.5847 - f1: 0.5447 - val_loss: 0.7096 - val_acc: 0.4111 - val_f1: 0.3795\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6729 - acc: 0.5740 - f1: 0.5053 - val_loss: 0.7052 - val_acc: 0.4296 - val_f1: 0.4663\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.5855 - f1: 0.5232 - val_loss: 0.7107 - val_acc: 0.4296 - val_f1: 0.4846\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6724 - acc: 0.5838 - f1: 0.5269 - val_loss: 0.7113 - val_acc: 0.4333 - val_f1: 0.4584\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6664 - acc: 0.6028 - f1: 0.5752 - val_loss: 0.7129 - val_acc: 0.4333 - val_f1: 0.4882\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.5847 - f1: 0.5263 - val_loss: 0.6983 - val_acc: 0.4444 - val_f1: 0.4739\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6694 - acc: 0.5900 - f1: 0.5436 - val_loss: 0.7152 - val_acc: 0.4333 - val_f1: 0.4938\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6643 - acc: 0.5954 - f1: 0.5580 - val_loss: 0.7142 - val_acc: 0.4222 - val_f1: 0.4868\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6657 - acc: 0.5921 - f1: 0.5589 - val_loss: 0.7067 - val_acc: 0.4630 - val_f1: 0.4784\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6631 - acc: 0.5871 - f1: 0.5501 - val_loss: 0.7175 - val_acc: 0.4222 - val_f1: 0.4336\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6641 - acc: 0.5962 - f1: 0.5598 - val_loss: 0.7228 - val_acc: 0.4185 - val_f1: 0.4602\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6636 - acc: 0.6016 - f1: 0.5690 - val_loss: 0.7187 - val_acc: 0.4148 - val_f1: 0.4574\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6613 - acc: 0.5974 - f1: 0.5539 - val_loss: 0.7146 - val_acc: 0.4259 - val_f1: 0.4630\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6586 - acc: 0.6036 - f1: 0.5787 - val_loss: 0.7176 - val_acc: 0.4259 - val_f1: 0.4824\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6577 - acc: 0.5991 - f1: 0.5610 - val_loss: 0.7216 - val_acc: 0.3963 - val_f1: 0.4689\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6540 - acc: 0.6139 - f1: 0.5900 - val_loss: 0.7218 - val_acc: 0.4259 - val_f1: 0.4654\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6511 - acc: 0.6226 - f1: 0.5990 - val_loss: 0.7207 - val_acc: 0.4185 - val_f1: 0.4638\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6524 - acc: 0.6185 - f1: 0.5966 - val_loss: 0.7139 - val_acc: 0.4370 - val_f1: 0.4964\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6521 - acc: 0.6148 - f1: 0.5880 - val_loss: 0.7249 - val_acc: 0.4630 - val_f1: 0.5135\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6495 - acc: 0.6139 - f1: 0.5915 - val_loss: 0.7151 - val_acc: 0.4667 - val_f1: 0.5106\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6521 - acc: 0.6110 - f1: 0.5838 - val_loss: 0.7189 - val_acc: 0.4222 - val_f1: 0.4623\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6460 - acc: 0.6271 - f1: 0.6009 - val_loss: 0.7111 - val_acc: 0.4593 - val_f1: 0.4699\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6464 - acc: 0.6160 - f1: 0.5963 - val_loss: 0.7148 - val_acc: 0.4667 - val_f1: 0.4857\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6461 - acc: 0.6168 - f1: 0.5968 - val_loss: 0.7150 - val_acc: 0.4556 - val_f1: 0.4483\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6428 - acc: 0.6333 - f1: 0.6090 - val_loss: 0.7276 - val_acc: 0.4333 - val_f1: 0.4513\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6398 - acc: 0.6238 - f1: 0.6042 - val_loss: 0.7255 - val_acc: 0.4481 - val_f1: 0.4625\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6353 - acc: 0.6366 - f1: 0.6168 - val_loss: 0.7234 - val_acc: 0.4333 - val_f1: 0.4520\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6315 - acc: 0.6448 - f1: 0.6315 - val_loss: 0.7320 - val_acc: 0.4481 - val_f1: 0.4612\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6404 - acc: 0.6395 - f1: 0.6223 - val_loss: 0.7361 - val_acc: 0.4370 - val_f1: 0.4548\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6312 - acc: 0.6506 - f1: 0.6352 - val_loss: 0.7303 - val_acc: 0.4407 - val_f1: 0.4574\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6305 - acc: 0.6419 - f1: 0.6209 - val_loss: 0.7368 - val_acc: 0.4481 - val_f1: 0.4801\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6307 - acc: 0.6494 - f1: 0.6339 - val_loss: 0.7373 - val_acc: 0.4741 - val_f1: 0.5203\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6322 - acc: 0.6489 - f1: 0.6333 - val_loss: 0.7354 - val_acc: 0.4407 - val_f1: 0.4717\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6300 - acc: 0.6444 - f1: 0.6277 - val_loss: 0.7362 - val_acc: 0.4481 - val_f1: 0.4625\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6246 - acc: 0.6527 - f1: 0.6370 - val_loss: 0.7328 - val_acc: 0.4667 - val_f1: 0.4930\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6214 - acc: 0.6584 - f1: 0.6433 - val_loss: 0.7303 - val_acc: 0.4630 - val_f1: 0.4948\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6254 - acc: 0.6555 - f1: 0.6411 - val_loss: 0.7620 - val_acc: 0.4148 - val_f1: 0.4392\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6189 - acc: 0.6461 - f1: 0.6321 - val_loss: 0.7504 - val_acc: 0.4296 - val_f1: 0.4495\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6174 - acc: 0.6560 - f1: 0.6443 - val_loss: 0.7508 - val_acc: 0.4667 - val_f1: 0.4930\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6149 - acc: 0.6572 - f1: 0.6395 - val_loss: 0.7406 - val_acc: 0.4556 - val_f1: 0.4667\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6113 - acc: 0.6687 - f1: 0.6560 - val_loss: 0.7532 - val_acc: 0.4481 - val_f1: 0.4782\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6075 - acc: 0.6658 - f1: 0.6500 - val_loss: 0.7625 - val_acc: 0.4370 - val_f1: 0.4549\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6140 - acc: 0.6749 - f1: 0.6657 - val_loss: 0.7492 - val_acc: 0.4519 - val_f1: 0.4785\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6057 - acc: 0.6757 - f1: 0.6623 - val_loss: 0.7721 - val_acc: 0.4370 - val_f1: 0.4752\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6040 - acc: 0.6700 - f1: 0.6589 - val_loss: 0.7478 - val_acc: 0.4444 - val_f1: 0.4579\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6024 - acc: 0.6831 - f1: 0.6711 - val_loss: 0.7688 - val_acc: 0.4556 - val_f1: 0.4895\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6057 - acc: 0.6840 - f1: 0.6745 - val_loss: 0.7738 - val_acc: 0.4185 - val_f1: 0.4284\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6014 - acc: 0.6786 - f1: 0.6639 - val_loss: 0.7569 - val_acc: 0.4667 - val_f1: 0.4748\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5946 - acc: 0.6922 - f1: 0.6811 - val_loss: 0.7526 - val_acc: 0.4481 - val_f1: 0.4762\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5974 - acc: 0.6774 - f1: 0.6661 - val_loss: 0.7594 - val_acc: 0.4407 - val_f1: 0.4553\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5908 - acc: 0.6848 - f1: 0.6735 - val_loss: 0.7681 - val_acc: 0.4519 - val_f1: 0.4604\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5876 - acc: 0.6926 - f1: 0.6834 - val_loss: 0.7726 - val_acc: 0.4593 - val_f1: 0.4692\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5962 - acc: 0.6844 - f1: 0.6726 - val_loss: 0.7594 - val_acc: 0.4185 - val_f1: 0.4396\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5965 - acc: 0.6766 - f1: 0.6655 - val_loss: 0.7743 - val_acc: 0.4296 - val_f1: 0.4492\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5867 - acc: 0.6881 - f1: 0.6801 - val_loss: 0.7868 - val_acc: 0.4259 - val_f1: 0.4436\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5807 - acc: 0.6926 - f1: 0.6822 - val_loss: 0.7777 - val_acc: 0.4111 - val_f1: 0.4347\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5827 - acc: 0.6963 - f1: 0.6865 - val_loss: 0.7891 - val_acc: 0.3926 - val_f1: 0.3968\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5780 - acc: 0.6959 - f1: 0.6841 - val_loss: 0.7979 - val_acc: 0.4519 - val_f1: 0.4861\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5792 - acc: 0.6918 - f1: 0.6792 - val_loss: 0.7646 - val_acc: 0.4741 - val_f1: 0.4595\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5794 - acc: 0.6910 - f1: 0.6825 - val_loss: 0.7904 - val_acc: 0.4370 - val_f1: 0.4746\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5673 - acc: 0.7042 - f1: 0.6913 - val_loss: 0.7753 - val_acc: 0.4370 - val_f1: 0.4532\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5689 - acc: 0.7087 - f1: 0.6996 - val_loss: 0.7744 - val_acc: 0.4481 - val_f1: 0.4560\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5668 - acc: 0.7029 - f1: 0.6934 - val_loss: 0.7980 - val_acc: 0.4630 - val_f1: 0.4942\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5587 - acc: 0.7132 - f1: 0.7048 - val_loss: 0.7835 - val_acc: 0.4407 - val_f1: 0.4546\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5570 - acc: 0.7141 - f1: 0.7057 - val_loss: 0.8030 - val_acc: 0.4407 - val_f1: 0.4999\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5547 - acc: 0.7124 - f1: 0.7043 - val_loss: 0.8174 - val_acc: 0.4185 - val_f1: 0.4626\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5540 - acc: 0.7157 - f1: 0.7071 - val_loss: 0.8038 - val_acc: 0.4259 - val_f1: 0.4686\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5498 - acc: 0.7149 - f1: 0.7069 - val_loss: 0.8041 - val_acc: 0.4519 - val_f1: 0.4874\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5494 - acc: 0.7165 - f1: 0.7076 - val_loss: 0.7978 - val_acc: 0.4296 - val_f1: 0.4717\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5465 - acc: 0.7264 - f1: 0.7199 - val_loss: 0.8134 - val_acc: 0.4407 - val_f1: 0.4499\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5471 - acc: 0.7153 - f1: 0.7060 - val_loss: 0.8085 - val_acc: 0.4296 - val_f1: 0.4158\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5470 - acc: 0.7256 - f1: 0.7180 - val_loss: 0.8095 - val_acc: 0.4333 - val_f1: 0.4229\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5432 - acc: 0.7165 - f1: 0.7099 - val_loss: 0.7963 - val_acc: 0.4481 - val_f1: 0.4557\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5373 - acc: 0.7392 - f1: 0.7306 - val_loss: 0.8190 - val_acc: 0.4370 - val_f1: 0.4211\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5397 - acc: 0.7347 - f1: 0.7270 - val_loss: 0.8349 - val_acc: 0.4370 - val_f1: 0.4168\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5326 - acc: 0.7309 - f1: 0.7246 - val_loss: 0.8366 - val_acc: 0.4370 - val_f1: 0.4521\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5382 - acc: 0.7248 - f1: 0.7178 - val_loss: 0.8513 - val_acc: 0.4519 - val_f1: 0.4855\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6913 - acc: 0.5443 - f1: 0.3883 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6873 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6931 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6865 - acc: 0.5521 - f1: 0.3645 - val_loss: 0.6980 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6885 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6931 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6922 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6877 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6871 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6925 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6868 - acc: 0.5542 - f1: 0.3577 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6869 - acc: 0.5538 - f1: 0.3582 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6859 - acc: 0.5534 - f1: 0.3581 - val_loss: 0.6933 - val_acc: 0.4926 - val_f1: 0.3589\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.5525 - f1: 0.3982 - val_loss: 0.6940 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6858 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6926 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6854 - acc: 0.5534 - f1: 0.3643 - val_loss: 0.6964 - val_acc: 0.4370 - val_f1: 0.3455\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6856 - acc: 0.5496 - f1: 0.3795 - val_loss: 0.6951 - val_acc: 0.4630 - val_f1: 0.4014\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6855 - acc: 0.5583 - f1: 0.4132 - val_loss: 0.6956 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6850 - acc: 0.5501 - f1: 0.3810 - val_loss: 0.6940 - val_acc: 0.5333 - val_f1: 0.3573\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6836 - acc: 0.5529 - f1: 0.3629 - val_loss: 0.6954 - val_acc: 0.4963 - val_f1: 0.3408\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6853 - acc: 0.5550 - f1: 0.4149 - val_loss: 0.6945 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5513 - f1: 0.3734 - val_loss: 0.6968 - val_acc: 0.4778 - val_f1: 0.3910\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6826 - acc: 0.5542 - f1: 0.3872 - val_loss: 0.6975 - val_acc: 0.4963 - val_f1: 0.3532\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5604 - f1: 0.4133 - val_loss: 0.6989 - val_acc: 0.4444 - val_f1: 0.4775\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6841 - acc: 0.5505 - f1: 0.4207 - val_loss: 0.6978 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6814 - acc: 0.5604 - f1: 0.4281 - val_loss: 0.6993 - val_acc: 0.5000 - val_f1: 0.3421\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6814 - acc: 0.5628 - f1: 0.4345 - val_loss: 0.6974 - val_acc: 0.4815 - val_f1: 0.4442\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6796 - acc: 0.5727 - f1: 0.4872 - val_loss: 0.6975 - val_acc: 0.5185 - val_f1: 0.3478\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6773 - acc: 0.5752 - f1: 0.4751 - val_loss: 0.7000 - val_acc: 0.4815 - val_f1: 0.4025\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6758 - acc: 0.5694 - f1: 0.4825 - val_loss: 0.7085 - val_acc: 0.4370 - val_f1: 0.3988\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6755 - acc: 0.5674 - f1: 0.5048 - val_loss: 0.6938 - val_acc: 0.5074 - val_f1: 0.4475\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6746 - acc: 0.5707 - f1: 0.5071 - val_loss: 0.7005 - val_acc: 0.4963 - val_f1: 0.4515\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6731 - acc: 0.5789 - f1: 0.5138 - val_loss: 0.6991 - val_acc: 0.5111 - val_f1: 0.4950\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6729 - acc: 0.5863 - f1: 0.5207 - val_loss: 0.6978 - val_acc: 0.4852 - val_f1: 0.4736\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6741 - acc: 0.5637 - f1: 0.5177 - val_loss: 0.7072 - val_acc: 0.4296 - val_f1: 0.4476\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6679 - acc: 0.5929 - f1: 0.5435 - val_loss: 0.7033 - val_acc: 0.5111 - val_f1: 0.5640\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6702 - acc: 0.5843 - f1: 0.5386 - val_loss: 0.6940 - val_acc: 0.5296 - val_f1: 0.4396\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.5851 - f1: 0.5428 - val_loss: 0.7097 - val_acc: 0.4926 - val_f1: 0.5229\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6663 - acc: 0.5913 - f1: 0.5290 - val_loss: 0.7085 - val_acc: 0.4926 - val_f1: 0.5013\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6631 - acc: 0.6036 - f1: 0.5657 - val_loss: 0.7082 - val_acc: 0.4852 - val_f1: 0.4802\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6655 - acc: 0.5925 - f1: 0.5529 - val_loss: 0.7066 - val_acc: 0.4889 - val_f1: 0.5246\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6622 - acc: 0.6086 - f1: 0.5812 - val_loss: 0.7027 - val_acc: 0.5074 - val_f1: 0.5451\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6600 - acc: 0.6057 - f1: 0.5688 - val_loss: 0.7019 - val_acc: 0.5370 - val_f1: 0.5398\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6589 - acc: 0.6098 - f1: 0.5871 - val_loss: 0.7258 - val_acc: 0.4778 - val_f1: 0.5460\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6591 - acc: 0.6040 - f1: 0.5745 - val_loss: 0.6918 - val_acc: 0.5370 - val_f1: 0.5342\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6573 - acc: 0.5999 - f1: 0.5683 - val_loss: 0.6994 - val_acc: 0.5222 - val_f1: 0.5367\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6614 - acc: 0.6032 - f1: 0.5746 - val_loss: 0.7059 - val_acc: 0.5222 - val_f1: 0.5298\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6584 - acc: 0.6110 - f1: 0.5757 - val_loss: 0.7002 - val_acc: 0.5259 - val_f1: 0.5369\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6546 - acc: 0.6205 - f1: 0.5996 - val_loss: 0.7036 - val_acc: 0.5185 - val_f1: 0.5406\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6522 - acc: 0.6164 - f1: 0.5945 - val_loss: 0.7003 - val_acc: 0.5519 - val_f1: 0.5567\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6506 - acc: 0.6267 - f1: 0.6039 - val_loss: 0.6944 - val_acc: 0.5407 - val_f1: 0.5405\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6527 - acc: 0.6094 - f1: 0.5906 - val_loss: 0.7033 - val_acc: 0.5370 - val_f1: 0.5445\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6508 - acc: 0.6201 - f1: 0.5888 - val_loss: 0.7088 - val_acc: 0.5370 - val_f1: 0.5744\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6485 - acc: 0.6329 - f1: 0.6144 - val_loss: 0.7133 - val_acc: 0.5296 - val_f1: 0.5467\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6458 - acc: 0.6209 - f1: 0.5929 - val_loss: 0.6982 - val_acc: 0.5333 - val_f1: 0.5787\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6422 - acc: 0.6345 - f1: 0.6208 - val_loss: 0.7161 - val_acc: 0.5222 - val_f1: 0.5638\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6421 - acc: 0.6321 - f1: 0.6099 - val_loss: 0.7165 - val_acc: 0.5333 - val_f1: 0.5712\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6383 - acc: 0.6382 - f1: 0.6208 - val_loss: 0.7079 - val_acc: 0.5259 - val_f1: 0.5697\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6368 - acc: 0.6362 - f1: 0.6183 - val_loss: 0.7219 - val_acc: 0.5259 - val_f1: 0.5714\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6379 - acc: 0.6386 - f1: 0.6208 - val_loss: 0.7198 - val_acc: 0.4963 - val_f1: 0.5545\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6359 - acc: 0.6407 - f1: 0.6242 - val_loss: 0.7201 - val_acc: 0.5185 - val_f1: 0.5707\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6280 - acc: 0.6601 - f1: 0.6428 - val_loss: 0.7184 - val_acc: 0.5037 - val_f1: 0.5230\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6359 - acc: 0.6337 - f1: 0.6188 - val_loss: 0.7184 - val_acc: 0.5074 - val_f1: 0.5251\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6319 - acc: 0.6411 - f1: 0.6221 - val_loss: 0.7138 - val_acc: 0.5222 - val_f1: 0.5439\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6322 - acc: 0.6605 - f1: 0.6504 - val_loss: 0.7051 - val_acc: 0.5333 - val_f1: 0.5435\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6317 - acc: 0.6411 - f1: 0.6180 - val_loss: 0.7250 - val_acc: 0.5000 - val_f1: 0.5414\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6286 - acc: 0.6510 - f1: 0.6365 - val_loss: 0.7152 - val_acc: 0.5148 - val_f1: 0.5683\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6277 - acc: 0.6514 - f1: 0.6367 - val_loss: 0.7099 - val_acc: 0.5593 - val_f1: 0.5976\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6268 - acc: 0.6407 - f1: 0.6272 - val_loss: 0.7033 - val_acc: 0.5519 - val_f1: 0.5472\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6206 - acc: 0.6593 - f1: 0.6446 - val_loss: 0.7205 - val_acc: 0.5407 - val_f1: 0.5807\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6189 - acc: 0.6704 - f1: 0.6563 - val_loss: 0.7087 - val_acc: 0.5148 - val_f1: 0.5495\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6233 - acc: 0.6527 - f1: 0.6409 - val_loss: 0.7232 - val_acc: 0.5148 - val_f1: 0.5356\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6142 - acc: 0.6696 - f1: 0.6547 - val_loss: 0.7209 - val_acc: 0.4963 - val_f1: 0.5385\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6179 - acc: 0.6642 - f1: 0.6532 - val_loss: 0.7053 - val_acc: 0.5630 - val_f1: 0.5977\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6124 - acc: 0.6654 - f1: 0.6527 - val_loss: 0.7084 - val_acc: 0.5519 - val_f1: 0.5960\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6113 - acc: 0.6679 - f1: 0.6545 - val_loss: 0.7192 - val_acc: 0.5370 - val_f1: 0.5845\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6109 - acc: 0.6667 - f1: 0.6570 - val_loss: 0.7212 - val_acc: 0.5222 - val_f1: 0.5751\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6040 - acc: 0.6757 - f1: 0.6674 - val_loss: 0.7212 - val_acc: 0.5185 - val_f1: 0.5730\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6047 - acc: 0.6856 - f1: 0.6749 - val_loss: 0.7265 - val_acc: 0.5370 - val_f1: 0.5861\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6036 - acc: 0.6811 - f1: 0.6646 - val_loss: 0.7148 - val_acc: 0.5296 - val_f1: 0.5729\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6014 - acc: 0.6844 - f1: 0.6731 - val_loss: 0.7280 - val_acc: 0.5296 - val_f1: 0.5592\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6004 - acc: 0.6823 - f1: 0.6707 - val_loss: 0.7356 - val_acc: 0.5222 - val_f1: 0.5749\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5961 - acc: 0.6869 - f1: 0.6799 - val_loss: 0.7283 - val_acc: 0.5259 - val_f1: 0.5757\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5917 - acc: 0.6811 - f1: 0.6675 - val_loss: 0.7233 - val_acc: 0.5370 - val_f1: 0.5821\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5875 - acc: 0.6955 - f1: 0.6841 - val_loss: 0.7333 - val_acc: 0.5000 - val_f1: 0.5409\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5957 - acc: 0.6897 - f1: 0.6825 - val_loss: 0.7293 - val_acc: 0.5556 - val_f1: 0.5936\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5880 - acc: 0.6972 - f1: 0.6855 - val_loss: 0.7197 - val_acc: 0.5296 - val_f1: 0.5593\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5872 - acc: 0.6852 - f1: 0.6752 - val_loss: 0.7183 - val_acc: 0.5222 - val_f1: 0.5638\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5742 - acc: 0.7124 - f1: 0.7045 - val_loss: 0.7525 - val_acc: 0.5185 - val_f1: 0.5306\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5833 - acc: 0.6972 - f1: 0.6867 - val_loss: 0.7389 - val_acc: 0.5222 - val_f1: 0.5456\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5808 - acc: 0.6980 - f1: 0.6901 - val_loss: 0.7269 - val_acc: 0.5333 - val_f1: 0.5591\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5798 - acc: 0.6897 - f1: 0.6805 - val_loss: 0.7223 - val_acc: 0.5259 - val_f1: 0.5624\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5810 - acc: 0.7033 - f1: 0.6952 - val_loss: 0.7293 - val_acc: 0.5481 - val_f1: 0.5870\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5751 - acc: 0.7087 - f1: 0.6992 - val_loss: 0.7321 - val_acc: 0.5407 - val_f1: 0.5652\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5787 - acc: 0.7066 - f1: 0.6992 - val_loss: 0.7376 - val_acc: 0.5444 - val_f1: 0.5801\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5710 - acc: 0.7120 - f1: 0.7029 - val_loss: 0.7423 - val_acc: 0.5000 - val_f1: 0.5177\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5688 - acc: 0.7058 - f1: 0.6980 - val_loss: 0.7210 - val_acc: 0.5259 - val_f1: 0.5419\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5654 - acc: 0.7165 - f1: 0.7077 - val_loss: 0.7410 - val_acc: 0.5185 - val_f1: 0.5365\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5741 - acc: 0.7062 - f1: 0.6926 - val_loss: 0.7163 - val_acc: 0.5111 - val_f1: 0.5348\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5645 - acc: 0.7087 - f1: 0.7018 - val_loss: 0.7287 - val_acc: 0.5296 - val_f1: 0.5618\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5636 - acc: 0.7108 - f1: 0.6981 - val_loss: 0.7339 - val_acc: 0.4889 - val_f1: 0.5071\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5604 - acc: 0.7178 - f1: 0.7110 - val_loss: 0.7578 - val_acc: 0.5000 - val_f1: 0.5350\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5564 - acc: 0.7305 - f1: 0.7245 - val_loss: 0.7450 - val_acc: 0.5074 - val_f1: 0.5155\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5522 - acc: 0.7272 - f1: 0.7177 - val_loss: 0.7533 - val_acc: 0.4963 - val_f1: 0.5109\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5571 - acc: 0.7124 - f1: 0.7073 - val_loss: 0.7421 - val_acc: 0.5037 - val_f1: 0.5337\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5555 - acc: 0.7202 - f1: 0.7104 - val_loss: 0.7477 - val_acc: 0.5148 - val_f1: 0.5430\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5543 - acc: 0.7173 - f1: 0.7128 - val_loss: 0.7470 - val_acc: 0.5037 - val_f1: 0.5083\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5448 - acc: 0.7252 - f1: 0.7175 - val_loss: 0.7424 - val_acc: 0.5185 - val_f1: 0.5414\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5322 - acc: 0.7408 - f1: 0.7328 - val_loss: 0.7616 - val_acc: 0.5074 - val_f1: 0.5148\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5410 - acc: 0.7326 - f1: 0.7252 - val_loss: 0.7530 - val_acc: 0.5000 - val_f1: 0.5247\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5473 - acc: 0.7256 - f1: 0.7184 - val_loss: 0.7647 - val_acc: 0.5222 - val_f1: 0.5548\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5385 - acc: 0.7408 - f1: 0.7323 - val_loss: 0.7404 - val_acc: 0.5074 - val_f1: 0.5402\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5404 - acc: 0.7301 - f1: 0.7251 - val_loss: 0.7503 - val_acc: 0.4926 - val_f1: 0.5060\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5407 - acc: 0.7281 - f1: 0.7214 - val_loss: 0.7566 - val_acc: 0.5074 - val_f1: 0.5346\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5331 - acc: 0.7285 - f1: 0.7216 - val_loss: 0.7521 - val_acc: 0.5037 - val_f1: 0.5304\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5301 - acc: 0.7359 - f1: 0.7293 - val_loss: 0.7480 - val_acc: 0.5185 - val_f1: 0.5435\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5373 - acc: 0.7367 - f1: 0.7298 - val_loss: 0.7466 - val_acc: 0.5074 - val_f1: 0.5261\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5191 - acc: 0.7470 - f1: 0.7402 - val_loss: 0.7715 - val_acc: 0.4963 - val_f1: 0.5319\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5248 - acc: 0.7363 - f1: 0.7295 - val_loss: 0.7653 - val_acc: 0.5222 - val_f1: 0.5457\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5205 - acc: 0.7458 - f1: 0.7389 - val_loss: 0.7532 - val_acc: 0.5185 - val_f1: 0.5403\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5184 - acc: 0.7495 - f1: 0.7425 - val_loss: 0.7778 - val_acc: 0.5111 - val_f1: 0.5150\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5283 - acc: 0.7388 - f1: 0.7319 - val_loss: 0.7614 - val_acc: 0.5296 - val_f1: 0.5554\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5115 - acc: 0.7499 - f1: 0.7443 - val_loss: 0.7576 - val_acc: 0.5222 - val_f1: 0.5410\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5173 - acc: 0.7553 - f1: 0.7492 - val_loss: 0.7735 - val_acc: 0.4963 - val_f1: 0.5310\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5033 - acc: 0.7585 - f1: 0.7533 - val_loss: 0.7530 - val_acc: 0.5148 - val_f1: 0.5391\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5137 - acc: 0.7499 - f1: 0.7443 - val_loss: 0.7788 - val_acc: 0.5111 - val_f1: 0.5190\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5091 - acc: 0.7482 - f1: 0.7420 - val_loss: 0.7723 - val_acc: 0.5148 - val_f1: 0.5430\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5057 - acc: 0.7647 - f1: 0.7579 - val_loss: 0.7878 - val_acc: 0.5000 - val_f1: 0.5346\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5057 - acc: 0.7557 - f1: 0.7501 - val_loss: 0.7881 - val_acc: 0.5259 - val_f1: 0.5515\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5094 - acc: 0.7577 - f1: 0.7519 - val_loss: 0.7693 - val_acc: 0.5185 - val_f1: 0.5459\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4996 - acc: 0.7627 - f1: 0.7567 - val_loss: 0.7852 - val_acc: 0.5037 - val_f1: 0.5326\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5018 - acc: 0.7565 - f1: 0.7507 - val_loss: 0.7803 - val_acc: 0.5296 - val_f1: 0.5546\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5041 - acc: 0.7524 - f1: 0.7447 - val_loss: 0.7855 - val_acc: 0.5037 - val_f1: 0.5355\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4977 - acc: 0.7631 - f1: 0.7587 - val_loss: 0.7810 - val_acc: 0.5148 - val_f1: 0.5392\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4956 - acc: 0.7590 - f1: 0.7519 - val_loss: 0.7725 - val_acc: 0.5074 - val_f1: 0.5349\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4975 - acc: 0.7656 - f1: 0.7608 - val_loss: 0.7859 - val_acc: 0.5074 - val_f1: 0.5403\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4936 - acc: 0.7684 - f1: 0.7632 - val_loss: 0.8091 - val_acc: 0.5037 - val_f1: 0.4999\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4860 - acc: 0.7746 - f1: 0.7687 - val_loss: 0.7972 - val_acc: 0.5222 - val_f1: 0.5233\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4778 - acc: 0.7734 - f1: 0.7675 - val_loss: 0.8165 - val_acc: 0.5222 - val_f1: 0.5446\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4843 - acc: 0.7701 - f1: 0.7647 - val_loss: 0.8045 - val_acc: 0.5037 - val_f1: 0.5396\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4924 - acc: 0.7532 - f1: 0.7465 - val_loss: 0.7877 - val_acc: 0.5370 - val_f1: 0.5350\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4821 - acc: 0.7660 - f1: 0.7612 - val_loss: 0.8146 - val_acc: 0.5037 - val_f1: 0.5371\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4800 - acc: 0.7779 - f1: 0.7723 - val_loss: 0.7959 - val_acc: 0.5185 - val_f1: 0.5414\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4809 - acc: 0.7684 - f1: 0.7636 - val_loss: 0.7980 - val_acc: 0.5407 - val_f1: 0.5325\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4820 - acc: 0.7738 - f1: 0.7687 - val_loss: 0.8284 - val_acc: 0.5037 - val_f1: 0.5364\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6906 - acc: 0.5538 - f1: 0.3658 - val_loss: 0.6957 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6876 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6939 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6890 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6973 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6888 - acc: 0.5538 - f1: 0.3565 - val_loss: 0.6940 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6875 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.6956 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6884 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.6955 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6866 - acc: 0.5534 - f1: 0.3553 - val_loss: 0.6969 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6860 - acc: 0.5529 - f1: 0.3561 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6861 - acc: 0.5534 - f1: 0.3690 - val_loss: 0.6971 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6866 - acc: 0.5459 - f1: 0.3775 - val_loss: 0.6943 - val_acc: 0.4741 - val_f1: 0.4015\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6850 - acc: 0.5542 - f1: 0.3668 - val_loss: 0.6940 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6854 - acc: 0.5538 - f1: 0.3577 - val_loss: 0.6930 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6857 - acc: 0.5529 - f1: 0.3583 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6848 - acc: 0.5542 - f1: 0.3577 - val_loss: 0.6932 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6842 - acc: 0.5550 - f1: 0.3613 - val_loss: 0.6924 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6845 - acc: 0.5575 - f1: 0.3860 - val_loss: 0.6955 - val_acc: 0.5296 - val_f1: 0.3844\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6836 - acc: 0.5571 - f1: 0.3705 - val_loss: 0.6951 - val_acc: 0.5185 - val_f1: 0.3866\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5579 - f1: 0.3869 - val_loss: 0.6937 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6840 - acc: 0.5616 - f1: 0.4009 - val_loss: 0.6930 - val_acc: 0.5259 - val_f1: 0.3413\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6846 - acc: 0.5542 - f1: 0.3750 - val_loss: 0.6932 - val_acc: 0.4889 - val_f1: 0.4241\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6863 - acc: 0.5480 - f1: 0.3991 - val_loss: 0.6951 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6854 - acc: 0.5554 - f1: 0.3833 - val_loss: 0.6918 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6837 - acc: 0.5505 - f1: 0.3748 - val_loss: 0.6913 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6836 - acc: 0.5571 - f1: 0.3956 - val_loss: 0.6936 - val_acc: 0.5185 - val_f1: 0.3653\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6839 - acc: 0.5562 - f1: 0.4034 - val_loss: 0.6920 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6843 - acc: 0.5600 - f1: 0.4154 - val_loss: 0.6916 - val_acc: 0.5407 - val_f1: 0.3776\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6816 - acc: 0.5620 - f1: 0.4233 - val_loss: 0.6923 - val_acc: 0.5370 - val_f1: 0.4664\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6803 - acc: 0.5665 - f1: 0.4400 - val_loss: 0.6927 - val_acc: 0.5333 - val_f1: 0.5524\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6823 - acc: 0.5558 - f1: 0.4615 - val_loss: 0.6938 - val_acc: 0.4778 - val_f1: 0.4710\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6814 - acc: 0.5641 - f1: 0.4190 - val_loss: 0.6922 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6796 - acc: 0.5703 - f1: 0.4490 - val_loss: 0.6921 - val_acc: 0.5370 - val_f1: 0.3979\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6814 - acc: 0.5616 - f1: 0.4314 - val_loss: 0.6921 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6791 - acc: 0.5707 - f1: 0.4452 - val_loss: 0.6919 - val_acc: 0.5185 - val_f1: 0.3484\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6771 - acc: 0.5686 - f1: 0.4575 - val_loss: 0.6885 - val_acc: 0.5444 - val_f1: 0.5305\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6754 - acc: 0.5645 - f1: 0.4555 - val_loss: 0.6889 - val_acc: 0.5259 - val_f1: 0.4430\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6745 - acc: 0.5764 - f1: 0.4896 - val_loss: 0.6914 - val_acc: 0.5407 - val_f1: 0.4347\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6750 - acc: 0.5719 - f1: 0.5214 - val_loss: 0.6901 - val_acc: 0.5333 - val_f1: 0.5544\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6735 - acc: 0.5756 - f1: 0.4940 - val_loss: 0.6903 - val_acc: 0.5481 - val_f1: 0.4883\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6717 - acc: 0.5744 - f1: 0.4881 - val_loss: 0.6899 - val_acc: 0.5593 - val_f1: 0.5651\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.5801 - f1: 0.5099 - val_loss: 0.6963 - val_acc: 0.4741 - val_f1: 0.4265\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6700 - acc: 0.5871 - f1: 0.5555 - val_loss: 0.6926 - val_acc: 0.5185 - val_f1: 0.5460\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6671 - acc: 0.5789 - f1: 0.5121 - val_loss: 0.6948 - val_acc: 0.5111 - val_f1: 0.5432\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6673 - acc: 0.5867 - f1: 0.5480 - val_loss: 0.6937 - val_acc: 0.5111 - val_f1: 0.5599\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6657 - acc: 0.5892 - f1: 0.5605 - val_loss: 0.6905 - val_acc: 0.5370 - val_f1: 0.5622\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6643 - acc: 0.5970 - f1: 0.5566 - val_loss: 0.6881 - val_acc: 0.5481 - val_f1: 0.5519\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6651 - acc: 0.5987 - f1: 0.5664 - val_loss: 0.6896 - val_acc: 0.5333 - val_f1: 0.5378\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6586 - acc: 0.6036 - f1: 0.5746 - val_loss: 0.6921 - val_acc: 0.5407 - val_f1: 0.5741\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6607 - acc: 0.6049 - f1: 0.5670 - val_loss: 0.6868 - val_acc: 0.5370 - val_f1: 0.5580\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6612 - acc: 0.6077 - f1: 0.5727 - val_loss: 0.6915 - val_acc: 0.5519 - val_f1: 0.5716\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6598 - acc: 0.6024 - f1: 0.5665 - val_loss: 0.6892 - val_acc: 0.5741 - val_f1: 0.5866\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6545 - acc: 0.6242 - f1: 0.6006 - val_loss: 0.6838 - val_acc: 0.5556 - val_f1: 0.5565\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6535 - acc: 0.6115 - f1: 0.5781 - val_loss: 0.6895 - val_acc: 0.5481 - val_f1: 0.5645\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6543 - acc: 0.6077 - f1: 0.5856 - val_loss: 0.6825 - val_acc: 0.5741 - val_f1: 0.6058\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6514 - acc: 0.6123 - f1: 0.5819 - val_loss: 0.6894 - val_acc: 0.5741 - val_f1: 0.5836\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6495 - acc: 0.6180 - f1: 0.5945 - val_loss: 0.6843 - val_acc: 0.5778 - val_f1: 0.6124\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6538 - acc: 0.6139 - f1: 0.5922 - val_loss: 0.6914 - val_acc: 0.5519 - val_f1: 0.5710\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6457 - acc: 0.6213 - f1: 0.5874 - val_loss: 0.6870 - val_acc: 0.6000 - val_f1: 0.6290\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6425 - acc: 0.6279 - f1: 0.6103 - val_loss: 0.6907 - val_acc: 0.5630 - val_f1: 0.5855\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6450 - acc: 0.6213 - f1: 0.6036 - val_loss: 0.6918 - val_acc: 0.5778 - val_f1: 0.6134\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6378 - acc: 0.6391 - f1: 0.6203 - val_loss: 0.7007 - val_acc: 0.5519 - val_f1: 0.5760\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6366 - acc: 0.6296 - f1: 0.6077 - val_loss: 0.6933 - val_acc: 0.5556 - val_f1: 0.5994\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6386 - acc: 0.6275 - f1: 0.6047 - val_loss: 0.6922 - val_acc: 0.5444 - val_f1: 0.5623\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6352 - acc: 0.6457 - f1: 0.6269 - val_loss: 0.6916 - val_acc: 0.5704 - val_f1: 0.6096\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6326 - acc: 0.6424 - f1: 0.6229 - val_loss: 0.6980 - val_acc: 0.5667 - val_f1: 0.6084\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6312 - acc: 0.6382 - f1: 0.6285 - val_loss: 0.6895 - val_acc: 0.5667 - val_f1: 0.6047\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6336 - acc: 0.6288 - f1: 0.6062 - val_loss: 0.6958 - val_acc: 0.5593 - val_f1: 0.6031\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6266 - acc: 0.6436 - f1: 0.6281 - val_loss: 0.6918 - val_acc: 0.5704 - val_f1: 0.6103\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6283 - acc: 0.6510 - f1: 0.6346 - val_loss: 0.6957 - val_acc: 0.5593 - val_f1: 0.5982\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6270 - acc: 0.6465 - f1: 0.6338 - val_loss: 0.7009 - val_acc: 0.5667 - val_f1: 0.6082\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6281 - acc: 0.6349 - f1: 0.6166 - val_loss: 0.6938 - val_acc: 0.5778 - val_f1: 0.6141\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6269 - acc: 0.6432 - f1: 0.6263 - val_loss: 0.6991 - val_acc: 0.5407 - val_f1: 0.5874\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6214 - acc: 0.6432 - f1: 0.6281 - val_loss: 0.7048 - val_acc: 0.5519 - val_f1: 0.5960\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6204 - acc: 0.6465 - f1: 0.6307 - val_loss: 0.6988 - val_acc: 0.5704 - val_f1: 0.6105\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6178 - acc: 0.6522 - f1: 0.6382 - val_loss: 0.6984 - val_acc: 0.5556 - val_f1: 0.5994\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6162 - acc: 0.6658 - f1: 0.6533 - val_loss: 0.6988 - val_acc: 0.5667 - val_f1: 0.6055\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6173 - acc: 0.6568 - f1: 0.6420 - val_loss: 0.7057 - val_acc: 0.5556 - val_f1: 0.6007\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6167 - acc: 0.6543 - f1: 0.6397 - val_loss: 0.7025 - val_acc: 0.5593 - val_f1: 0.6030\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6163 - acc: 0.6708 - f1: 0.6609 - val_loss: 0.7070 - val_acc: 0.5704 - val_f1: 0.6094\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6156 - acc: 0.6588 - f1: 0.6418 - val_loss: 0.7042 - val_acc: 0.5444 - val_f1: 0.5921\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6111 - acc: 0.6638 - f1: 0.6540 - val_loss: 0.7036 - val_acc: 0.5333 - val_f1: 0.5846\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6163 - acc: 0.6568 - f1: 0.6458 - val_loss: 0.6983 - val_acc: 0.5519 - val_f1: 0.5972\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6062 - acc: 0.6683 - f1: 0.6546 - val_loss: 0.6938 - val_acc: 0.5519 - val_f1: 0.5980\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5995 - acc: 0.6774 - f1: 0.6674 - val_loss: 0.7031 - val_acc: 0.5259 - val_f1: 0.5795\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6071 - acc: 0.6691 - f1: 0.6551 - val_loss: 0.6996 - val_acc: 0.5407 - val_f1: 0.5901\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6048 - acc: 0.6786 - f1: 0.6721 - val_loss: 0.6932 - val_acc: 0.5667 - val_f1: 0.6078\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6005 - acc: 0.6642 - f1: 0.6505 - val_loss: 0.7010 - val_acc: 0.5481 - val_f1: 0.5953\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6017 - acc: 0.6827 - f1: 0.6724 - val_loss: 0.7148 - val_acc: 0.5259 - val_f1: 0.5599\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6037 - acc: 0.6679 - f1: 0.6546 - val_loss: 0.7034 - val_acc: 0.5630 - val_f1: 0.6005\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5992 - acc: 0.6881 - f1: 0.6761 - val_loss: 0.7096 - val_acc: 0.5185 - val_f1: 0.5739\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5928 - acc: 0.6873 - f1: 0.6805 - val_loss: 0.7100 - val_acc: 0.5259 - val_f1: 0.5797\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5887 - acc: 0.6889 - f1: 0.6801 - val_loss: 0.7109 - val_acc: 0.5556 - val_f1: 0.6003\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5990 - acc: 0.6786 - f1: 0.6668 - val_loss: 0.7043 - val_acc: 0.5407 - val_f1: 0.5700\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5987 - acc: 0.6811 - f1: 0.6707 - val_loss: 0.7110 - val_acc: 0.5111 - val_f1: 0.5686\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5853 - acc: 0.6885 - f1: 0.6762 - val_loss: 0.7201 - val_acc: 0.5222 - val_f1: 0.5761\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5885 - acc: 0.6893 - f1: 0.6807 - val_loss: 0.7163 - val_acc: 0.5222 - val_f1: 0.5762\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5858 - acc: 0.6918 - f1: 0.6815 - val_loss: 0.7100 - val_acc: 0.5519 - val_f1: 0.5980\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5909 - acc: 0.6807 - f1: 0.6726 - val_loss: 0.7216 - val_acc: 0.5481 - val_f1: 0.5952\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5905 - acc: 0.6766 - f1: 0.6664 - val_loss: 0.7179 - val_acc: 0.5259 - val_f1: 0.5592\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5849 - acc: 0.6889 - f1: 0.6783 - val_loss: 0.7173 - val_acc: 0.5296 - val_f1: 0.5820\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5829 - acc: 0.6967 - f1: 0.6861 - val_loss: 0.7254 - val_acc: 0.5037 - val_f1: 0.5433\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5839 - acc: 0.7021 - f1: 0.6943 - val_loss: 0.7177 - val_acc: 0.5407 - val_f1: 0.5899\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5754 - acc: 0.6980 - f1: 0.6892 - val_loss: 0.7187 - val_acc: 0.5333 - val_f1: 0.5844\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5744 - acc: 0.7042 - f1: 0.6955 - val_loss: 0.7259 - val_acc: 0.5296 - val_f1: 0.5621\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5753 - acc: 0.6885 - f1: 0.6803 - val_loss: 0.7128 - val_acc: 0.5593 - val_f1: 0.5830\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5731 - acc: 0.6972 - f1: 0.6868 - val_loss: 0.7151 - val_acc: 0.5444 - val_f1: 0.5714\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5717 - acc: 0.6914 - f1: 0.6828 - val_loss: 0.7261 - val_acc: 0.5333 - val_f1: 0.5428\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5689 - acc: 0.7124 - f1: 0.7061 - val_loss: 0.7308 - val_acc: 0.5259 - val_f1: 0.5780\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5722 - acc: 0.7005 - f1: 0.6883 - val_loss: 0.7270 - val_acc: 0.5370 - val_f1: 0.5466\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5698 - acc: 0.6980 - f1: 0.6879 - val_loss: 0.7419 - val_acc: 0.5111 - val_f1: 0.5281\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5624 - acc: 0.7033 - f1: 0.6944 - val_loss: 0.7234 - val_acc: 0.5556 - val_f1: 0.5807\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5623 - acc: 0.7103 - f1: 0.7029 - val_loss: 0.7317 - val_acc: 0.5259 - val_f1: 0.5596\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5682 - acc: 0.7128 - f1: 0.7040 - val_loss: 0.7217 - val_acc: 0.5519 - val_f1: 0.5769\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5651 - acc: 0.7000 - f1: 0.6912 - val_loss: 0.7319 - val_acc: 0.5333 - val_f1: 0.5644\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5637 - acc: 0.7095 - f1: 0.7019 - val_loss: 0.7328 - val_acc: 0.5222 - val_f1: 0.5753\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5586 - acc: 0.7141 - f1: 0.7068 - val_loss: 0.7463 - val_acc: 0.5333 - val_f1: 0.5644\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5601 - acc: 0.7141 - f1: 0.7053 - val_loss: 0.7397 - val_acc: 0.5296 - val_f1: 0.5819\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5605 - acc: 0.7149 - f1: 0.7085 - val_loss: 0.7392 - val_acc: 0.5333 - val_f1: 0.5648\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5511 - acc: 0.7248 - f1: 0.7163 - val_loss: 0.7398 - val_acc: 0.5148 - val_f1: 0.5312\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5488 - acc: 0.7256 - f1: 0.7182 - val_loss: 0.7526 - val_acc: 0.5148 - val_f1: 0.5704\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5521 - acc: 0.7202 - f1: 0.7111 - val_loss: 0.7406 - val_acc: 0.5444 - val_f1: 0.5939\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5521 - acc: 0.7219 - f1: 0.7167 - val_loss: 0.7463 - val_acc: 0.5185 - val_f1: 0.5332\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5427 - acc: 0.7309 - f1: 0.7236 - val_loss: 0.7407 - val_acc: 0.5370 - val_f1: 0.5650\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5449 - acc: 0.7293 - f1: 0.7213 - val_loss: 0.7563 - val_acc: 0.5556 - val_f1: 0.5934\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5444 - acc: 0.7252 - f1: 0.7188 - val_loss: 0.7563 - val_acc: 0.5259 - val_f1: 0.5594\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5488 - acc: 0.7182 - f1: 0.7099 - val_loss: 0.7596 - val_acc: 0.5370 - val_f1: 0.5335\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5330 - acc: 0.7404 - f1: 0.7358 - val_loss: 0.7590 - val_acc: 0.5370 - val_f1: 0.5869\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5463 - acc: 0.7132 - f1: 0.7050 - val_loss: 0.7549 - val_acc: 0.5407 - val_f1: 0.5897\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5362 - acc: 0.7309 - f1: 0.7237 - val_loss: 0.7452 - val_acc: 0.5222 - val_f1: 0.5567\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5430 - acc: 0.7227 - f1: 0.7146 - val_loss: 0.7563 - val_acc: 0.5037 - val_f1: 0.5625\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5475 - acc: 0.7223 - f1: 0.7161 - val_loss: 0.7437 - val_acc: 0.5407 - val_f1: 0.5898\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5325 - acc: 0.7379 - f1: 0.7299 - val_loss: 0.7426 - val_acc: 0.5370 - val_f1: 0.5671\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5371 - acc: 0.7412 - f1: 0.7342 - val_loss: 0.7868 - val_acc: 0.5556 - val_f1: 0.5744\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5397 - acc: 0.7384 - f1: 0.7305 - val_loss: 0.7631 - val_acc: 0.5481 - val_f1: 0.5873\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5315 - acc: 0.7297 - f1: 0.7240 - val_loss: 0.7626 - val_acc: 0.5407 - val_f1: 0.5899\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5307 - acc: 0.7429 - f1: 0.7359 - val_loss: 0.7799 - val_acc: 0.5556 - val_f1: 0.5623\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5315 - acc: 0.7371 - f1: 0.7281 - val_loss: 0.7710 - val_acc: 0.5444 - val_f1: 0.5540\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5356 - acc: 0.7375 - f1: 0.7311 - val_loss: 0.7637 - val_acc: 0.5333 - val_f1: 0.5594\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5192 - acc: 0.7466 - f1: 0.7375 - val_loss: 0.7758 - val_acc: 0.5370 - val_f1: 0.5607\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5281 - acc: 0.7281 - f1: 0.7214 - val_loss: 0.7614 - val_acc: 0.5593 - val_f1: 0.6254\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5158 - acc: 0.7441 - f1: 0.7366 - val_loss: 0.7838 - val_acc: 0.5333 - val_f1: 0.5465\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5221 - acc: 0.7400 - f1: 0.7341 - val_loss: 0.7645 - val_acc: 0.5556 - val_f1: 0.5471\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5202 - acc: 0.7445 - f1: 0.7382 - val_loss: 0.7739 - val_acc: 0.5222 - val_f1: 0.5392\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5247 - acc: 0.7433 - f1: 0.7371 - val_loss: 0.7778 - val_acc: 0.5296 - val_f1: 0.5279\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5165 - acc: 0.7511 - f1: 0.7446 - val_loss: 0.7799 - val_acc: 0.5148 - val_f1: 0.5336\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5245 - acc: 0.7417 - f1: 0.7347 - val_loss: 0.7865 - val_acc: 0.5444 - val_f1: 0.5509\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5148 - acc: 0.7445 - f1: 0.7379 - val_loss: 0.7884 - val_acc: 0.5333 - val_f1: 0.5580\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5159 - acc: 0.7528 - f1: 0.7456 - val_loss: 0.7809 - val_acc: 0.5481 - val_f1: 0.5417\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5092 - acc: 0.7524 - f1: 0.7459 - val_loss: 0.7965 - val_acc: 0.5333 - val_f1: 0.5583\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5173 - acc: 0.7433 - f1: 0.7364 - val_loss: 0.7929 - val_acc: 0.5148 - val_f1: 0.5300\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5127 - acc: 0.7470 - f1: 0.7423 - val_loss: 0.7858 - val_acc: 0.5333 - val_f1: 0.6034\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5242 - acc: 0.7318 - f1: 0.7253 - val_loss: 0.7749 - val_acc: 0.5296 - val_f1: 0.5451\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5144 - acc: 0.7466 - f1: 0.7410 - val_loss: 0.7708 - val_acc: 0.5556 - val_f1: 0.5753\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5090 - acc: 0.7462 - f1: 0.7411 - val_loss: 0.7979 - val_acc: 0.5185 - val_f1: 0.5371\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6909 - acc: 0.5443 - f1: 0.3661 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6891 - acc: 0.5480 - f1: 0.3696 - val_loss: 0.6927 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6882 - acc: 0.5525 - f1: 0.3706 - val_loss: 0.6978 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6885 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6867 - acc: 0.5534 - f1: 0.3567 - val_loss: 0.6943 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6876 - acc: 0.5534 - f1: 0.3737 - val_loss: 0.6937 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6858 - acc: 0.5529 - f1: 0.3566 - val_loss: 0.6943 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6853 - acc: 0.5534 - f1: 0.3671 - val_loss: 0.6948 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6865 - acc: 0.5505 - f1: 0.3704 - val_loss: 0.6935 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6855 - acc: 0.5513 - f1: 0.3620 - val_loss: 0.6952 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6827 - acc: 0.5550 - f1: 0.3760 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6841 - acc: 0.5542 - f1: 0.3724 - val_loss: 0.6960 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6821 - acc: 0.5579 - f1: 0.3834 - val_loss: 0.6951 - val_acc: 0.5259 - val_f1: 0.3460\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6824 - acc: 0.5538 - f1: 0.3892 - val_loss: 0.6934 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6813 - acc: 0.5587 - f1: 0.3953 - val_loss: 0.6945 - val_acc: 0.5074 - val_f1: 0.3739\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6842 - acc: 0.5624 - f1: 0.4627 - val_loss: 0.7003 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6799 - acc: 0.5604 - f1: 0.4162 - val_loss: 0.6947 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6796 - acc: 0.5575 - f1: 0.4345 - val_loss: 0.6954 - val_acc: 0.5074 - val_f1: 0.3811\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6834 - acc: 0.5600 - f1: 0.4709 - val_loss: 0.6959 - val_acc: 0.4926 - val_f1: 0.3539\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6797 - acc: 0.5653 - f1: 0.4589 - val_loss: 0.6908 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6798 - acc: 0.5748 - f1: 0.4778 - val_loss: 0.6963 - val_acc: 0.4889 - val_f1: 0.3648\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6769 - acc: 0.5682 - f1: 0.4585 - val_loss: 0.6928 - val_acc: 0.4778 - val_f1: 0.4200\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6777 - acc: 0.5665 - f1: 0.5186 - val_loss: 0.6919 - val_acc: 0.5333 - val_f1: 0.4124\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6745 - acc: 0.5748 - f1: 0.4711 - val_loss: 0.6908 - val_acc: 0.5370 - val_f1: 0.3543\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6748 - acc: 0.5781 - f1: 0.5398 - val_loss: 0.7022 - val_acc: 0.5148 - val_f1: 0.3515\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6756 - acc: 0.5595 - f1: 0.4848 - val_loss: 0.6928 - val_acc: 0.5222 - val_f1: 0.3450\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6730 - acc: 0.5768 - f1: 0.5186 - val_loss: 0.6905 - val_acc: 0.5444 - val_f1: 0.5264\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6721 - acc: 0.5793 - f1: 0.5370 - val_loss: 0.6913 - val_acc: 0.5407 - val_f1: 0.3650\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6725 - acc: 0.5871 - f1: 0.5401 - val_loss: 0.6916 - val_acc: 0.5259 - val_f1: 0.3864\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.5822 - f1: 0.5309 - val_loss: 0.6963 - val_acc: 0.5259 - val_f1: 0.3546\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6716 - acc: 0.5826 - f1: 0.5332 - val_loss: 0.6864 - val_acc: 0.5296 - val_f1: 0.5337\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6688 - acc: 0.5913 - f1: 0.5546 - val_loss: 0.6922 - val_acc: 0.5296 - val_f1: 0.3879\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6665 - acc: 0.5954 - f1: 0.5465 - val_loss: 0.6907 - val_acc: 0.5296 - val_f1: 0.3943\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6645 - acc: 0.5987 - f1: 0.5697 - val_loss: 0.6855 - val_acc: 0.5556 - val_f1: 0.5260\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6648 - acc: 0.5979 - f1: 0.5612 - val_loss: 0.6945 - val_acc: 0.5407 - val_f1: 0.4206\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6601 - acc: 0.6156 - f1: 0.5860 - val_loss: 0.6888 - val_acc: 0.5481 - val_f1: 0.4668\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6614 - acc: 0.5962 - f1: 0.5533 - val_loss: 0.6896 - val_acc: 0.5333 - val_f1: 0.4497\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6629 - acc: 0.5925 - f1: 0.5532 - val_loss: 0.6925 - val_acc: 0.5370 - val_f1: 0.4430\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6575 - acc: 0.6110 - f1: 0.5799 - val_loss: 0.6902 - val_acc: 0.5370 - val_f1: 0.4551\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6581 - acc: 0.6036 - f1: 0.5712 - val_loss: 0.6919 - val_acc: 0.5222 - val_f1: 0.4684\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6572 - acc: 0.6201 - f1: 0.5975 - val_loss: 0.6936 - val_acc: 0.5222 - val_f1: 0.4121\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6504 - acc: 0.6197 - f1: 0.5936 - val_loss: 0.6883 - val_acc: 0.5333 - val_f1: 0.4828\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6545 - acc: 0.6131 - f1: 0.5805 - val_loss: 0.6894 - val_acc: 0.5074 - val_f1: 0.5019\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6457 - acc: 0.6238 - f1: 0.6013 - val_loss: 0.6925 - val_acc: 0.5111 - val_f1: 0.4702\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6491 - acc: 0.6226 - f1: 0.5963 - val_loss: 0.6960 - val_acc: 0.5000 - val_f1: 0.4560\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6492 - acc: 0.6139 - f1: 0.5877 - val_loss: 0.6926 - val_acc: 0.5148 - val_f1: 0.4881\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6460 - acc: 0.6267 - f1: 0.6049 - val_loss: 0.6955 - val_acc: 0.5185 - val_f1: 0.4492\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6447 - acc: 0.6209 - f1: 0.6059 - val_loss: 0.6979 - val_acc: 0.5333 - val_f1: 0.4863\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6475 - acc: 0.6251 - f1: 0.5896 - val_loss: 0.6962 - val_acc: 0.5185 - val_f1: 0.4900\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6411 - acc: 0.6333 - f1: 0.6156 - val_loss: 0.7096 - val_acc: 0.4963 - val_f1: 0.4731\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6346 - acc: 0.6403 - f1: 0.6259 - val_loss: 0.6958 - val_acc: 0.5185 - val_f1: 0.4854\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6360 - acc: 0.6333 - f1: 0.6137 - val_loss: 0.6929 - val_acc: 0.5259 - val_f1: 0.4914\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6415 - acc: 0.6308 - f1: 0.6109 - val_loss: 0.7009 - val_acc: 0.5074 - val_f1: 0.4723\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6346 - acc: 0.6444 - f1: 0.6236 - val_loss: 0.7003 - val_acc: 0.5259 - val_f1: 0.4814\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6343 - acc: 0.6341 - f1: 0.6193 - val_loss: 0.7008 - val_acc: 0.5185 - val_f1: 0.4923\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6266 - acc: 0.6502 - f1: 0.6319 - val_loss: 0.6929 - val_acc: 0.5296 - val_f1: 0.5076\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6233 - acc: 0.6386 - f1: 0.6193 - val_loss: 0.7055 - val_acc: 0.5111 - val_f1: 0.4510\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6227 - acc: 0.6539 - f1: 0.6366 - val_loss: 0.6973 - val_acc: 0.5185 - val_f1: 0.5115\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6196 - acc: 0.6481 - f1: 0.6365 - val_loss: 0.6987 - val_acc: 0.5037 - val_f1: 0.5169\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6190 - acc: 0.6576 - f1: 0.6425 - val_loss: 0.7035 - val_acc: 0.5222 - val_f1: 0.4774\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6165 - acc: 0.6654 - f1: 0.6503 - val_loss: 0.6986 - val_acc: 0.5333 - val_f1: 0.5420\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6172 - acc: 0.6543 - f1: 0.6424 - val_loss: 0.6903 - val_acc: 0.5593 - val_f1: 0.5602\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6095 - acc: 0.6683 - f1: 0.6560 - val_loss: 0.6970 - val_acc: 0.5222 - val_f1: 0.5493\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6124 - acc: 0.6572 - f1: 0.6405 - val_loss: 0.6985 - val_acc: 0.5074 - val_f1: 0.5134\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6116 - acc: 0.6593 - f1: 0.6476 - val_loss: 0.7201 - val_acc: 0.5074 - val_f1: 0.4842\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6064 - acc: 0.6708 - f1: 0.6583 - val_loss: 0.7069 - val_acc: 0.5296 - val_f1: 0.4993\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.6009 - acc: 0.6761 - f1: 0.6636 - val_loss: 0.7038 - val_acc: 0.5444 - val_f1: 0.5236\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.6704 - f1: 0.6608 - val_loss: 0.7017 - val_acc: 0.5333 - val_f1: 0.5141\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.6007 - acc: 0.6716 - f1: 0.6607 - val_loss: 0.6865 - val_acc: 0.5593 - val_f1: 0.5590\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5956 - acc: 0.6807 - f1: 0.6693 - val_loss: 0.6974 - val_acc: 0.5296 - val_f1: 0.5567\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5963 - acc: 0.6749 - f1: 0.6634 - val_loss: 0.7081 - val_acc: 0.5111 - val_f1: 0.4788\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5960 - acc: 0.6741 - f1: 0.6640 - val_loss: 0.6918 - val_acc: 0.5556 - val_f1: 0.5561\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5936 - acc: 0.6848 - f1: 0.6724 - val_loss: 0.7112 - val_acc: 0.5444 - val_f1: 0.5285\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5900 - acc: 0.6819 - f1: 0.6709 - val_loss: 0.6956 - val_acc: 0.5259 - val_f1: 0.5355\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5905 - acc: 0.6782 - f1: 0.6684 - val_loss: 0.6913 - val_acc: 0.5259 - val_f1: 0.5314\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5802 - acc: 0.6922 - f1: 0.6834 - val_loss: 0.6858 - val_acc: 0.5593 - val_f1: 0.5367\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5789 - acc: 0.6943 - f1: 0.6831 - val_loss: 0.6826 - val_acc: 0.5556 - val_f1: 0.5551\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5820 - acc: 0.7070 - f1: 0.6985 - val_loss: 0.6876 - val_acc: 0.5556 - val_f1: 0.5490\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5818 - acc: 0.6934 - f1: 0.6843 - val_loss: 0.6940 - val_acc: 0.5481 - val_f1: 0.5466\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5812 - acc: 0.6930 - f1: 0.6845 - val_loss: 0.6920 - val_acc: 0.5704 - val_f1: 0.5602\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5788 - acc: 0.6939 - f1: 0.6823 - val_loss: 0.6893 - val_acc: 0.5593 - val_f1: 0.5550\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5681 - acc: 0.7050 - f1: 0.6950 - val_loss: 0.7001 - val_acc: 0.5481 - val_f1: 0.5344\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5712 - acc: 0.7087 - f1: 0.7003 - val_loss: 0.6886 - val_acc: 0.5593 - val_f1: 0.5557\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5706 - acc: 0.7029 - f1: 0.6931 - val_loss: 0.6853 - val_acc: 0.5778 - val_f1: 0.5704\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5604 - acc: 0.7070 - f1: 0.6986 - val_loss: 0.6790 - val_acc: 0.5593 - val_f1: 0.5548\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5719 - acc: 0.7054 - f1: 0.6963 - val_loss: 0.6709 - val_acc: 0.6037 - val_f1: 0.6087\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5619 - acc: 0.7025 - f1: 0.6922 - val_loss: 0.6798 - val_acc: 0.5519 - val_f1: 0.5483\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5647 - acc: 0.7141 - f1: 0.7070 - val_loss: 0.6710 - val_acc: 0.5963 - val_f1: 0.5823\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5549 - acc: 0.7103 - f1: 0.7037 - val_loss: 0.6842 - val_acc: 0.5630 - val_f1: 0.5589\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5555 - acc: 0.7120 - f1: 0.7019 - val_loss: 0.6789 - val_acc: 0.5556 - val_f1: 0.5520\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5531 - acc: 0.7186 - f1: 0.7113 - val_loss: 0.6788 - val_acc: 0.5704 - val_f1: 0.5652\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5531 - acc: 0.7215 - f1: 0.7154 - val_loss: 0.6724 - val_acc: 0.5704 - val_f1: 0.5563\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5512 - acc: 0.7178 - f1: 0.7072 - val_loss: 0.6826 - val_acc: 0.5444 - val_f1: 0.5652\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5476 - acc: 0.7194 - f1: 0.7135 - val_loss: 0.7003 - val_acc: 0.5333 - val_f1: 0.5289\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5427 - acc: 0.7198 - f1: 0.7089 - val_loss: 0.6741 - val_acc: 0.5815 - val_f1: 0.6141\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5481 - acc: 0.7227 - f1: 0.7155 - val_loss: 0.6739 - val_acc: 0.5815 - val_f1: 0.5719\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5364 - acc: 0.7301 - f1: 0.7236 - val_loss: 0.6720 - val_acc: 0.5815 - val_f1: 0.5689\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5386 - acc: 0.7285 - f1: 0.7225 - val_loss: 0.6852 - val_acc: 0.5556 - val_f1: 0.5502\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5401 - acc: 0.7219 - f1: 0.7146 - val_loss: 0.6832 - val_acc: 0.5741 - val_f1: 0.5643\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5351 - acc: 0.7239 - f1: 0.7161 - val_loss: 0.6700 - val_acc: 0.5815 - val_f1: 0.5724\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5332 - acc: 0.7392 - f1: 0.7335 - val_loss: 0.6746 - val_acc: 0.5556 - val_f1: 0.5513\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5313 - acc: 0.7309 - f1: 0.7229 - val_loss: 0.6784 - val_acc: 0.5963 - val_f1: 0.5982\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.5355 - acc: 0.7256 - f1: 0.7187 - val_loss: 0.6695 - val_acc: 0.5778 - val_f1: 0.5695\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5290 - acc: 0.7429 - f1: 0.7353 - val_loss: 0.6766 - val_acc: 0.5370 - val_f1: 0.5549\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5248 - acc: 0.7379 - f1: 0.7333 - val_loss: 0.6730 - val_acc: 0.5889 - val_f1: 0.5950\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5195 - acc: 0.7367 - f1: 0.7273 - val_loss: 0.6747 - val_acc: 0.5667 - val_f1: 0.6035\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5250 - acc: 0.7462 - f1: 0.7411 - val_loss: 0.6752 - val_acc: 0.5815 - val_f1: 0.6103\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5187 - acc: 0.7408 - f1: 0.7349 - val_loss: 0.6781 - val_acc: 0.5815 - val_f1: 0.5864\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5189 - acc: 0.7450 - f1: 0.7374 - val_loss: 0.6665 - val_acc: 0.6037 - val_f1: 0.5894\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5212 - acc: 0.7338 - f1: 0.7284 - val_loss: 0.6641 - val_acc: 0.5778 - val_f1: 0.5886\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5118 - acc: 0.7577 - f1: 0.7502 - val_loss: 0.6675 - val_acc: 0.5741 - val_f1: 0.5667\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5161 - acc: 0.7371 - f1: 0.7302 - val_loss: 0.6823 - val_acc: 0.5704 - val_f1: 0.6043\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5086 - acc: 0.7511 - f1: 0.7441 - val_loss: 0.6773 - val_acc: 0.5852 - val_f1: 0.5689\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5105 - acc: 0.7412 - f1: 0.7353 - val_loss: 0.6787 - val_acc: 0.5630 - val_f1: 0.5788\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5039 - acc: 0.7487 - f1: 0.7418 - val_loss: 0.6663 - val_acc: 0.5704 - val_f1: 0.5642\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.5133 - acc: 0.7421 - f1: 0.7346 - val_loss: 0.6769 - val_acc: 0.5630 - val_f1: 0.5570\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4964 - acc: 0.7511 - f1: 0.7438 - val_loss: 0.6725 - val_acc: 0.5667 - val_f1: 0.5627\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4956 - acc: 0.7548 - f1: 0.7476 - val_loss: 0.6695 - val_acc: 0.5963 - val_f1: 0.6051\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4926 - acc: 0.7602 - f1: 0.7548 - val_loss: 0.6805 - val_acc: 0.5593 - val_f1: 0.5747\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4949 - acc: 0.7581 - f1: 0.7520 - val_loss: 0.6659 - val_acc: 0.5889 - val_f1: 0.5748\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4985 - acc: 0.7606 - f1: 0.7539 - val_loss: 0.6816 - val_acc: 0.5481 - val_f1: 0.5447\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4963 - acc: 0.7573 - f1: 0.7511 - val_loss: 0.6817 - val_acc: 0.5667 - val_f1: 0.5638\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4929 - acc: 0.7672 - f1: 0.7610 - val_loss: 0.6806 - val_acc: 0.5481 - val_f1: 0.5691\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4948 - acc: 0.7623 - f1: 0.7567 - val_loss: 0.7116 - val_acc: 0.5407 - val_f1: 0.5329\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4879 - acc: 0.7660 - f1: 0.7602 - val_loss: 0.6844 - val_acc: 0.5593 - val_f1: 0.5575\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4981 - acc: 0.7532 - f1: 0.7464 - val_loss: 0.6930 - val_acc: 0.5481 - val_f1: 0.5900\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4921 - acc: 0.7606 - f1: 0.7567 - val_loss: 0.6869 - val_acc: 0.5630 - val_f1: 0.5848\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4876 - acc: 0.7598 - f1: 0.7540 - val_loss: 0.6777 - val_acc: 0.5593 - val_f1: 0.5736\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4860 - acc: 0.7639 - f1: 0.7584 - val_loss: 0.6835 - val_acc: 0.5556 - val_f1: 0.5736\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4784 - acc: 0.7726 - f1: 0.7682 - val_loss: 0.6869 - val_acc: 0.5519 - val_f1: 0.5721\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4867 - acc: 0.7606 - f1: 0.7553 - val_loss: 0.6774 - val_acc: 0.5630 - val_f1: 0.5773\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4754 - acc: 0.7787 - f1: 0.7730 - val_loss: 0.6753 - val_acc: 0.5741 - val_f1: 0.5679\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4659 - acc: 0.7787 - f1: 0.7715 - val_loss: 0.6756 - val_acc: 0.5667 - val_f1: 0.6072\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4776 - acc: 0.7721 - f1: 0.7658 - val_loss: 0.6860 - val_acc: 0.5926 - val_f1: 0.5980\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4760 - acc: 0.7759 - f1: 0.7699 - val_loss: 0.6942 - val_acc: 0.5593 - val_f1: 0.5571\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4802 - acc: 0.7726 - f1: 0.7669 - val_loss: 0.6924 - val_acc: 0.5370 - val_f1: 0.5573\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4679 - acc: 0.7742 - f1: 0.7688 - val_loss: 0.7025 - val_acc: 0.5481 - val_f1: 0.5700\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4699 - acc: 0.7808 - f1: 0.7767 - val_loss: 0.6948 - val_acc: 0.5667 - val_f1: 0.5861\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4708 - acc: 0.7792 - f1: 0.7731 - val_loss: 0.6874 - val_acc: 0.5704 - val_f1: 0.5866\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4723 - acc: 0.7783 - f1: 0.7736 - val_loss: 0.6798 - val_acc: 0.5741 - val_f1: 0.6094\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4625 - acc: 0.7820 - f1: 0.7765 - val_loss: 0.6970 - val_acc: 0.5481 - val_f1: 0.5710\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4552 - acc: 0.7841 - f1: 0.7802 - val_loss: 0.6935 - val_acc: 0.5481 - val_f1: 0.5732\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4606 - acc: 0.7796 - f1: 0.7744 - val_loss: 0.7036 - val_acc: 0.5481 - val_f1: 0.5828\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4645 - acc: 0.7742 - f1: 0.7687 - val_loss: 0.6969 - val_acc: 0.5630 - val_f1: 0.5764\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4597 - acc: 0.7804 - f1: 0.7745 - val_loss: 0.7053 - val_acc: 0.5630 - val_f1: 0.5596\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4598 - acc: 0.7767 - f1: 0.7722 - val_loss: 0.6834 - val_acc: 0.5815 - val_f1: 0.5925\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4600 - acc: 0.7829 - f1: 0.7771 - val_loss: 0.6845 - val_acc: 0.5889 - val_f1: 0.5980\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4596 - acc: 0.7862 - f1: 0.7826 - val_loss: 0.7071 - val_acc: 0.5593 - val_f1: 0.5803\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4546 - acc: 0.7849 - f1: 0.7805 - val_loss: 0.6986 - val_acc: 0.5481 - val_f1: 0.5684\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4476 - acc: 0.7911 - f1: 0.7857 - val_loss: 0.6932 - val_acc: 0.5704 - val_f1: 0.5837\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4535 - acc: 0.7936 - f1: 0.7882 - val_loss: 0.7097 - val_acc: 0.5704 - val_f1: 0.6097\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4391 - acc: 0.7956 - f1: 0.7913 - val_loss: 0.7099 - val_acc: 0.5667 - val_f1: 0.5839\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4426 - acc: 0.7936 - f1: 0.7889 - val_loss: 0.6880 - val_acc: 0.5815 - val_f1: 0.5982\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4436 - acc: 0.7923 - f1: 0.7879 - val_loss: 0.7149 - val_acc: 0.5667 - val_f1: 0.5823\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4411 - acc: 0.7948 - f1: 0.7912 - val_loss: 0.6910 - val_acc: 0.5926 - val_f1: 0.6210\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4296 - acc: 0.7940 - f1: 0.7873 - val_loss: 0.6926 - val_acc: 0.5704 - val_f1: 0.5903\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4306 - acc: 0.8022 - f1: 0.7982 - val_loss: 0.7011 - val_acc: 0.5815 - val_f1: 0.5954\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4327 - acc: 0.7923 - f1: 0.7871 - val_loss: 0.7141 - val_acc: 0.5704 - val_f1: 0.5858\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4396 - acc: 0.7866 - f1: 0.7819 - val_loss: 0.7115 - val_acc: 0.5556 - val_f1: 0.5743\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4433 - acc: 0.7927 - f1: 0.7880 - val_loss: 0.7187 - val_acc: 0.5481 - val_f1: 0.5936\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4438 - acc: 0.7833 - f1: 0.7783 - val_loss: 0.6984 - val_acc: 0.5815 - val_f1: 0.6168\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4340 - acc: 0.7960 - f1: 0.7920 - val_loss: 0.7280 - val_acc: 0.5741 - val_f1: 0.6120\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4334 - acc: 0.7965 - f1: 0.7915 - val_loss: 0.6969 - val_acc: 0.5630 - val_f1: 0.5798\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4373 - acc: 0.7932 - f1: 0.7883 - val_loss: 0.7040 - val_acc: 0.5815 - val_f1: 0.6181\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4387 - acc: 0.7899 - f1: 0.7841 - val_loss: 0.7160 - val_acc: 0.5593 - val_f1: 0.5782\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4279 - acc: 0.8006 - f1: 0.7970 - val_loss: 0.7205 - val_acc: 0.5852 - val_f1: 0.6210\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4314 - acc: 0.8002 - f1: 0.7951 - val_loss: 0.7268 - val_acc: 0.5333 - val_f1: 0.5813\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4176 - acc: 0.8088 - f1: 0.8035 - val_loss: 0.7200 - val_acc: 0.5778 - val_f1: 0.6148\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4308 - acc: 0.7998 - f1: 0.7947 - val_loss: 0.7163 - val_acc: 0.5704 - val_f1: 0.5855\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4220 - acc: 0.8101 - f1: 0.8065 - val_loss: 0.7191 - val_acc: 0.5556 - val_f1: 0.5998\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4241 - acc: 0.8117 - f1: 0.8073 - val_loss: 0.7403 - val_acc: 0.5519 - val_f1: 0.5964\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4164 - acc: 0.8096 - f1: 0.8049 - val_loss: 0.7165 - val_acc: 0.5963 - val_f1: 0.6031\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4117 - acc: 0.8092 - f1: 0.8051 - val_loss: 0.7301 - val_acc: 0.5741 - val_f1: 0.6136\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4289 - acc: 0.8030 - f1: 0.7984 - val_loss: 0.7349 - val_acc: 0.5630 - val_f1: 0.6050\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4196 - acc: 0.8039 - f1: 0.8004 - val_loss: 0.7410 - val_acc: 0.5778 - val_f1: 0.5726\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4119 - acc: 0.8035 - f1: 0.7988 - val_loss: 0.7245 - val_acc: 0.5815 - val_f1: 0.6187\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4174 - acc: 0.8084 - f1: 0.8054 - val_loss: 0.7141 - val_acc: 0.5556 - val_f1: 0.5773\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4163 - acc: 0.8121 - f1: 0.8081 - val_loss: 0.7485 - val_acc: 0.5444 - val_f1: 0.5680\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4149 - acc: 0.8109 - f1: 0.8072 - val_loss: 0.7410 - val_acc: 0.5370 - val_f1: 0.5859\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.4142 - acc: 0.8043 - f1: 0.7997 - val_loss: 0.7506 - val_acc: 0.5667 - val_f1: 0.5861\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4075 - acc: 0.8195 - f1: 0.8157 - val_loss: 0.7383 - val_acc: 0.5259 - val_f1: 0.5577\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4211 - acc: 0.8068 - f1: 0.8024 - val_loss: 0.7531 - val_acc: 0.5185 - val_f1: 0.5503\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4077 - acc: 0.8154 - f1: 0.8111 - val_loss: 0.7300 - val_acc: 0.5667 - val_f1: 0.6065\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4010 - acc: 0.8146 - f1: 0.8109 - val_loss: 0.7419 - val_acc: 0.5593 - val_f1: 0.6027\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4017 - acc: 0.8068 - f1: 0.8031 - val_loss: 0.7797 - val_acc: 0.5519 - val_f1: 0.5991\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3979 - acc: 0.8150 - f1: 0.8108 - val_loss: 0.7430 - val_acc: 0.5407 - val_f1: 0.5869\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4021 - acc: 0.8109 - f1: 0.8064 - val_loss: 0.7813 - val_acc: 0.5370 - val_f1: 0.5472\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4118 - acc: 0.8063 - f1: 0.8032 - val_loss: 0.7448 - val_acc: 0.5593 - val_f1: 0.5782\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4055 - acc: 0.8109 - f1: 0.8064 - val_loss: 0.7656 - val_acc: 0.5444 - val_f1: 0.5927\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3889 - acc: 0.8241 - f1: 0.8205 - val_loss: 0.7766 - val_acc: 0.5407 - val_f1: 0.5466\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4010 - acc: 0.8183 - f1: 0.8134 - val_loss: 0.7589 - val_acc: 0.5630 - val_f1: 0.6072\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.4036 - acc: 0.8068 - f1: 0.8018 - val_loss: 0.7517 - val_acc: 0.5556 - val_f1: 0.5753\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3996 - acc: 0.8129 - f1: 0.8087 - val_loss: 0.7411 - val_acc: 0.5630 - val_f1: 0.6049\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3934 - acc: 0.8228 - f1: 0.8184 - val_loss: 0.7744 - val_acc: 0.5519 - val_f1: 0.5730\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3990 - acc: 0.8105 - f1: 0.8061 - val_loss: 0.7349 - val_acc: 0.5815 - val_f1: 0.6188\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.3933 - acc: 0.8154 - f1: 0.8102 - val_loss: 0.7777 - val_acc: 0.5333 - val_f1: 0.5415\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3939 - acc: 0.8191 - f1: 0.8149 - val_loss: 0.7566 - val_acc: 0.5630 - val_f1: 0.6059\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3902 - acc: 0.8278 - f1: 0.8243 - val_loss: 0.7538 - val_acc: 0.5519 - val_f1: 0.5777\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3865 - acc: 0.8331 - f1: 0.8303 - val_loss: 0.7630 - val_acc: 0.5333 - val_f1: 0.5395\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3999 - acc: 0.8171 - f1: 0.8133 - val_loss: 0.7668 - val_acc: 0.5593 - val_f1: 0.6019\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model_full = cnnpred_2d(60, 57, [8, 8, 8])\n",
    "    epochs = 200\n",
    "    batch_size=128\n",
    "\n",
    "    ## Training\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "        mode='auto', baseline=None, restore_best_weights=False\n",
    "    )\n",
    "\n",
    "    model_full.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"acc\", f1])\n",
    "    model_full.fit(X_train_full, y_train_full, epochs=epochs,\n",
    "                batch_size=batch_size, callbacks=[early_stopping],\n",
    "                validation_data=(X_valid_full, y_valid_full))\n",
    "\n",
    "    acc1 = -1\n",
    "    acc2 = -2\n",
    "    acc3 = -3\n",
    "    ## aapl\n",
    "    result_aapl_full = model_full.predict(aapl_X_test_full)\n",
    "    result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "\n",
    "    if acc1 < accuracy_score(result_aapl_full, aapl_y_test_full):\n",
    "        acc1 = accuracy_score(result_aapl_full, aapl_y_test_full)\n",
    "        f.write(f\"aapl Accuracy: {acc1}\")\n",
    "        f.write(f\"aapl F1: {f1_score(result_aapl_full, aapl_y_test_full, average='macro')}\")\n",
    "        f.write('\\n')\n",
    "\n",
    "    ## msft\n",
    "    result_msft_full = model_full.predict(msft_X_test_full)\n",
    "    result_msft_full = (result_msft_full > 0.5).astype(int)\n",
    "    if acc2 < accuracy_score(result_msft_full, msft_y_test_full):\n",
    "        acc2 = accuracy_score(result_msft_full, msft_y_test_full)\n",
    "        f.write(f\"msft Accuracy: {acc2}\")\n",
    "        f.write(f\"msft F1: {f1_score(result_msft_full, msft_y_test_full, average='macro')}\")\n",
    "        f.write('\\n')\n",
    "    ## amzn\n",
    "    result_amzn_full = model_full.predict(amzn_X_test_full)\n",
    "    result_amzn_full = (result_amzn_full > 0.5).astype(int)\n",
    "    if acc3 < accuracy_score(result_amzn_full, amzn_y_test_full):\n",
    "        acc3 = accuracy_score(result_amzn_full, amzn_y_test_full)\n",
    "        f.writelines(f\"amzn Accuracy: {acc3}\")\n",
    "        f.write(f\"amzn F1: {f1_score(result_amzn_full, amzn_y_test_full, average='macro')}\")\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.47      0.51        51\n",
      "           1       0.53      0.61      0.57        49\n",
      "\n",
      "    accuracy                           0.54       100\n",
      "   macro avg       0.54      0.54      0.54       100\n",
      "weighted avg       0.54      0.54      0.54       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## AAPL\n",
    "print(classification_report(result_aapl_full, aapl_y_test_full))\n",
    "plot_confusion_matrix(result_aapl_full, aapl_y_test_full, labels=[\"Down\", \"Up\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.4975 - acc: 0.5385 - f1: 0.3828 - val_loss: 0.4956 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4795 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4809 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4526 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4708 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4469 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4705 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3561 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3552 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3552 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4705 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4706 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4705 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4707 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4711 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4465 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4710 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4464 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4726 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4734 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4457 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4734 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4450 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4757 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4451 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4735 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4447 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4722 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4441 - acc: 0.5538 - f1: 0.3583 - val_loss: 0.4743 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4437 - acc: 0.5562 - f1: 0.3719 - val_loss: 0.4722 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4430 - acc: 0.5604 - f1: 0.3890 - val_loss: 0.4709 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4429 - acc: 0.5575 - f1: 0.3781 - val_loss: 0.4720 - val_acc: 0.5370 - val_f1: 0.3733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a17109edc0>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca = cnnpred_2d(60, 5, [8, 8, 8])\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "## Training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=50, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model_pca.compile(optimizer=\"Adam\", loss=\"mae\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_pca.fit(X_train_pca, y_train_pca, epochs=epochs,\n",
    "              batch_size=batch_size, callbacks=[early_stopping],\n",
    "              validation_data=(X_valid_pca, y_valid_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl Accuracy: 0.57\n",
      "aapl F1: 0.36305732484076436\n"
     ]
    }
   ],
   "source": [
    "## aapl\n",
    "result_aapl_pca = model_pca.predict(aapl_X_test_pca)\n",
    "result_aapl_pca = (result_aapl_pca > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_pca, aapl_y_test_pca)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_pca, aapl_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft Accuracy: 0.55\n",
      "msft F1: 0.3548387096774194\n"
     ]
    }
   ],
   "source": [
    "## msft\n",
    "result_msft_pca = model_pca.predict(msft_X_test_pca)\n",
    "result_msft_pca = (result_msft_pca > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_pca, msft_y_test_pca)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_pca, msft_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amzn Accuracy: 0.54\n",
      "amzn F1: 0.5245969408846631\n"
     ]
    }
   ],
   "source": [
    "## amzn\n",
    "result_amzn_pca = model_pca.predict(amzn_X_test_pca)\n",
    "result_amzn_pca = (result_amzn_pca > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_pca, amzn_y_test_pca)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_pca, amzn_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical indicator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 1s 19ms/step - loss: 0.4804 - acc: 0.5496 - f1: 0.3599 - val_loss: 0.4736 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4475 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4467 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3553 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3553 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3553 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3561 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3551 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3553 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3555 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3556 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3554 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3559 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3560 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3558 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3552 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.4466 - acc: 0.5534 - f1: 0.3557 - val_loss: 0.4704 - val_acc: 0.5296 - val_f1: 0.3424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a171354a60>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ti = cnnpred_2d(60, X_train_ti.shape[2], [8, 8, 8])\n",
    "epochs = 200\n",
    "batch_size=128\n",
    "\n",
    "## Training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=50, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model_ti.compile(optimizer=\"Adam\", loss=\"mae\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_ti.fit(X_train_ti, y_train_ti, epochs=epochs,\n",
    "              batch_size=batch_size, callbacks=[early_stopping],\n",
    "              validation_data=(X_valid_ti, y_valid_ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl Accuracy: 0.57\n",
      "aapl F1: 0.36305732484076436\n"
     ]
    }
   ],
   "source": [
    "## aapl\n",
    "result_aapl_ti = model_ti.predict(aapl_X_test_ti)\n",
    "result_aapl_ti = (result_aapl_ti > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_ti, aapl_y_test_ti)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_ti, aapl_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft Accuracy: 0.55\n",
      "msft F1: 0.3548387096774194\n"
     ]
    }
   ],
   "source": [
    "## msft\n",
    "result_msft_ti = model_ti.predict(msft_X_test_ti)\n",
    "result_msft_ti = (result_msft_ti > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_ti, msft_y_test_ti)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_ti, msft_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amzn Accuracy: 0.49\n",
      "amzn F1: 0.32885906040268453\n"
     ]
    }
   ],
   "source": [
    "## amzn\n",
    "result_amzn_ti = model_ti.predict(amzn_X_test_ti)\n",
    "result_amzn_ti = (result_amzn_ti > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_ti, amzn_y_test_ti)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_ti, amzn_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aapl_X_test_cor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-65aeae4d617a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnnpred_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maapl_X_test_cor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m## Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aapl_X_test_cor' is not defined"
     ]
    }
   ],
   "source": [
    "model_cor = cnnpred_2d(30, aapl_X_test_cor.shape[2], [8, 8, 8])\n",
    "epochs = 200\n",
    "batch_size=128\n",
    "\n",
    "## Training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=50, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model_cor.compile(optimizer=\"Adam\", loss=\"mae\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_cor.fit(X_train_cor, y_train_cor, epochs=epochs,\n",
    "              batch_size=batch_size, callbacks=[early_stopping],\n",
    "              validation_data=(X_valid_cor, y_valid_cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aapl\n",
    "result_aapl_cor = model_cor.predict(aapl_X_test_cor)\n",
    "result_aapl_cor = (result_aapl_ti > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_cor, aapl_y_test_cor)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_ti, aapl_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "result_msft_cor = model_cor.predict(msft_X_test_cor)\n",
    "result_msft_cor = (result_msft_ti > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_cor, msft_y_test_cor)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_cor, msft_y_test_cor, average='macro')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "result_amzn_cor = model_cor.predict(amzn_X_test_cor)\n",
    "result_amzn_cor = (result_amzn_cor > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_cor, amzn_y_test_cor)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_cor, amzn_y_test_cor, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (full features)\n",
    "aapl_X_seq_flatten = sequential_reshape(aapl_X_seq, (len(aapl_X_seq), -1))\n",
    "msft_X_seq_flatten = sequential_reshape(msft_X_seq, (len(msft_X_seq), -1))\n",
    "amzn_X_seq_flatten = sequential_reshape(amzn_X_seq, (len(amzn_X_seq), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (pca)\n",
    "aapl_X_pca_seq_flatten = sequential_reshape(aapl_X_pca_seq, (len(aapl_X_pca_seq), -1))\n",
    "msft_X_pca_seq_flatten = sequential_reshape(msft_X_pca_seq, (len(msft_X_pca_seq), -1))\n",
    "amzn_X_pca_seq_flatten = sequential_reshape(amzn_X_pca_seq, (len(amzn_X_pca_seq), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential flatten (technical indicator)\n",
    "aapl_X_ti_seq_flatten = sequential_reshape(aapl_X_ti_seq, (len(aapl_X_ti_seq), -1))\n",
    "msft_X_ti_seq_flatten = sequential_reshape(msft_X_ti_seq, (len(msft_X_ti_seq), -1))\n",
    "amzn_X_ti_seq_flatten = sequential_reshape(amzn_X_ti_seq, (len(amzn_X_ti_seq), -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training/validation/test (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full features\n",
    "aapl_X_train_full, aapl_X_test_full, aapl_y_train_full, aapl_y_test_full = train_test_split(aapl_X_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=aapl_y_seq,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=True)\n",
    "aapl_X_train_full, aapl_X_valid_full, aapl_y_train_full, aapl_y_valid_full = train_test_split(aapl_X_train_full,\n",
    "                                                                                        aapl_y_train_full,\n",
    "                                                                                        stratify=aapl_y_train_full,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=True)\n",
    "msft_X_train_full, msft_X_test_full, msft_y_train_full, msft_y_test_full = train_test_split(msft_X_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=msft_y_seq,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=True)\n",
    "msft_X_train_full, msft_X_valid_full, msft_y_train_full, msft_y_valid_full = train_test_split(msft_X_train_full,\n",
    "                                                                                        msft_y_train_full,\n",
    "                                                                                        stratify=msft_y_train_full,\n",
    "                                                                                        test_size=0.1,\n",
    "                                                                                        shuffle=True)\n",
    "amzn_X_train_full, amzn_X_test_full, amzn_y_train_full, amzn_y_test_full = train_test_split(amzn_X_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=amzn_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "amzn_X_train_full, amzn_X_valid_full, amzn_y_train_full, amzn_y_valid_full = train_test_split(amzn_X_train_full,\n",
    "                                                                                        amzn_y_train_full,\n",
    "                                                                                        stratify=amzn_y_train_full,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pca features\n",
    "aapl_X_train_pca, aapl_X_test_pca, aapl_y_train_pca, aapl_y_test_pca = train_test_split(aapl_X_pca_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=aapl_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "aapl_X_train_pca, aapl_X_valid_pca, aapl_y_train_pca, aapl_y_valid_pca = train_test_split(aapl_X_train_pca,\n",
    "                                                                                        aapl_y_train_pca,\n",
    "                                                                                        stratify=aapl_y_train_pca,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "msft_X_train_pca, msft_X_test_pca, msft_y_train_pca, msft_y_test_pca = train_test_split(msft_X_pca_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=msft_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "msft_X_train_pca, msft_X_valid_pca, msft_y_train_pca, msft_y_valid_pca = train_test_split(msft_X_train_pca,\n",
    "                                                                                        msft_y_train_pca,\n",
    "                                                                                        stratify=msft_y_train_pca,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "amzn_X_train_pca, amzn_X_test_pca, amzn_y_train_pca, amzn_y_test_pca = train_test_split(amzn_X_pca_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=amzn_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "amzn_X_train_pca, amzn_X_valid_pca, amzn_y_train_pca, amzn_y_valid_pca = train_test_split(amzn_X_train_pca,\n",
    "                                                                                        amzn_y_train_pca,\n",
    "                                                                                        stratify=amzn_y_train_pca,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ti features\n",
    "aapl_X_train_ti, aapl_X_test_ti, aapl_y_train_ti, aapl_y_test_ti = train_test_split(aapl_X_ti_seq_flatten,\n",
    "                                                                                        aapl_y_seq,\n",
    "                                                                                        stratify=aapl_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "aapl_X_train_ti, aapl_X_valid_ti, aapl_y_train_ti, aapl_y_valid_ti = train_test_split(aapl_X_train_ti,\n",
    "                                                                                        aapl_y_train_ti,\n",
    "                                                                                        stratify=aapl_y_train_ti,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "msft_X_train_ti, msft_X_test_ti, msft_y_train_ti, msft_y_test_ti = train_test_split(msft_X_ti_seq_flatten,\n",
    "                                                                                        msft_y_seq,\n",
    "                                                                                        stratify=msft_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "msft_X_train_ti, msft_X_valid_ti, msft_y_train_ti, msft_y_valid_ti = train_test_split(msft_X_train_ti,\n",
    "                                                                                        msft_y_train_ti,\n",
    "                                                                                        stratify=msft_y_train_ti,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "amzn_X_train_ti, amzn_X_test_ti, amzn_y_train_ti, amzn_y_test_ti = train_test_split(amzn_X_ti_seq_flatten,\n",
    "                                                                                        amzn_y_seq,\n",
    "                                                                                        stratify=amzn_y_seq,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n",
    "amzn_X_train_ti, amzn_X_valid_ti, amzn_y_train_ti, amzn_y_valid_ti = train_test_split(amzn_X_train_ti,\n",
    "                                                                                        amzn_y_train_ti,\n",
    "                                                                                        stratify=amzn_y_train_ti,\n",
    "                                                                                        test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aapl\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-2)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=50, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(aapl_X_train_full, np.array(aapl_y_train_full), \n",
    "          epochs=200, batch_size=32,\n",
    "          validation_data=(aapl_X_valid_full, np.array(aapl_y_valid_full)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(aapl_X_test_full)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_full, aapl_y_test_full)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_full, aapl_y_test_full, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(msft_X_train_full, np.array(msft_y_train_full), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(msft_X_valid_full, np.array(msft_y_valid_full)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "result_msft_full = model.predict(msft_X_test_full)\n",
    "result_msft_full = (result_msft_full > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_full, msft_y_test_full)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_full, msft_y_test_full, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(amzn_X_train_full, np.array(amzn_y_train_full), \n",
    "          epochs=200, batch_size=32,\n",
    "          validation_data=(amzn_X_valid_full, np.array(amzn_y_valid_full)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "result_amzn_full = model.predict(amzn_X_test_full)\n",
    "result_amzn_full = (result_amzn_full > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_full, amzn_y_test_full)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_full, amzn_y_test_full, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aapl\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-2)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(aapl_X_train_pca, np.array(aapl_y_train_pca), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(aapl_X_valid_pca, np.array(aapl_y_valid_pca)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(aapl_X_test_pca)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_full, aapl_y_test_pca)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_full, aapl_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(msft_X_train_pca, np.array(msft_y_train_pca), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(msft_X_valid_pca, np.array(msft_y_valid_pca)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "result_msft_full = model.predict(msft_X_test_pca)\n",
    "result_msft_full = (result_msft_full > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_full, msft_y_test_pca)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_full, msft_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(amzn_X_train_pca, np.array(amzn_y_train_pca), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(amzn_X_valid_pca, np.array(amzn_y_valid_pca)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "result_amzn_full = model.predict(amzn_X_test_pca)\n",
    "result_amzn_full = (result_amzn_full > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_full, amzn_y_test_pca)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_full, amzn_y_test_pca, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical indicator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aapl\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-2)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(aapl_X_train_ti, np.array(aapl_y_train_ti), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(aapl_X_valid_ti, np.array(aapl_y_valid_ti)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(aapl_X_test_ti)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_full, aapl_y_test_ti)}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_full, aapl_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(msft_X_train_ti, np.array(msft_y_train_ti), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(msft_X_valid_ti, np.array(msft_y_valid_ti)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## msft\n",
    "result_msft_full = model.predict(msft_X_test_ti)\n",
    "result_msft_full = (result_msft_full > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_msft_full, msft_y_test_ti)}\")\n",
    "print(f\"msft F1: {f1_score(result_msft_full, msft_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=100, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit(amzn_X_train_ti, np.array(amzn_y_train_ti), \n",
    "          epochs=200, batch_size=128,\n",
    "          validation_data=(amzn_X_valid_ti, np.array(amzn_y_valid_ti)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amzn\n",
    "result_amzn_full = model.predict(amzn_X_test_ti)\n",
    "result_amzn_full = (result_amzn_full > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_amzn_full, amzn_y_test_ti)}\")\n",
    "print(f\"amzn F1: {f1_score(result_amzn_full, amzn_y_test_ti, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing values, do some scaling (run prev cell first)\n",
    "list_df = []\n",
    "\n",
    "for df in [aapl_df, msft_df, amzn_df]:\n",
    "    columns = df.columns\n",
    "    df.fillna(0, inplace=True) # fill na with 0\n",
    "    y = df[\"MOVEMENT\"].copy()\n",
    "    X = df.drop(columns=[\"MOVEMENT\"]).copy()\n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X))\n",
    "    X[\"MOVEMENT\"] = np.array(y)\n",
    "    X.columns = columns\n",
    "    list_df.append(X)\n",
    "    \n",
    "aapl_df_full = list_df[0]\n",
    "msft_df_full = list_df[1]\n",
    "amzn_df_full = list_df[2]\n",
    "\n",
    "# #Columns RFE + PCA with the columns of high ranking feature classified using RFE in Data Exploration.ipynb\n",
    "# list_df_pca = []\n",
    "\n",
    "columns_pca = [\n",
    "    \"Open\", \"Close\", \"Adj Close\", \"Lower_bb\",\n",
    "    \"Sma\", \"Macd\" \n",
    "]\n",
    "\n",
    "# # columns_pca = [\n",
    "# #     \"Mom5\", \"Mom20\", \"Volume\", \"Fast_k\",\n",
    "# #     \"Nat_Gas\", \"Cci\", 'Ultosc'\n",
    "# # ]\n",
    "\n",
    "for df in [aapl_df_full, msft_df_full, amzn_df_full]:\n",
    "    cur_df = df.copy()\n",
    "    cur_df = feature_select(cur_df , 5)\n",
    "    pca = PCA(n_components= 1)\n",
    "    y = df[\"MOVEMENT\"].copy()\n",
    "    X = df.drop(columns=[\"MOVEMENT\"]).copy()\n",
    "    reduced_X = pd.DataFrame(pca.fit_transform(X))\n",
    "    reduced_X[\"MOVEMENT\"] = y\n",
    "    list_df_pca.append(reduced_X)\n",
    "\n",
    "aapl_df_pca = list_df_pca[0]\n",
    "msft_df_pca = list_df_pca[1]\n",
    "amzn_df_pca = list_df_pca[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aapl_df_full = list_df_pca[0]\n",
    "msft_df_full = list_df_pca[1]\n",
    "amzn_df_full = list_df_pca[2]\n",
    "\n",
    "# #Ingnore movement column\n",
    "nf = amzn_df_full.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aapl\n",
    "# Split\n",
    "X = np.array(aapl_df_full.drop(columns=[\"MOVEMENT\"]).copy())\n",
    "y = np.array(aapl_df_full[\"MOVEMENT\"].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test, should not shuffle as the data is time series\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False , random_state = 32\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, shuffle=False , random_state = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input ready for lstm\n",
    "win_length = 30\n",
    "batch_size = 32\n",
    "num_features = nf\n",
    "train_generator = TimeseriesGenerator(np.array(X_train), np.array(y_train),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "test_generator = TimeseriesGenerator(np.array(X_test), np.array(y_test),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "valid_generator = TimeseriesGenerator(np.array(X_valid), np.array(y_valid),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = gru(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model_gru.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_gru.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lstm(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model_gru.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"aapl Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"aapl F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# Split train test, should not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"Mean Absolute Error:\", round(metrics.mean_absolute_error(y_test, predict), 4))\n",
    "print(\"Mean Squared Error:\", round(metrics.mean_squared_error(y_test, predict), 4))\n",
    "print(\"Root Mean Squared Error:\", round(np.sqrt(metrics.mean_squared_error(y_test, predict)), 4))\n",
    "print(\"(R^2) Score:\", round(metrics.r2_score(y_test, predict), 4))\n",
    "# print(f'Train Score : {model.score(X_train, y_train) * 100:.2f}% and Test Score : {model.score(X_test, y_test) * 100:.2f}% using Random Tree Regressor.')\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(predict , y_test) , '%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### msft\n",
    "# Split\n",
    "X = np.array(msft_df_full.drop(columns=[\"MOVEMENT\"]).copy())\n",
    "y = np.array(msft_df_full[\"MOVEMENT\"].copy())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test, should not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False , random_state = 32\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, shuffle=False , random_state = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input ready for lstm\n",
    "win_length = 30\n",
    "batch_size = 32\n",
    "num_features = nf\n",
    "train_generator = TimeseriesGenerator(np.array(X_train), np.array(y_train),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "test_generator = TimeseriesGenerator(np.array(X_test), np.array(y_test),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "valid_generator = TimeseriesGenerator(np.array(X_valid), np.array(y_valid),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = gru(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model_gru.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_gru.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lstm(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model_gru.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"msft F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"msft Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"msft F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# Split train test, should not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"Mean Absolute Error:\", round(metrics.mean_absolute_error(y_test, predict), 4))\n",
    "print(\"Mean Squared Error:\", round(metrics.mean_squared_error(y_test, predict), 4))\n",
    "print(\"Root Mean Squared Error:\", round(np.sqrt(metrics.mean_squared_error(y_test, predict)), 4))\n",
    "print(\"(R^2) Score:\", round(metrics.r2_score(y_test, predict), 4))\n",
    "# print(f'Train Score : {model.score(X_train, y_train) * 100:.2f}% and Test Score : {model.score(X_test, y_test) * 100:.2f}% using Random Tree Regressor.')\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(predict , y_test) , '%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### amzn\n",
    "# Split\n",
    "X = np.array(amzn_df_full.drop(columns=[\"MOVEMENT\"]).copy())\n",
    "y = np.array(amzn_df_full[\"MOVEMENT\"].copy())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test, should not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False , random_state = 32\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, shuffle=False , random_state = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input ready for lstm\n",
    "win_length = 30\n",
    "batch_size = 32\n",
    "num_features = nf\n",
    "train_generator = TimeseriesGenerator(np.array(X_train), np.array(y_train),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "test_generator = TimeseriesGenerator(np.array(X_test), np.array(y_test),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "valid_generator = TimeseriesGenerator(np.array(X_valid), np.array(y_valid),\n",
    "                                     length=win_length,\n",
    "                                     sampling_rate=1,\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = gru(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model_gru.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model_gru.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lstm(win_length, num_features)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                 patience=20,\n",
    "                                                 mode=\"min\")\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                   metrics=[\"acc\", f1])\n",
    "model.fit_generator(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=valid_generator,\n",
    "                   shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model_gru.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"amzn F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_aapl_full = model.predict(test_generator)\n",
    "result_aapl_full = (result_aapl_full > 0.5).astype(int)\n",
    "print(f\"amzn Accuracy: {accuracy_score(result_aapl_full, y_test[win_length:])}\")\n",
    "print(f\"amzn F1: {f1_score(result_aapl_full, y_test[win_length:], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# Split train test, should not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "print(\"Mean Absolute Error:\", round(metrics.mean_absolute_error(y_test, predict), 4))\n",
    "print(\"Mean Squared Error:\", round(metrics.mean_squared_error(y_test, predict), 4))\n",
    "print(\"Root Mean Squared Error:\", round(np.sqrt(metrics.mean_squared_error(y_test, predict)), 4))\n",
    "print(\"(R^2) Score:\", round(metrics.r2_score(y_test, predict), 4))\n",
    "# print(f'Train Score : {model.score(X_train, y_train) * 100:.2f}% and Test Score : {model.score(X_test, y_test) * 100:.2f}% using Random Tree Regressor.')\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(predict , y_test) , '%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Full feature\n",
    "\n",
    "# aapl Accuracy: 0.44\n",
    "# aapl F1: 0.41\n",
    "\n",
    "# msft Accuracy: 0.57\n",
    "# msft F1: 0.50\n",
    "\n",
    "# amzn Accuracy: 0.45\n",
    "# amzn F1: 0.44\n",
    "\n",
    "# #45,53,49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "# aapl Accuracy: 0.47093023255813954\n",
    "# aapl F1: 0.45545002261420175\n",
    "\n",
    "# msft Accuracy: 0.563953488372093\n",
    "# msft F1: 0.3944514857062385\n",
    "\n",
    "# amzn Accuracy: 0.4883720930232558\n",
    "# amzn F1: 0.4649321266968325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aapl Accuracy: 0.5581395348837209\n",
    "# aapl F1: 0.4509408602150538\n",
    "\n",
    "# msft Accuracy: 0.5581395348837209\n",
    "# msft F1: 0.3810606060606061\n",
    "\n",
    "# amzn Accuracy: 0.5\n",
    "# amzn F1: 0.3333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV 7 FEATURE LOGISTIC REGRESSION\n",
    "\n",
    "# aapl Accuracy: 0.45348837209302323\n",
    "# aapl F1: 0.4443986254295532\n",
    "\n",
    "\n",
    "# msft Accuracy: 0.5290697674418605\n",
    "# msft F1: 0.49767441860465117\n",
    "\n",
    "# amzn Accuracy: 0.5116279069767442\n",
    "# amzn F1: 0.40786885245901644\n",
    "\n",
    "#RFE DecisionTreeClassifier \n",
    "\n",
    "# aapl Accuracy: 0.45348837209302323\n",
    "# aapl F1: 0.3937303134843258\n",
    "\n",
    "# msft Accuracy: 0.48255813953488375\n",
    "# msft F1: 0.4023814171383955\n",
    "\n",
    "# amzn Accuracy: 0.4883720930232558\n",
    "# amzn F1: 0.48135964912280693\n",
    "\n",
    "#Anova -F score\n",
    "\n",
    "# aapl Accuracy: 0.47674418604651164\n",
    "# aapl F1: 0.4695723684210526\n",
    "\n",
    "# msft Accuracy: 0.47093023255813954\n",
    "# msft F1: 0.45951172347111435\n",
    "\n",
    "# amzn Accuracy: 0.5\n",
    "# amzn F1: 0.47434257285003556\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
